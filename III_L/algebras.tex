\documentclass[a4paper]{article}

\def\npart {III}
\def\nterm {Lent}
\def\nyear {2017}
\def\nlecturer {C. J. B. Brookes}
\def\ncourse {Algebras}

\input{header}

\begin{document}
\maketitle
{\small
\setlength{\parindent}{0em}
\setlength{\parskip}{1em}
The aim of the course is to give an introduction to algebras. The emphasis will be on non-commutative examples that arise in representation theory (of groups and Lie algebras) and the theory of algebraic D-modules, though you will learn something about commutative algebras in passing.

Topics I hope to fit in are:

Artinian algebras. Examples, group algebras of finite groups, crossed products. Structure theory. Artin-Wedderburn theorem. Projective modules. Blocks.

Noetherian algebras. Examples, quantum plane and quantum torus, differential operator algebras, enveloping algebras of finite dimensional Lie algebras. Structure theory. Injective hulls, uniform dimension and Goldie's theorem.

Hochschild chain and cochain complexes. Hochschild homology and cohomology. Gerstenhaber algebras.

$K_0$ and $K_1$.

Deformation of algebras. Quantum co-ordinate algebras and quantum enveloping algebras.

Coalgebras, bialgebras and Hopf algebras. Quantum groups.

\subsubsection*{Pre-requisites}
It will be assumed that you have attended a first course on ring theory, eg IB Groups, Rings and Modules. Experience of other algebraic courses such as II Representation Theory, Galois Theory or Number Fields, or III Lie algebras will be helpful but not necessary.
}
\tableofcontents

\setcounter{section}{-1}
\section{Introduction}
We start with the definition of an algebra. Throughout the course, $k$ will be a field.
\begin{defi}[$k$-algebra]\index{$k$-algebra}\index{algebra}
  A (unital) associative $k$-algebra is a $k$-vector space $A$ together with an associative product $m: A \times A \to A$, written $(x, y) \mapsto xy$, which is $k$-bilinear, and a $k$-linear map $u: k \to A$ such that $u(1)$ is the identity of the multiplication of $A$.
\end{defi}
We will mostly talk about $k$-algebras, but other algebraic structures will appear, eg. Lie algebras.

\begin{eg}
  Let $K/k$ be a finite field extension. Then $K$ is a $k$-algebra.
\end{eg}

\begin{eg}
  The $n\times n$ matrices $M_n(k)$ over $k$ are non-commutative $k$-algebras.
\end{eg}

\begin{eg}
  The quaternions $\H$ is an $\R$-algebra, with an $\R$-basis $1, i, j, k$, and multiplication given by
  \[
    i^2 = j^2 = k^2 = 1,\quad ij = k,\quad ji = -k.
  \]
  This is in fact a \term{division algebra} (or \term{skew fields}), ie. the non-zero elements have multiplicative inverse.
\end{eg}

\begin{eg}
  Let $G$ be a finite group. Then the group algebra $kG$ is a $k$-algebra. These are the associative algebras underlying the representation theory of finite groups.
\end{eg}

\begin{defi}[Ideal]\index{ideal}
  A \emph{left ideal} of $A$ is a $k$-subspace of $A$ such that if $x \in A$ and $y \in I$, then $xy \in I$.
\end{defi}
We can similarly define a right ideal. Since the multiplication is not necessarily commutative, we have to make the distinction between left and right things. Most of the time, we just talk about the left case, as the other case is entirely analogous.

First of all, we'll think about algebras that are finite-dimensional as $k$-vector spaces, but in fact we can be slightly more general than that.
\begin{defi}[Artinian algebra]\index{Artinian algebra}\index{algebra!Artinian}
  An algebra $A$ is \emph{left Artinian} if it satisfies the \term{descending chain condition} (\term{DCC}) on left ideals, ie. if we have a descending chain of left ideals
  \[
    I_1 \geq I_2 \geq I_3 \geq \cdots,
  \]
  then there is some $N$ such that $I_{N + m} = I_{N}$ for all $m \geq 0$.

  We say an algebra is \emph{Artinian} if it is both left and right Artinian.
\end{defi}

\begin{eg}
  Any finite-dimensional algebra is Artinian.
\end{eg}

We'll prove the Artin-Wedderburn theorem:
\begin{thm}[Artin-Wedderburn theorem]\index{Artin-Wedderburn theorem}
  Let $A$ be a left-Artinian algebra such that the intersection of the maximal left ideals is zero, then $A$ is the direct sum of finitely many matrix algebras over division algebras.
\end{thm}
We will later give a better characterization of the second requirement. This theorem is useful for representation theory, where we apply this to the study of group algebras.

After studying Artinian rings, we'll talk about Noetherian algebras.
\begin{defi}[Noetherian algebra]\index{Noetherian algebra}\index{algebra!Noetherian}
  An algebra is \emph{left Noetherian} if it satisfies the \term{ascending chain condition} (\term{ACC}) on left ideals, ie. if
  \[
    I_1 \leq I_2 \leq I_3 \leq \cdots
  \]
  is an ascending chain of left ideals, then there is some $N$ such that $I_{N + m} = I_N$ for all $m \geq 0$.

  Similarly,, we say an algebra is \emph{Noetherian} if it is both left and right Noetherian.
\end{defi}

\begin{eg}
  Again all finite-dimensional algebras are Noetherian.
\end{eg}

\begin{eg}
  In the commutative case, Hilbert's basis theorem tells us a polynomial algebra $k[X_1, \cdots, X_k]$ in finitely many variables is Noetherian. Similarly, the power series rings $k[[X_1, \cdots, X_n]]$ are Noetherian.
\end{eg}

\begin{eg}
  The \term{universal enveloping algebra} of a finite-dimensional Lie algebra are the (associative!) algebras that underpin the representation theory of these Lie algebras.
\end{eg}

\begin{eg}
  Some differential operator algebras are Noetherian. We assume $\Char k = 0$. Consider the polynomial ring $k[X]$. We have operators ``multiplication by $X$'' and ``differentiate with respect to $X$'' on $k[X]$. We can form the algebra $k[X, \frac{\partial}{\partial x}]$ of differential operators on $k[X]$. This is called the \term{Weyl algebra} $A_1$. This is a non-commutative Noetherian algebra.
\end{eg}

\begin{eg}
  Some group algebras are Noetherian. Clearly all group algebras of finite groups are Noetherian, but the group algebras of certain infinite groups are Noetherian. For example, we can take
  \[
    G = \left\{
      \begin{pmatrix}
        1 & \lambda & \mu\\
        0 & 1 & \nu\\
        0 & 0 & 0
      \end{pmatrix}: \lambda, \mu, \nu \in \Z
    \right\}.
  \]
\end{eg}

We'll see that left Artinian implies left Noetherian. There is a general theory of Noetherian algebras, but is not as useful as that in commutative algebra.

In the commutative case, we often look at $\Spec A$, the set of prime ideals of $A$. However, sometimes in the non-commutative there are few prime ideals, and so $\Spec$ is not going to keep us busy.
\begin{eg}
  In the Weyl algebra $A_1$, the only prime ideals are $0$ and $A_1$.
\end{eg}

We will prove a theorem of Goldie:
\begin{thm}[Goldie's theorem]\index{Goldie's theorem}
  Let $A$ be a left Noetherian such that the intersection of prime ideals is zero. Then $A$ has a \term{full ring of quotients} which is the finite sum of matrix algebras over division algebras, where the full ring of quotients is what we obtain by adding inverses to everything that is not a zero divisor.
\end{thm}

Some types of Noetherian algebras can be thought of as non-commutative polynomial algebras and non-commutative power series, ie. they are \emph{deformations} of the analogous commutative algebra. For example, we say $A_1$ is a deformation of the polynomial algebra $k[X, Y]$, where instead of having $XY - YX = 0$, we have $XY - YX = 1$. This also applies to enveloping algebras and Iwasawa algebras. We study when one can deform the multiplication so that it remains associative, and this is bound up with the cohomology theory of associative algebras --- \emph{Hochschild cohomology}. The Hochschild complex has additional algebraic structure, and this will allow us to understand how we can deform the algebra.

If time remains, we'll talk about about bialgebras, Hopf algebras and quantum groups. In a bialgebra, one also has a comultiplication map $A \to A \otimes A$, which in representation theory is crucial in saying how to regard a tensor product of two representations as a representation.

We finish with a little bit of history. In 1890's, Hilbert proved some big theorems in complex polynomial algebras. In 1920's, Noether came and abstracted out the key properties that made Hilbert's work work, and came up with the notion of the Noetherian property. In 1930s and 1940s, the development of standard commutative algebra. In 1945 came Hochschild, and in 1960s came Goldie. In 1960 we had Gerstenhaber, who told us about the structure of the Hochschild complex. In the 1960s and 1970s, the study of enveloping algebras of differential operators started, and from the 1980s we started studying quantum groups, whose motivation came from mathematical physics, but got the algebraists excited.

\section{Artinian algebras}
We start with some general definitions. Recall the definitions of right and left Artinian algebras from the introduction. Most examples we'll meet are in fact finite-dimensional vector spaces over $k$. However, we can have some perverse examples.

\begin{eg}
  Let
  \[
    A = \left\{
      \begin{pmatrix}
        r & s\\
        0 & t
      \end{pmatrix}: r \in \Q, s, t \in \R
    \right\}
  \]
  Then this is left Artinian but not right Artinian.
\end{eg}

\begin{defi}[module]\index{module}
  Let $A$ be an algebra. A \emph{left $A$-module} is a $k$-vector space $M$ and a map
  \[
    \begin{tikzcd}[cdmap]
      A \times M \ar[r] & M\\
      (x, m) \ar[r, maps to] & xm
    \end{tikzcd}
  \]
  such that
  \begin{align*}
    (x + y)m &= xm + ym\\
    (xy)m &= x(ym).
  \end{align*}
  Right $A$-modules are defined similarly.
\end{defi}
\begin{eg}
  The algebra $A$ itself is a left $A$-module. We write this as $_A A$, and call this the \term{left regular representation}. Similarly, the right action is denoted $A_A$.
\end{eg}
Notice that with $_A A$, we have a $k$-algebra homomorphism $A \to \End_k(A)$, with $\End_k(A)$ denoting the $k$-linear maps $A \to A$. However, with the right action $A_A$, then we have $k$-algebra homomorphism $A \to \End_k(A)^{\op}$, where
\begin{defi}[Opposite algebra]\index{opposite algebra}\index{algebra!opposite}{$A^\op$}
  Let $A$ be a $k$-algebra. We define the \emph{opposite algebra} $A^\op$ where $A^\op$ has the same underlying vector space, but we define the multiplication
  \[
    x \cdot y = yx.
  \]
  Here on the left we have the multiplication in $A^\op$ and on the right we have the multiplication in $A$.
\end{defi}
In general, a left $A$-module is a right $A^\op$-module.

Since $A$ is both a left module and a right module, we say it is an \term{$A$-$A$-bimodule}. Notice that the two actions of $A$ commute, ie. $(xy)z = x(yz)$.

The (two-sided) ideals of $A$ are then the sub-bimodules of $A$.

\begin{defi}[Prime ideal]\index{prime ideal}\index{ideal!prime}
  An ideal $P$ is \emph{prime} if it is a proper ideal, and if $I$ and $J$ are ideals with $IJ \subseteq P$, then either $I \subseteq P$ or $J \subseteq P$.
\end{defi}
It is an exercise to check that this coincides in the commutative case with the definition using elements.

\begin{defi}[Annihilator]\index{annihilator}
  Let $M$ be a left $A$-module and $m \in M$. We define the \emph{annihilators} to be
  \begin{align*}
    \Ann(m) &= \{a \in A: am = 0\}\\
    \Ann(M) &= \{a \in A: am = 0\text{ for all }m \in M\} = \bigcap_{m \in M} \Ann(m).
  \end{align*}
\end{defi}
Note that $\Ann(m)$ is a left ideal of $A$, and is in fact the kernel of the $A$-module homomorphism $A \to M$ given by $x \mapsto xm$. We'll denote the image of this map by $Am$, a left submodule of $M$, and we have
\[
  \frac{A}{\Ann(m)} \cong Am.
\]
On the other hand, $\Ann(M)$ is an ideal --- it is the kernel of the obvious $k$-algebra homomorphism $A \to \End_k(M)$.

\begin{defi}[Simple module]\index{simple module}\index{irreducible module}\index{module!simple}\index{module!irreducible}
  A non-zero module $M$ is \emph{simple} or \emph{irreducible} if the only submodules of $M$ are $0$ and $M$.
\end{defi}
Note that $\Ann(m)$ is a maximal left ideal iff $Am$ is irreducible. More generally, an ideal $I$ is a maximal left ideal iff $A/I$ is simple. Note that maximal left ideals always exist if we're happy to use Zorn's lemma.

\begin{defi}[Jacobson radical]\index{Jacobson radical}\index{$J(A)$}
  The \index{Jacobson radical} $J(A)$ of $A$ is the intersection of all maximal left ideals.
\end{defi}
This is in fact an ideal, and not just a left one, because
\[
  J(A) = \bigcap \{\text{maximal left ideals}\} = \bigcap_{m \in M\text{ simple}} \Ann(m) = \bigcap_{M\text{ simple}} \Ann(M),
\]
which we have established is an ideal. However, it still looks as if this definition depends on the sidedness. However, we have the following result:
\begin{lemma}[Nakayama lemma]\index{Nakayama lemma}
  The following are equivalent for a left ideal $I$ of $A$.
  \begin{enumerate}
    \item $I < J(A)$
    \item For any finitely-generated left $A$-module $m$, we have $IM = M$ implies $M = 0$, where $IM$ is the module generated by elements of the form $xm$, with $x \in I$ and $m \in M$.
    \item $G = \{1 + x: x \in I\} = 1 + I$ is a subgroup of the unit group of $A$.
  \end{enumerate}
\end{lemma}
Note that this shows that the Jacobson radical is the largest ideal satisfying (iii), which is something that does not depend on handedness.

\begin{proof}\leavevmode
  \begin{itemize}
    \item (i) $\Rightarrow$ (ii): Suppose $I < J(A)$ and $M \not= 0$ is a finitely-generated $A$-module, and we'll see that $IM \lneq M$.

      Take a minimal generating set $m_1, \cdots, m_n$, say. If we form the submodule $M_{n - 1} = Am_1 + \cdots + A_{n - 1}$, then this is strictly contained in $M$. By Zorn's lemma, we can find a maximal proper submodule of $M$ containing $M_{n - 1}$, since such submodules are proper iff $m_n$ is not in the submodule. Then this gives us a maximal submodule of $M$.

      Let $N$ be one such maximal submodule. Then $M/N$ is a simple module, so for any $\bar{m} \in M/N$, we know $\Ann(\bar{m})$ is a maximal left ideal. So $J(A) \leq \Ann(M/N)$. So $J(A) N \leq N \lneq M$.
    \item (ii) $\Rightarrow$ (iii): Assume (ii). We let $x \in I$ and set $y = 1 + x$. Hence $1 = y - x \in Ay + I$. Since $Ay + I$ is a left ideal, we know $Ay + I = A$. In other words, we know
      \[
        I \left(\frac{A}{Ay}\right) = \frac{A}{Ay}.
      \]
      Now using $2$ on the finitely-generated module $A/Ay$ (it is in fact generated by $1$), we know that $A/Ay = 0$. So $A = Ay$. So there exists $z \in A$ such that $1 = zy = z(1 + x)$. So $(1 + x)$ has a left inverse, and in fact $z$ is in $G$, since we can write $z = 1 - zx$. This is enough to show that $G$ is a group.
    \item (iii) $\Rightarrow$ (i): Suppose $I$ is a maximal left ideal of $A$. Let $x \in I$. If $x \not \in I_1$, then $I_1 + Ax = A$ by maximality of $I$. So $1 = y + zx$ for some $y \in I$ and $z \in A$. So $y = 1 - zx \in G$. So $y$ is invertible. But $y \in I_1$. So $I_1 = A$. This is a contradiction. So we found that $I < I_1$, and this is true for all maximal left ideals $I_1$. Hence $I \leq J(A)$.
  \end{itemize}
\end{proof}

\begin{defi}[Semisimple algebra]\index{semisimple algebra}\index{algebra!semisimple}
  An algebra is \emph{semisimple} if $J(A) = 0$.
\end{defi}

\begin{eg}
  For any $A$, we know $A/J(A)$ is always semisimple.
\end{eg}
\printindex
\end{document}
