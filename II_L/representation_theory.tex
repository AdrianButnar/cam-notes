\documentclass[a4paper]{article}

\def\npart {II}
\def\nterm {Lent}
\def\nyear {2016}
\def\nlecturer {S. Martin}
\def\ncourse {Representation Theory}
\def\nlectures {TTS.9}
\def\nnotready {}

\input{header}

\begin{document}
\maketitle
{\small
\noindent\textbf{Representations of finite groups}\\
Representations of groups on vector spaces, matrix representations. Equivalence of representations. Invariant subspaces and submodules. Irreducibility and Schur's Lemma. Complete reducibility for finite groups. Irreducible representations of Abelian groups.

\vspace{10pt}
\noindent\textbf{Character theory}\\
Determination of a representation by its character. The group algebra, conjugacy classes, and orthogonality relations. Regular representation. Permutation representations and their characters. Induced representations and the Frobenius reciprocity theorem. Mackey's theorem. Frobenius's Theorem.\hspace*{\fill}[12]

\vspace{10pt}
\noindent\textbf{Arithmetic properties of characters}\\
Divisibility of the order of the group by the degrees of its irreducible characters. Burnside's $p^a q^b$ theorem.\hspace*{\fill}[2]

\vspace{10pt}
\noindent\textbf{Tensor products}\\
Tensor products of representations and products of characters. The character ring. Tensor, symmetric and exterior algebras.\hspace*{\fill}[3]

\vspace{10pt}
\noindent\textbf{Representations of $S^1$ and $SU_2$}\\
The groups $S^1$, $SU_2$ and $SO(3)$, their irreducible representations, complete reducibility. The Clebsch-Gordan formula. *Compact groups.*\hspace*{\fill}[4]

\vspace{10pt}
\noindent\textbf{Further worked examples}\\
The characters of one of $GL_2(F_q), S_n$ or the Heisenberg group.\hspace*{\fill}[3]}

\tableofcontents
\setcounter{section}{-1}
\section{Introduction}
The course studies how groups act as groups of linear transformations on vector spaces. Hopefully, you understand all the words in this sentence. If so, this is a good start.

In our case, groups are usually either finite groups or topological compact groups (to be defined later). Topological compact groups are typically subgroups of the general linear group over some infinite fields. It turns out the tools we have for finite groups often work well for these particular kinds of infinite groups. The vector spaces are always finite-dimensional, and usually over $\C$.

Prerequisites of this course include knowledge of group theory (as much as the IB Groups, Rings and Modules course), linear algebra, and, optionally, geometry, Galois theory and metric and topological spaces. There is one lemma where we must use something from Galois theory, but if you don't know about Galois theory, you can just assume the lemma to be true without bothering yourself too much about the proofs.

% C Curtis: pioneers of representation theory

\section{Group actions}

\subsection{Basic linear algebra}
We first set out our notations:

\begin{notation}
  $\F$ always represents a field.
\end{notation}

Usually, we take $\F = \C$, but sometimes it can also be $\R$ or $\Q$. These fields all have characteristic zero, and in this case, we call what we're doing \emph{ordinary} representation theory. Sometimes, we will take $F = \F_p$ or $\bar{\F}_p$, the algebraic closure of $\F_p$. This is called \emph{modular} representation theory.

\begin{notation}
  We write $V$ for a vector space over $\F$ --- this will always be finite dimensional over $\F$. We write $\GL(V)$ for the group of invertible linear maps $\theta: V \to V$. This is a group with the operation given by composition of maps, with the identity as the identity map (and inverse by inverse).
\end{notation}

\begin{notation}
  Let $V$ be a finite-dimensional vector space over $\F$. We write $\End(V)$ for the endomorphism algebra, the set of all linear maps $V \to V$.
\end{notation}

We recall a couple of facts from linear algebra:

If $\dim_\F V = n < \infty$, we can choose a basis $\mathbf{e}_1, \cdots, \mathbf{e}_n$ of $V$ over $\F$. So we can identify $V$ with $\F^n$. Then every endomorphism $\theta \in \GL(V)$ corresponds to a matrix $A_\theta = (a_{ij}) \in M_n(F)$ given by
\[
  \theta(\mathbf{e}_j) = \sum_i a_{ij} \mathbf{e}_i.
\]
In fact, we have $A_\theta \in \GL_n(\F)$, the general linear group. It is easy to see the following:
\begin{prop}
  As groups, $\GL(V) \cong \GL_n(\F)$, with the isomorphism given by $\theta \mapsto A_\theta$.
\end{prop}

Of course, picking a different basis of $V$ gives a different isomorphism to $\GL_n(\F)$, but we have the following fact:
\begin{prop}
  Matrices $A_1, A_2$ represent the same element of $\GL(V)$ with respect to different bases if and only if they are \emph{conjugate}, namely there is some $X \in \GL_n(\F)$ such that
  \[
    A_2 = XA_1 X^{-1}.
  \]
\end{prop}

Recall that $\tr(A) = \sum_i a_{ii}$, where $A = (a_{ij}) \in M_n(\F)$, is the trace of $A$. A nice property of the trace is that it doesn't notice conjugacy:
\begin{prop}
  \[
    \tr(XAX^{-1}) = \tr (A).
  \]
\end{prop}

Hence we can define the trace of an operator $\tr(\theta) = \tr(A_\theta)$, which is independent of our choice of basis. This is an important result. When we study representations, we will have matrices flying all over the place, and often we just look at the trace of these matrices. This reduces our problem of studying matrices to plain arithmetic.

When we have too many matrices, we get confused. So we want to put a matrix into a form as simple as possible. One of the simplest form a matrix can take is being diagonal. So we want to know something about diagonalizing matrices.

\begin{prop}
  Let $\alpha \in \GL(V)$, where $V$ is a finite-dimensional vector space over $\C$ and $\alpha^m = \id$ for some $m$. Then $\alpha$ is diagonalizable.
\end{prop}

\begin{prop}
  Let $V$ be a finite-dimensional vector space over $\C$, and $\alpha \in \End(V)$, not necessarily invertible. Then $\alpha$ is diagonalizable if and only if there is a polynomial $f$ with distinct linear factors with $f(\alpha) = 0$.
\end{prop}
This proposition allows us to prove the previous proposition immediately, noting that $X^m - 1 = \prod(X - \omega^j)$, where $\omega = e^{2\pi i/m}$.

Instead of just one endomorphism, we can look at many endomorphisms.

\begin{prop}
  A finite family of separately diagonalizable endomorphisms of a vector space over $\C$ can be simultaneously diagonalized if and only if they commute.
\end{prop}

\subsection{Basic group theory}
We start by listing all our favorite groups.

\begin{defi}[Symmetric group $S_n$]
  The \emph{symmetric group} $S_n$ is the set of all permutations of $X = \{1, \cdots, n\}$, ie. the set of all bijections $X \to X$. We have $|S_n| = n!$.
\end{defi}

\begin{defi}[Alternating group $A_n$]
  The \emph{alternating group} $A_n$ is the set of products of an even number of transpositions $(i\; j)$ in $S_n$. We know $|A_n| = \frac{n!}{2}$. So this is a subgroup of index 2 and hence normal.
\end{defi}

\begin{defi}[Cyclic group $C_m$]
  The \emph{cyclic group} of order $m$, written $C_m$ is
  \[
    C_m = \bra x: x^m = 1\ket.
  \]
  This also occurs naturally, as $\Z/m\Z$ over addition, and also the group of $n$th roots of unity in $\C$. We can view this as a subgroup of $\GL_1(\C) \cong \C^*$. Alternatively, this is the group of rotation symmetries of a regular $m$-gon in $\R^2$, and can be viewed as a subgroup of $\GL_2(\R)$.
\end{defi}

\begin{defi}[Dihedral group $D_{2m}$]
  The \emph{dihedral group} $D_{2m}$ of order $2m$ is
  \[
    D_{2m} = \bra x, y: x^m = y^2 = 1, yxy^{-1} = x^{-1}\ket.
  \]
  This is the symmetry group of a regular $m$-gon. The $x^i$ are the rotations and $x^i y$ are the reflections. For example, in $D_8$, $x$ is rotation by $\frac{\pi}{2}$ and $y$ is any reflection.

  This group can be viewed as a subgroup of $\GL_2(\R)$, but since it also acts on the vertices, it can be viewed as a subgroup of $S_m$.
\end{defi}

\begin{defi}[Quaternion group]
  The \emph{quaternion group} is given by
  \[
    Q_8 = \bra x, y: x^4 = 1, y^2 = x^2, yxy^{-1} = x^{-1}\ket.
  \]
  This has order $8$, and we write $i = x, j = y$, $k = ij$, $-1 = i^2$, with
  \[
    Q_8 = \{\pm 1, \pm i, \pm j, \pm k\}.
  \]
  We can view this as a subgroup of $\GL_2(\C)$ via
  \[
    1 = \begin{pmatrix}
      1&0\\0&1
    \end{pmatrix},\quad
    i = \begin{pmatrix}
      i & 0\\0&-i
    \end{pmatrix},\quad
    j = \begin{pmatrix}
      0&1\\-1&0
    \end{pmatrix},\quad
    k = \begin{pmatrix}
      0&i\\i&0
    \end{pmatrix}
  \]
\end{defi}

\begin{defi}[Conjugacy class]
  The \emph{conjugacy class} of $g \in G$ is
  \[
    \mathcal{C}_G(g)=\{xgx^{-1}: x \in G\}.
  \]
\end{defi}

\begin{defi}[Centralizer]
  The \emph{centralizer} of $g \in G$ is
  \[
    C_G(g) = \{x \in G: xg = gx\}.
  \]
\end{defi}
Then by the orbit-stabilizer theorem, we have $|\mathcal{C}_G(g)| = |G: C_G(G)|$.

\begin{defi}[Group action]
  Let $G$ be a group and $X$ a set. We say $G$ \emph{acts on} $X$ if there is a map $*: G \times X \to X$, written $(g, x) \mapsto g * x = gx$ such that
  \begin{enumerate}
    \item $1x = x$
    \item $g(hx) = (gh)x$
  \end{enumerate}
\end{defi}

The group action can also be characterised in terms of a homomorphism.
\begin{lemma}
  Given an action of $G$ on $X$, we obtain a homomorphism $\theta: G \to \Sym(X)$, where $\Sym(X)$ is the set of all permutations of $X$.
\end{lemma}

\begin{proof}
  For $g \in G$, define $\theta(g) = \theta_g \in \Sym (X)$ as the function $X \to X$ by $x \mapsto gx$. This is indeed a permutation of $X$ because $\theta_{g^{-1}}$ is an inverse.

  Moreover, for any $g_1, g_2 \in G$, we get $\theta_{g_1g_2} = \theta_{g_1} \theta_{g_2}$, since $(g_1g_2) x = g_1(g_2x)$.
\end{proof}

\begin{defi}[Permutation representation]
  The \emph{permutation representation} of a group action $G$ on $X$ is the homomorphism $\theta: G \to \Sym (X)$ obtained above.
\end{defi}

In this course, $X$ is often a finite-dimensional vector space over $F$, and we want the action to satisfy some more properties. We will require the action to be linear, ie. for all $g \in G$, $\mathbf{v}_1, \mathbf{v}_2 \in V$, and $\lambda \in \F$.
\[
  g(\mathbf{v}_1 + \mathbf{v}_2) = g \mathbf{v}_1 + g \mathbf{v}_2,\quad g(\lambda \mathbf{v}_1) = \lambda (g\mathbf{v}_1).
\]
\section{Basic definitions}
\subsection{Representations}
We finally get to something new. We will get some new definitions. As always, $G$ will be a finite group and $\F$ will be a field, usually $\C$.

\begin{defi}[Representation]
  Let $V$ be a finite-dimensional vector space over $\F$. A \emph{(linear) representation} of $G$ on $V$ is a group homomorphism
  \[
    \rho = \rho_V: G \to \GL(V).
  \]
  We sometimes write $\rho_g$ for $\rho_V(g)$, so for each $g \in G$, $\rho_g \in \GL(V)$, and $\rho_g \rho_h = \rho_{gh}$ and $\rho_{g^{-1}} = (\rho_g)^{-1}$ for all $g, h \in G$.
\end{defi}

\begin{defi}[Dimension or degree of representation]
  The \emph{dimension} (or \emph{degree}) of a representation $\rho: G \to \GL(V)$ is $\dim_\F(V)$.
\end{defi}

Recall that $\ker \rho \lhd G$ and $G/\ker \rho \cong \rho(G) \leq \GL(V)$. In the very special case where $\ker \rho$ is trivial, we give it a name:
\begin{defi}[Faithful representation]
  A \emph{faithful} representation is a representation $\rho$ such that $\ker \rho = 1$.
\end{defi}
These are the representations where the identity is the only element that does nothing.

An alternative (and of course equivalent) definition of a representation is to observe that a linear representation is ``the same'' as a linear action of $G$.
\begin{defi}[Linear action]
  A group $G$ \emph{acts linearly} on a vector space $V$ if it acts on $V$ such that
  \[
    g(\mathbf{v}_1 + \mathbf{v}_2) = g \mathbf{v}_1 + g \mathbf{v}_2,\quad g(\lambda \mathbf{v}_1) = \lambda (g\mathbf{v}_1)
  \]
  for all $g \in G$, $\mathbf{v}_1, \mathbf{v}_2 \in V$ and $\lambda \in \F$. We call this a \emph{linear action}.
\end{defi}
Now if $g$ acts linearly on $V$, the map $G \to \GL(V)$ defined by $g \mapsto \rho_g$, with $\rho_g: \mathbf{v} \mapsto g\mathbf{v}$, is a representation in the previous sense. Conversely, given a representation $\rho: G \to \GL(V)$, we have a linear action of $G$ on $V$ via $g\mathbf{v} = \rho(g) \mathbf{v}$.

In other words, a representation is just a linear action.

\begin{defi}[$G$-space/$G$-module]
  If there is a linear action $G$ on $V$, we say $V$ is a \emph{$G$-space} or \emph{$G$-module}.
\end{defi}

Alternatively, we can define the group action using the group algebra:
\begin{defi}[Group algebra]
  The \emph{group algebra} $\F G$ is defined to be the algebra (ie. a vector space with a bilinear multiplication operation) of formal sums
  \[
    \F G = \left\{ \sum_{g \in G} \alpha_g g: \alpha_g \in F\right\}
  \]
  with the obvious addition and multiplication.
\end{defi}
Then we can regard $\F G$ as a ring, and a $G$-space is just an $\F G$-module in the sense of IB Groups, Rings and Modules.

\begin{defi}[Matrix representation]
  $R$ is a \emph{matrix representation} of $G$ of degree $n$ if $R$ Is a homomorphism $G \to \GL_n(\F)$.
\end{defi}

Given a linear representation $\rho: G \to \GL(V)$ with $\dim V = n$, we can get a matrix representation by fixing a basis $\mathcal{B}$, and then define the matrix representation $G \to \GL_n(\F)$ by $g \mapsto [\rho(g)]_{\mathcal{B}}$.

Conversely, given a matrix representation $R$, we get a linear representation $\rho$ in the obvious way --- $\rho: G \to \GL(\F^n)$ by $g \mapsto \rho_g$ via $\rho_g(\mathbf{v}) = R_g \mathbf{v}$.

We have defined representations in four ways --- as a homomorphism to $\GL(V)$, as linear actions, as $\F G$-modules and as matrix representations. Now let's look at some examples.

\begin{eg}[Trivial representation]
  Given any group $G$, take $V = \F$ (the one-dimensional space), and $\rho: G \to \GL(V)$ by $g \mapsto (\id: \F \to \F)$ for all $g$. This is the \emph{trivial representation} of $G$, and has degree $1$.
\end{eg}
Despite being called trivial, trivial representations are highly non-trivial in representation theory. The way they interact with other representations geometrically, topologically etc, and cannot be disregarded. This is a very important representation, despite looking silly.

\begin{eg}
  Let $G = C_4 = \bra x: x^4 = 1\ket$. Let $n = 2$, and work over $\F = \C$. Then we can define a representation by $R: x \mapsto X$, and the action of other elements follows directly by $x^j \mapsto X^j$. Of course, we need $X^4 = I_2$. So we can take
  \begin{enumerate}
    \item $X$ diagonal: any choice of diagonal entries $\{\pm 1, \pm i\}$, in which we have $16$ choices; or
    \item $X$ is not diagonal: then it will be equivalent to a diagonal matrix since $X^4 = I_2$.
  \end{enumerate}
\end{eg}
What we would like to say above that any matrix representation in which $X$ is not diagonal is ``equivalent'' to one in which $X$ is. To make this notion precise, we need to define what it means for representations to be equivalent.

\begin{defi}[$G$-homomorphism/intertwine]
  Fix a group $G$ and a field $\F$. Let $V, V'$ be finite-dimensional vector spaces over $\F$ and $\rho: G \to \GL(V)$ and $\rho': G \to \GL(V')$ be representations of $G$. The linear map $\varphi: V \to V'$ is a \emph{$G$-homomorphism} if
  \[
    \varphi \circ \rho(g) = \rho'(g) \circ \varphi.\tag{$*$}
  \]
  In other words, the following diagram commutes:
  \[
    \begin{tikzcd}
      V \ar[r, "\rho_g"] \ar[d, "\varphi"] & V \ar[d, "\varphi"]\\
      V' \ar[r, "\rho_g'"] & V'
    \end{tikzcd}
  \]
  ie. no matter which way we go form $V$ (top left) to $V'$ (bottom right), we still get the same map.

  We say $\varphi$ \emph{intertwines} $\rho$ and $\rho'$. We write $\Hom_G(V, V')$ for the $\F$-space of all these maps.
\end{defi}

\begin{defi}[$G$-isomorphism]
  A $G$-homomorphism is a \emph{$G$-isomorphism} if $\varphi$ is bijective.
\end{defi}

\begin{defi}[Equivalent/isomorphic representations]
  Two representations $\rho, \rho'$ are \emph{equivalent} or \emph{isomorphic} if there is a $G$-isomorphism between them.
\end{defi}

If $\varphi$ is a $G$-isomorphism, then we can write $(*)$ as
\[
  \rho' = \varphi \rho \varphi^{-1}.\tag{$\dagger$}
\]
\begin{lemma}
  The relation of ``being isomorphic'' is an equivalence relation on the set of all linear representations of $G$ over $\F$.
\end{lemma}
This is an easy exercise left for the reader.

\begin{lemma}
  If $\rho, \rho'$ are isomorphic representations, then they have the same dimension.
\end{lemma}

\begin{proof}
  Trivial since isomorphisms between vector spaces preserve dimension.
\end{proof}

The converse is false.
\begin{eg}
  $C_4$ has four non-isomorphic one-dimensional representations: if $\omega = e^{2 \pi i/4}$, then we have the representations
  \[
    \rho_j (x^i) = \omega^{ij},
  \]
  for $0 \leq i \leq 3$.
\end{eg}
Note that given a group $G$, field $\F$, a vector space $V$ of dimension $n$, and a representation $\rho: G \to \GL(V)$, fix a basis $\mathcal{B}$ of $V$. Then we get a linear $G$-isomorphism $\varphi: V \to \F^n$ by $\mathbf{v} \mapsto [\mathbf{v}]_{\mathcal{B}}$, ie. by writing $\mathbf{v}$ as a column vector with respect to $\mathcal{B}$. Then we get a representation $\rho': G \to \GL(\F^n)$ isomorphic to $\rho$. In other words, every representation is isomorphic to a matrix representation.
\[
  \begin{tikzcd}
    V \ar[r, "\rho"] \ar[d, "\varphi"] & V \ar[d, "\varphi"]\\
    \F^n \ar[r, "\rho'"] & \F^n
  \end{tikzcd}
\]
This allows us to formulate equivalence in a different way. In terms of matrix representations, the representations $R: G \to \GL_n(\F)$ and $R': G \to \GL_n(\F)$ are $G$-isomorphic if there exists some non-singular matrix $X \in \GL_n(\F)$ such that
\[
  R'(g) = X R(g) X^{-1}
\]
for all $g$.

Alternatively, in terms of linear $G$-actions, the actions of $G$ on $V$ and $V'$ are $G$-isomorphic if there is some isomorphism $\varphi: V \to V'$ such that
\[
  g \varphi(\mathbf{v}) = \varphi(g\mathbf{v}).
\]
for all $g \in G, \mathbf{v} \in V$. It should be clear that this is just a reformulation of our previous definition.

\subsection{Subrepresentations}
\begin{defi}[$G$-subspace]
  Let $\rho: G \to \GL(V)$ be a representation of $G$. We say $W \leq V$ is a \emph{$G$-subspace} if it is a subspace that is $\rho(G)$-invariant, ie.
  \[
    \rho_g(W) \leq W
  \]
  for all $g \in G$.
\end{defi}

Obviously, $\{0\}$ and $V$ are $G$-subspaces. These are the trivial $G$-subspaces.

\begin{defi}[Irreducible/simple representation]
  A representation $\rho$ is \emph{irreducible} or \emph{simple} if there are no proper non-zero $G$-subspaces.
\end{defi}

\begin{eg}
  Any $1$-dimensional representation of $G$ is necessarily irreducible, but the converse does not hold, or else life would be very boring. We will later see that $D_8$ has a two-dimensional irreducible complex representation.
\end{eg}

\begin{defi}[Subrepresentation]
  If $W$ is a $G$-subspace, then the corresponding map $G \to \GL(W)$ given by $g \mapsto \rho(g)|_W$ gives us a new representation of $W$. This is a \emph{subrepresentation} of $\rho$.
\end{defi}

There is a nice way to characterize this in terms of matrices.
\begin{lemma}
  Let $\rho: G \to \GL(V)$ be a representation. If $W$ is a $G$-subspace of $V$. If $\mathcal{B} = \{\mathbf{v}_1, \cdots, \mathbf{v}_n\}$ is a basis containing a basis $\mathcal{B}_1 = \{\mathbf{v}_1, \cdots, \mathbf{v}_m\}$ of $W$ (with $0 < m < n$), then the matrix of $\rho(g)$ with respect to $\mathcal{B}$ has the block upper triangular form
  \[
    \begin{pmatrix}
      * & *\\
      0 & *
    \end{pmatrix}
  \]
  for each $g \in G$.
\end{lemma}
This follows directly from definition.

However, we do not like block triangular matrices. What we really like is block diagonal matrices, ie. we want the top-right block to vanish. In the next chapter, we will give conditions for when this can happen.

\begin{eg}
  Let $G = D_6$. Then every irreducible complex representation has dimension at most $2$.

  To show this, let $\rho: G \to \GL(V)$ be an irreducible $G$-representation. Let $r \in G$ be a (non-identity) rotation and $s\in G$ be a reflection. These generate $D_6$.

  Take an eigenvector $v$ of $\rho(r)$. So $\rho(r) v = \lambda v$ for some $\lambda \not= 0$ (since $\rho(r)$ is invertible, it cannot have zero eigenvalues). Let $W = \bra v, \rho(s) v\ket \leq V$ be the space spanned by the two vectors. We now check this is fixed by $\rho$. Firstly, we have
  \[
    \rho(s)\rho(s) \mathbf{v} = \rho(e) \mathbf{v} = \mathbf{v} \in W,
  \]
  and
  \[
    \rho(r)\rho(s) \mathbf{v} = \rho(s) \rho(r^{-1}) \mathbf{v} = \lambda^{-1} \rho(s) \mathbf{v} \in W.
  \]
  Also, $\rho(r) \mathbf{v} = \lambda \mathbf{v} \in W$ and $\rho(s) \mathbf{v} \in W$. So $W$ is $G$-invariant. Since $V$ is irreducible, we must have $W = V$. So $V$ has dimension at most $2$.
\end{eg}

We now have a definition similar to (ir)reducibility using direct sums.
\begin{defi}[(In)decomposable]
  A representation $\rho: G \to \GL(V)$ is \emph{decomposable} if there are proper $G$-invariant subspaces $U, W \leq V$ with
  \[
    V = U \oplus W.
  \]
  We say $\rho$ is a direct sum $\rho_u \oplus \rho_w$.

  If no such decomposition exists, we say that $\rho$ is indecomposable.
\end{defi}
It is clear that irreducibility implies indecomposability. The converse is not necessarily true. However, over a field of characteristic zero, it turns out irreducibility is the same as indecomposability, as we will later show.

Again, we can formulate this in terms of matrices.
\begin{lemma}
  Let $\rho: G \to \GL(V)$ be a decomposable representation with $G$-invariant decomposition $V = U \oplus W$. Let $\mathcal{B}_1 = \{\mathbf{u}_1, \cdots, \mathbf{u}_k\}$ and $\mathcal{B}_2 = \{\mathbf{w}_1, \cdots, \mathbf{w}_\ell\}$ be bases for $U$ and $W$, and $\mathcal{B} = \mathcal{B}_1 \cup \mathcal{B}_2$ be the corresponding basis for $V$. Then with respect to $\mathcal{B}$, we have
  \[
    [\rho(g)]_{\mathcal{B}} =
    \begin{pmatrix}
      [\rho_u(g)]_{\mathcal{B}_1} & 0\\
      0 & [\rho_u (g)]_{\mathcal{B}_2}
    \end{pmatrix}
  \]
\end{lemma}

The reverse operation of decomposition is taking direct sums.
\begin{defi}[Direct sum]
  Let $\rho: G\to \GL(V)$ and $\rho': G \to \GL(V')$ be representations of $G$. Then the \emph{direct sum} of $\rho, \rho'$ is the representation
  \[
    \rho \oplus \rho': G \to \GL(V \oplus V')
  \]
  given by
  \[
    (\rho \oplus \rho')(g)(\mathbf{v} + \mathbf{v}') = \rho(g) \mathbf{v} + \rho'(g) \mathbf{v}'.
  \]
\end{defi}
In terms of matrices, for matrix representations $R: G \to \GL_n(\F)$ and $R': G \to \GL_{n'}(\F)$, define $R \oplus R': G \to \GL_{n + n'}(\F)$ by
\[
  (R\oplus R') (g) =
  \begin{pmatrix}
    R(g) & 0\\
    0 & R'(g)
  \end{pmatrix}.
\]
The direct sum was easy to define. It turns out we can also multiply two representations, known as the tensor products. However, to do this, we need to know what the tensor product of two vector spaces is. We will not do this yet.

\section{Complete reducibility and Maschke's theorem}
\begin{defi}[Completely reducible/semisimple representation]
  A representation $\rho: G \to \GL(V)$ is \emph{completely reducible} or \emph{semisimple} if it is the direct sum of irreducible representations.
\end{defi}
Clearly, irreducible implies completely reducible.

On the other hand, not all representations are completely reducible. An example is to be found on example sheet 1. These are in fact not too hard to find. For example, there are representations of $\Z$ over $\C$ that are not completely reducible, and also a non-completely reducible representation of $C_p$ over $\F_p$.

However, it turns out we have the following theorem:
\begin{thm}
  Every finite-dimensional representation $V$ of a finite group over a field of characteristic $0$ is completely reducible, namely, $V \cong V_1 \oplus \cdots \oplus V_r$ is a direct sum of irreducible representations.
\end{thm}
By induction, it suffices to prove the following:
\begin{thm}[Maschke's theorem]
  Let $G$ be a finite group, and $\rho: G \to \GL(V)$ a representation over a finite-dimensional vector space $V$ over a field $\F $ with $\Char \F = 0$. If $W$ is a $G$-subspace of $V$, then there exists a $G$-subspace $U$ of $V$ such that $V = W \oplus U$.
\end{thm}

We will prove this many times
\begin{proof}
  From linear algebra, we know $W$ has a complementary sub\emph{space}. Let $W'$ be any vector subspace complement of $W$ in $V$, ie. $V = W \oplus W'$ \emph{as vector spaces}.

  Let $q: V \to W$ be the projection of $V$ onto $W$ along $W'$, ie. if $\mathbf{v} = \mathbf{w} + \mathbf{w}'$ with $\mathbf{w} \in W, \mathbf{w}' \in W'$, then $q(\mathbf{v}) = \mathbf{w}$.

  The clever bit is to take this $q$ and tweak it a little bit. Define
  \[
    \bar{q}: \mathbf{v} \mapsto \frac{1}{|G|} \sum_{g \in G} \rho(g) q (\rho(g^{-1})\mathbf{v}).
  \]
  This is in some sense an averaging operator, averaging over what $\rho(g)$ does. Here we need the field to have characteristic zero such that $\frac{1}{|G|}$ is well-defined. In fact, this theorem holds as long as $\Char F \nmid |G|$.

  For simplicity of expression, we drop the $\rho$'s, and simply write
  \[
    \bar{q}: \mathbf{v} \mapsto \frac{1}{|G|} \sum_{g \in G} g q (g^{-1}\mathbf{v}).
  \]
  We first claim that $\bar{q}$ has image in $W$. This is true since for $\mathbf{v} \in V$, $q(g^{-1} \mathbf{v}) \in W$, and $gW \leq W$. So this is a little bit like a projection.

  Next, we claim that for $\mathbf{w} \in W$, we have $\bar{q}(w) = w$. This follows from the fact that $q$ itself fixes $w$. We have
  \[
    \bar{q}(\mathbf{w}) = \frac{1}{|G|} \sum_{g \in G} g q(g^{-1}\mathbf{w}) = \frac{1}{|G|} \sum_{g \in G} gg^{-1}\mathbf{v} = \frac{1}{|G|} \sum_{g \in G}\mathbf{w} = \mathbf{w}.
  \]
  Putting these together, this tells us $\bar{q}$ is a projection onto $W$.

  Finally, we claim that for $h \in G$, we have $h \bar{q}(\mathbf{v}) = \bar{q}(h\mathbf{v})$, ie. it is invariant under the $G$-action. This follows easily from definition:
  \begin{align*}
    h \bar{q} (\mathbf{v}) &= h\frac{1}{|G|} \sum_{g \in G} g q (g^{-1}\mathbf{v})\\
    &= \frac{1}{|G|} \sum_{g \in G} hg q (g^{-1} \mathbf{v})\\
    &= \frac{1}{|G|} \sum_{g \in G} (hg) q ((hg)^{-1} h\mathbf{v})\\
    &= \frac{1}{|G|} \sum_{g' \in G} g' q(g'^{-1}(h\mathbf{v}))\\
    &= \bar{q} (h\mathbf{v}).
  \end{align*}
  We are pretty much done. We finally show that $\ker \bar{q}$ is $G$-invariant. If $\mathbf{v} \in \ker \bar{q}$ and $h \in G$, then $\bar{q}(h\mathbf{v}) = h\bar{q}(\mathbf{v}) = 0$. So $h\mathbf{v} \in \ker \bar{q}$.

  Thus
  \[
    V = \im \bar{q} \oplus \ker \bar{q} = W \oplus \ker\bar{q}
  \]
  is a $G$-subspace decomposition.
\end{proof}
The crux of the whole proof is the definition of $\bar{q}$. Once we have that, everything else follows easily.

Yet, for the whole proof to work, we need $\frac{1}{|G|}$ to exist, which in particular means $G$ must be a finite group. There is no obvious way to generalize this to infinite groups. So let's try a different proof.

The second proof uses inner products, and hence we must take $\F = \C$. This can be generalized to infinite compact groups, as we will later see.

Recall the definition of an inner product:
\begin{defi}[Hermitian inner product]
  For $V$ a complex space, $\bra\ph, \ph\ket$ is a \emph{Hermitian inner product} if
  \begin{enumerate}
    \item $\bra \mathbf{v}, \mathbf{w}\ket = \overline{\bra \mathbf{w}, \mathbf{v}\ket}$ \hfill (Hermitian)
    \item $\bra \mathbf{v}, \lambda_1 \mathbf{w}_1 + \lambda_2 \mathbf{w}_2\ket = \lambda_1 \bra \mathbf{v}, \mathbf{w}_1\ket + \lambda_2 \bra \mathbf{v}, \mathbf{w}_2\ket$ \hfill (sesquilinear)
    \item $\bra \mathbf{v}, \mathbf{v}\ket > 0$ if $\mathbf{v} \not= 0$\hfill (positive definite)
  \end{enumerate}
\end{defi}

\begin{defi}[$G$-invariant inner product]
  An inner product $\bra \ph, \ph \ket$ is in addition \emph{$G$-invariant} if
  \[
    \bra g\mathbf{v}, g\mathbf{w}\ket = \bra \mathbf{v}, \mathbf{w}\ket.
  \]
\end{defi}

\begin{prop}
  Let $W$ be $G$-invariant subspace of $V$, and $V$ have a $G$-invariant inner product. Then $W^\perp$ is also $G$-invariant.
\end{prop}

\begin{proof}
  To prove this, we have to show that for all $\mathbf{v} \in W^\perp$, $g \in G$, we have $g \mathbf{v} \in W^\perp$.

  This is not hard. We know $\mathbf{v} \in W^\perp$ if and only if $\bra \mathbf{v}, \mathbf{w}\ket = 0$ for all $\mathbf{w} \in W$. Thus, using the definition of $G$-invariance, for $\mathbf{v} \in W^\perp$, we know
  \[
    \bra g\mathbf{v}, g\mathbf{w}\ket = 0
  \]
  for all $g \in G, \mathbf{w}\in W$.

  Thus for all $\mathbf{w}' \in W$, pick $\mathbf{w} = g^{-1} \mathbf{w}' \in W$, and this shows $\bra g\mathbf{v}, \mathbf{w}'\ket = 0$. Hence $g\mathbf{v} \in W^\perp$.
\end{proof}

Hence if there is a $G$-invariant inner product on any complex $G$-space $V$, then we get another proof of Maschke's theorem.
\begin{thm}[Weyl's unitary trick]
  Let $\rho$ be a complex representation of a finite group $G$ on the complex vector space $V$. Then there is a $G$-invariant Hermitian inner product on $V$.
\end{thm}

Recall that the unitary group is defined by
\begin{align*}
  \U(V) &= \{f \in \GL(V): \bra f(\mathbf{u}), f(\mathbf{v})\ket = \bra \mathbf{u}, \mathbf{v}\ket \text{ for all }\mathbf{u}, \mathbf{v} \in V\}\\
  &= \{A \in \GL_n(\C): AA^\dagger = I\}\\
  &= \U(n).
\end{align*}
Then we have an easy corollary:
\begin{cor}
  Every finite subgroup of $\GL_n(\C)$ is conjugate to a subgroup of $\U(n)$.
\end{cor}
See also example sheet 1 question 12.

\begin{proof}
  We start by defining an arbitrary inner product on $V$: take a basis $\mathbf{e}_1, \cdots, \mathbf{e}_n$. Define $(\mathbf{e}_i, \mathbf{e}_j) = \delta_{ij}$, and extend it sesquilinearly. Define a new inner product
  \[
    \bra \mathbf{v}, \mathbf{w}\ket = \frac{1}{|G|} \sum_{g \in G} (g\mathbf{v}, g\mathbf{w}).
  \]
  We now check this is sesquilinear, positive-definite and $G$-invariant. Sesquilinearity and positive-definiteness are easy. So we just check $G$-invariance: we have
  \begin{align*}
    \bra h\mathbf{v}, h\mathbf{w}\ket &= \frac{1}{|G|} \sum_{g \in G} ((gh)\mathbf{v}, (gh)\mathbf{w})\\
    &= \frac{1}{|G|} \sum_{g' \in G} (g' \mathbf{v}, g' \mathbf{w})\\
    &= \bra \mathbf{v}, \mathbf{w}\ket.
  \end{align*}
\end{proof}
Again, we had to take the inverse $\frac{1}{|G|}$. To generalize this to compact groups, we will later replace the sum by an integral, and $\frac{1}{|G|}$ by a volume element. This is fine since $(g' \mathbf{v}, g'\mathbf{w})$ is a complex number and we know how to integrate complex numbers. This cannot be easily done in the case of $\bar{q}$.

Recall we defined the group algebra of $G$ to be the $F$-vector space
\[
  \F G = \bra \mathbf{e}_g: g \in G\ket,
\]
ie. its basis is in one-to-one correspondence with the elements of $G$. There is a linear $G$-action defined in the obvious way: for $h \in G$, we define
\[
  h \sum_g a_g \mathbf{e}_g = \sum_g a_g \mathbf{e}_{hg} = \sum_{g'} a_{h^{-1}g'} \mathbf{e}_{g'}.
\]
This gives a representation of $G$.
\begin{defi}[Regular representation and regular module]
  The \emph{regular representation} of a group $G$, written $\rho_{\mathrm{reg}}$, is the natural action of $G$ on $\F G$. $\F G$ is called the \emph{regular module}.
\end{defi}
It is a nice faithful representation of dimension $|G|$. Far more importantly, it turns out that \emph{every} irreducible representation of $G$ is a subrepresentation of the regular representation.
\begin{prop}
  Let $\rho$ be an irreducible representation of the finite group $G$ over a field of characteristic 0. Then $\rho$ is isomorphic to a subrepresentation of $\rho_{\mathrm{reg}}$
\end{prop}

\begin{proof}
  Take $\rho: G \to \GL(V)$ be irreducible, and pick our favorite $0 \not= \mathbf{v} \in V$. Now define $\theta: \F G \to V$ by
  \[
    \sum_g a_g \mathbf{e}_g \mapsto \sum a_g (g\mathbf{v}).
  \]
  It is not hard to see this is a $G$-homomorphism. We are now going to exploit the fact that $V$ is irreducible. Thus, since $\im \theta$ is a $G$-subspace of $V$ and non-zero, we must have $\im \theta = V$. Also, $\ker \theta$ is a $G$-subspace of $\F G$. Now let $W$ be the $G$-complement of $\ker \theta$ in $\F G$, which exists by Maschke's theorem. Then $W \leq \F G$ is a $G$-subspace and
  \[
    \F G = \ker \theta \oplus W.
  \]
  Then the isomorphism theorem gives
  \[
    W\cong \F G / \ker \theta \cong \im \theta = V.
  \]
\end{proof}
More generally, $G$ doesn't have to just act on the vector space generated by itself. If $G$ acts on any set, we can take that space and create a space acted on by $G$.
\begin{defi}[Permutation representation]
  Let $\F$ be a field, and let $G$ act on a set $X$. Let $\F X = \bra \mathbf{e}_x: x \in X\ket$ with a $G$-action given by
  \[
    g \sum_x a_x \mathbf{e}_x = \sum_x a_x \mathbf{e}_{gx}.
  \]
  So we have a $G$-space on $\F X$. The representation $G \to \GL(\F X)$ is the corresponding \emph{permutation representation}.
\end{defi}

\section{Schur's lemma}
\begin{thm}[Schur's lemma]\leavevmode
  \begin{enumerate}
    \item Assume $V$ and $W$ are irreducible $G$-spaces over a field $\F$. Then any $G$-homomorphism $\theta: V \to W$ is either zero or an isomorphism.
    \item If $\F$ is algebraically closed, and $V$ is an irreducible $G$-space, then any $G$-endomorphism $V \to V$ is a scalar multiple of the identity map $\iota_V$.
  \end{enumerate}
\end{thm}

\begin{proof}\leavevmode
  \begin{enumerate}
    \item Let $\theta: V \to W$ be a $G$-homomorphism between irreducibles. Then $\ker \theta$ is a $G$-subspace of $V$, and since $V$ is irreducible, either $\ker \theta = 0$ or $\ker \theta = V$. Similarly, $\im \theta$ is a $G$-subspace of $W$, and as $W$ is irreducible, we must have $\im \theta = 0$ or $\im \theta = W$. Hence either $\ker \theta = 0$, in which case $\theta = 0$, or $\ker \theta = 0$ and $\im \theta = W$, ie. $\theta$ is a bijection.
    \item Since $\F$ is algebraically closed, $\theta$ has an eigenvalue $\lambda$. Then $\theta - \lambda \iota_V$ is a singular $G$-endomorphism of $V$. So by (i), it must be the zero map. So $\theta = \lambda \iota_V$.
  \end{enumerate}
\end{proof}

Recall that the $\F$-space $\Hom_G(V, W)$ is the space of all $G$-homomorphisms $V \to W$. If $V = W$, we write $\End_G(V)$ for the $G$-endomorphisms of $V$.

\begin{cor}
  If $V, W$ are irreducible complex $G$-spaces, then
  \[
    \dim_\C \Hom_G(V, W) =
    \begin{cases}
      1 & V, W\text{ are $G$-isomorphic}\\
      0 & \text{otherwise}
    \end{cases}
  \]
\end{cor}

\begin{proof}
  If $V$ and $W$ are not isomorphic, then the only possible map between them is the zero map by Schur's lemma.

  Otherwise, suppose $V \cong W$ and let $\theta_1, \theta_2 \in \Hom_G(V, W)$ be both non-zero. By Schur's lemma, they are isomorphisms, and hence invertible. So $\theta_2^{-1}\theta_1 \in \End_G(V)$. Thus $\theta_2^{-1}\theta_1 = \lambda \iota_V$ for some $\lambda \in \C$. Thus $\theta_1 = \lambda \theta_2$.
\end{proof}

We have another less obvious corollary.
\begin{cor}
  If $G$ is a finite group and has a faithful complex irreducible representation, then its center $Z(G)$ is cyclic.
\end{cor}
This is a useful result --- it allows us transfer our representation-theoretic knowledge (the existence of a faithful complex irreducible representation) to group theoretic knowledge (center of group being cyclic). This will become increasingly common in the future, and is a good thing since representations are easy and groups are hard.

The converse, however, is not true. For this, see example sheet 1, question 10.
\begin{proof}
  Let $\rho: G \to \GL(V)$ be a faithful irreducible complex representation. Let $z \in \Z(G)$. So $zg = gz$ for all $g \in G$. Hence $\phi_z: \mathbf{v} \mapsto z\mathbf{v}$ is a $G$-endomorphism on $V$. Hence by Schur's lemma, it is multiplication by a scalar $\mu_z$, say. Thus $z\mathbf{v} = \mu_z \mathbf{v}$ for all $\mathbf{v}\in V$.

  Then the map
  \begin{align*}
    \sigma: Z(G) &\to \C^*\\
    z &\mapsto \mu_g
  \end{align*}
  is a representation of $\Z$. Since $\rho$ is faithful, so is $\sigma$. So $Z(G) = \{\mu_z: z \in Z(G)\}$ is isomorphic to a finite subgroup of $\C^*$, hence cyclic.
\end{proof}

\begin{cor}
  The irreducible complex representations of a finite abelian group $G$ are all $1$-dimensional.
\end{cor}

\begin{proof}
  We can either use the fact that commuting diagonalizable matrices are simultaneously diagonalizable. Thus for every irreducible $V$, we can pick some $\mathbf{v} \in V$ that is an eigenvector for each $g \in G$. Thus $\bra \mathbf{v}\ket$ is a $G$-subspace. As $V$ is irreducible, we must have $V = \bra \mathbf{v}\ket$.

  Alternatively, we can prove this in a representation-theoretic way. Let $V$ be an irreducible complex representation. For each $g \in G$, the map
  \begin{align*}
    \theta_g: V &\to V\\
    \mathbf{v} &\mapsto g\mathbf{v}
  \end{align*}
  is a $G$-endomorphism of $V$, since it commutes with the other group elements. Since $V$ is irreducible, $\theta_g = \lambda_g \iota_V$ for some $\lambda_g \in \C$. Thus
  \[
    g\mathbf{v} = \lambda_g \mathbf{v}
  \]
  for any $g$. As $V$ is irreducible, we must have $V = \bra \mathbf{v}\ket$.
\end{proof}
Note that this result fails over $\R$. For example, $C_3$ has a two irreducible real representations, one of dimension $1$ and one of dimension $2$.

We can do something else. Recall that every finite abelian group $G$ isomorphic to a product of abelian groups. In fact, it can be written as a product of $C_{p^\alpha}$ for various primes $p$ and $\alpha \geq 1$, and the factors are uniquely determined up to order.

This you already know from IB Groups Rings and Modules. You might be born knowing it --- it's such a fundamental fact of nature.

\begin{prop}
  The finite abelian group $G = C_{n_1} \times \cdots \times C_{n_r}$ has precisely $|G|$ irreducible representations over $\C$.
\end{prop}
This is not a coincidence. We will later show that the number of irreducible representations is the number of conjugacy classes of the group. In abelian groups, each conjugacy class is just a singleton, and hence this result.

\begin{proof}
  Write
  \[
    G = \bra x_1\ket \times \cdots \times \bra x_r\ket,
  \]
  where $|x_j| = n_j$. Any irreducible representation $\rho$ must be one-dimensional. So we have
  \[
    \rho: G \to \C^*.
  \]
  Let $\rho(1, \cdots, x_j, \cdots, 1) = \lambda_j$. Then since $\rho$ is a homomorphism, we must have $\lambda_j^{n_j} = 1$. Therefore $\lambda_j$ is an $n_j$th root of unity.

  Now the values $(\lambda_1, \cdots, \lambda_r)$ determine $\rho$ completely, namely
  \[
    \rho(x_1^{j_1}, \cdots, x_r^{j_r}) = \lambda_1^{j_1} \cdots \lambda_r ^{j_r}.
  \]
  Also, whenever $\lambda_i$ is an $n_i$th root of unity for each $i$, then the above formula gives a well-defined representation. So there is a one-to-one correspondence $\rho \leftrightarrow (\lambda_1, \cdots, \lambda_r)$, with $\lambda_j^{n_j} = 1$.

  Since for each $j$, there are $n_j$ many $n_j$th roots of unity, it follows that there are $|G| = n_1\cdots n_r$ many choices of the $\lambda_i$. Thus the proposition.
\end{proof}

\begin{eg}\leavevmode
  \begin{enumerate}
    \item Consider $G = C_4 \bra x\ket$. The four $1$-dimensional irreducible representations are given by
      \begin{center}
        \begin{tabular}{ccccc}
          \toprule
          & $1$ & $x$ & $x^2$ & $x^3$\\
          \midrule
          $\rho_1$ & $1$ & $1$ & $1$ & $1$\\
          $\rho_2$ & $1$ & $i$ & $-1$ & $-i$\\
          $\rho_2$ & $1$ & $-1$ & $1$ & $-1$\\
          $\rho_2$ & $1$ & $-i$ & $-1$ & $i$\\
          \bottomrule
        \end{tabular}
      \end{center}
    \item Consider the Klein four group $G = V_R = \bra x_1 \ket \times \bra x_2\ket$. The irreducible representations are
      \begin{center}
        \begin{tabular}{ccccc}
          \toprule
          & $1$ & $x_1$ & $x_2$ & $x_1x_2$\\
          \midrule
          $\rho_1$ & $1$ & $1$ & $1$ & $1$\\
          $\rho_2$ & $1$ & $1$ & $-1$ & $-1$\\
          $\rho_2$ & $1$ & $-1$ & $1$ & $-1$\\
          $\rho_2$ & $1$ & $-1$ & $-1$ & $1$\\
          \bottomrule
        \end{tabular}
      \end{center}
  \end{enumerate}
\end{eg}
These are also known as character tables, and we will spend quite a lot of time computing these for non-abelian groups.

Note that there is no ``natural'' one-to-one correspondence between the elements of $G$ and the representations of $G$ (for $G$ finite-abelian). If we choose an isomorphism $G \cong C_{n_1} \times \cdots C_{n_r}$, then we can identify the two sets, but it depends on the choice of the isomorphism (while the decomposition is unique, we can pick a different generator of, say, $C_{n_1}$ and get a different isomorphsim to the same decomposition).

\subsubsection*{Isotypical decompositions}
Recall that we proved we can decompose any $G$-representation into a product of irreducible representations. Is this decomposition unique? If it isn't, can we say anything about, say, the size of the irreducible representations, or the number of factors in the decomposition?

We know any diagonalizable endomorphism $\alpha: V \to V$ for a \emph{vector space} $V$ gives us a vector space decomposition
\[
  V = \bigoplus_{\lambda} V(\lambda),
\]
where
\[
  V(\lambda) = \{\mathbf{v} \in V: \alpha(\mathbf{v}) = \lambda \mathbf{v}\}.
\]
This is canonical in that it depends on $\alpha$ alone, and nothing else.

If $V$ is moreover a $G$-representation, how does this tie in to the decomposition of $V$ into the irreducible representations?

Let's do an example.
\begin{eg}
  Consider $G = D_6 \cong S_3 = \bra r, s: r^3 = s^2 = 1, rs = sr^{-1}\ket$. We have previously that each irreducible representation has dimension at most $2$. We spot at least three irreducible representations:
  \begin{center}
    \begin{tabular}{cccc}
      1 & triad & $r \mapsto 1$ & $s \mapsto 1$\\
      S & sign & $r \mapsto 1$ & $s \mapsto -1$\\
      W & $2$-dimensional &
    \end{tabular}
  \end{center}
  The last representation is the action of $D_6$ on $\R^2$ in the natural way. It is helpful to view this as a complex representation in order to make the matrix look nice. The $2$-dimensional representation $\rho, W$ is defined by $W = \C^2$, where $r$ and $s$ act on $W$ as
  \[
    \rho(r) =
    \begin{pmatrix}
      \omega & 0\\
      0 & \omega^2
    \end{pmatrix},\quad
    \rho(s) =
    \begin{pmatrix}
      0 & 1\\
      1 & 0
    \end{pmatrix},
  \]
  and $\omega = e^{2\pi i/3}$ is a third root of unity. We will soon show that these are indeed all the irreducible representations, by decomposing any representation into sum of these.

  Now let's decompose a random representation. Let $(\rho', V)$ be any complex representation of $G$. Since $\rho'(r)$ has order $3$, it is diagonalizable has eigenvalues $1, \omega, \omega^2$. We diagonalize $\rho'(r)$ and then $V$ splits as a vector space into the eigenspaces
  \[
    V = V(1) \oplus V(\omega) \oplus V(\omega^2).
  \]
  Since $srs^{-1}= r^{-1}$, we know $\rho'(s)$ preserves $V(1)$ and interchanges $V(\omega)$ and $V(\omega^2)$.

  Now we decompose $V(1)$ into $\rho'(s)$ eigenspaces, with eigenvalues $\pm1$. Since $r$ has to act trivially on these eigenspaces, $V(1)$ splits into sums of copies of the irreducible representations 1 and S.

  For the remaining mess, choose a basis $\mathbf{v}_1, \cdots, \mathbf{v}_n$ of $V(\omega)$, and let $\mathbf{v}_j' = \rho'(s) \mathbf{v}_j$. Then $\rho'(s)$ acts on the two-dimensional space $\bra \mathbf{v}_j, \mathbf{v}_j'\ket$ as $\begin{pmatrix}0 & 1\\1 & 0\end{pmatrix}$, while $\rho'(r)$ acts as $\begin{pmatrix} \omega & 0\\0 & \omega^2\end{pmatrix}$. This means $V(\omega) \oplus V(\omega^2)$ decomposes into many copies of W.
\end{eg}

How do we generalize this? We first have the following lemma:
\begin{lemma}
  Let $V, V_1, V_2$ be $G$ vector spaces over $F$. Then
  \begin{enumerate}
    \item $\Hom_G(V, V_1 \oplus V_2) \cong \Hom_G(V, V_1) \oplus \Hom_G(V, V_2)$
    \item $\Hom_G(V_1 \oplus V_2, V) \cong \Hom_G(V_1, V) \oplus \Hom_G(V_2, V)$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  The proof is to write down the obvious homomorphisms and inverses.

  Define the projection map
  \[
    \pi_i: V_1 \oplus V_2 \to V_i,
  \]
  which is the $G$-linear projection onto $V_i$. Then we can define the $G$-homomorphism
  \begin{align*}
    \Hom_G (V, V_1 \oplus V_2) &\mapsto \Hom_G(V, V_1) \oplus \Hom_G(V, V_2)\\
    \varphi &\mapsto (\pi_1 \varphi, \pi_2 \varphi).
  \end{align*}
  Then the map $(\psi_1, \psi_2) \mapsto \psi_1 + \psi_2$ is an inverse.

  For the second part, we have the homomorphism $\varphi \mapsto (\varphi|_{V_1}, \varphi|_{V_2})$ with inverse $(\psi_1, \psi_2) \mapsto \psi_1 \pi_1 + \psi_2 \pi_2$.
\end{proof}

\begin{lemma}
  Let $\F$ be an algebraically closed field, and $V$ be a representation of $G$. Suppose $V = \bigoplus_{i = 1}^n V_i$ is its decomposition into irreducible components. Then for each irreducible representation $S$ of $G$,
  \[
    |\{j: V_j \cong S\}| = \dim \Hom_G(S, V).
  \]
\end{lemma}
This tells us we can count the multiplicity of $S$ in $V$ by looking at the homomorphisms.

\begin{proof}
  We induct on $n$. If $n = 0$, then this is a trivial space. If $n = 1$, then $V$ itself is irreducible, and by Schur's lemma, $\dim \Hom_G(S, V) = 1$ if $V = S$, $0$ otherwise. Otherwise, for $n > 1$, we have
  \[
    V = \left(\bigoplus_{i = 1}^{n - 1} V_i\right) \oplus V_n.
  \]
  By the previous lemma, we know
  \[
    \dim \hom_G\left(S, \left(\bigoplus_{i = 1}^{n - 1} V_i\right) \oplus V_n\right) = \dim \Hom_G\left(S, \bigoplus_{i = 1}^{n - 1} V_i\right) + \dim \hom_G(S, V_n).
  \]
  The result then follows by induction.
\end{proof}

\begin{defi}[Canonical decomposition/decomposition into isotypical components]
  A decomposition of $V$ as $\bigoplus W_j$, where each $W_j$ is (isomorphic to) $n_j$ copies of the irreducible $S_j$ (with $S_j \not \cong S_i$ for $i \not= j$) is the \emph{canonical decomposition} or \emph{decomposition into isotypical components}.
\end{defi}
For an algebraically closed field $\F$, we know we must have
\[
  n_j = \dim \Hom_G(S_j, V),
\]
and hence this decomposition is well-defined.

We've finally all the introductory stuff. The course now begins.

\section{Character theory}
In topology, we want to classify spaces. To do so, we come up with invariants of spaces, like the number of holes. Then we know that a torus is not the same as a sphere. Here, we want to attach invariants to a representation $\rho$ of a finite group $G$ on $V$.

One thing we might want to do is to look at the matrix coefficients of $\rho(g)$. However, this is bad, since this is highly highly highly basis dependent. It is not a true invariant. We need to do something better than that.

Let $\F = \C$, and $G$ be a finite group. Let $\rho = \rho_V: G \to \GL(V)$ be a representation of $G$. The clue is to look at the characteristic polynomial of the matrix. The coefficients are functions of the eigenvalues --- on one extreme, the determinant is the product of all eigenvalues; on the other extreme, and the trace is the sum of all of them. Surprisingly, it is the trace that works. We don't have to bother ourselves with the other coefficients.

\begin{defi}[Character]
  The \emph{character} of a representation $\rho: G \to \GL(V)$, written $\chi_\rho = \chi_v = \chi$, is defined as
  \[
    \chi(g) = \tr \rho(g).
  \]
  Alternatively, it is $\tr R(g)$, where $R(g)$ is any matrix representing $\rho(g)$ with respect to any basis.
\end{defi}

\begin{defi}[Degree of character]
  The \emph{degree} of $\chi_v$ is $\dim V$.
\end{defi}

Thus, $\chi$ is a function $G \to \C$.
\begin{defi}[Linear character]
  We say $\chi$ is \emph{linear} if $\dim V = 1$, in which case $\chi$ is a homomorphism $G \to \C^* = \GL_1(\C)$.
\end{defi}

Various properties of representations are inherited by characters.
\begin{defi}[Irreducible/faithful character]
  A character $\chi$ is \emph{irreducible/faithful} if $\rho$ is \emph{irreducible/faithful}.
\end{defi}

\begin{defi}[Trivial/principal representation]
  A character $\chi$ is \emph{trivial} or \emph{principal} if $\rho$ is the trivial representation. We write $\chi = 1_G$.
\end{defi}

$\chi$ is a complete invariant in the sense that it determines $\rho$ up to isomorphism. This is staggering. This is a very simple function --- trace of a matrix, and it tells you all about the representation. We will prove this later.

We first prove some useful facts.
\begin{thm}\leavevmode
  \begin{enumerate}
    \item $\chi_V(1) = \dim V$.
    \item $\chi_V$ is a \emph{class function}, namely it is conjugation invariant, ie.
      \[
        \chi_V(hgh^{-1}) = \chi_V(g)
      \]
      for all $g, h \in G$. Thus $\chi_V$ is constant on conjugacy classes.
    \item $\chi_V(g^{-1}) = \overline{\chi_V(g)}$.
    \item For two representations $V, W$, we have
      \[
        \chi_{V \oplus W} = \chi_V + \chi_W.
      \]
  \end{enumerate}
\end{thm}
These results, despite being rather easy to prove, are very useful, since they save us a lot of work when computing the characters of representations

\begin{proof}\leavevmode
  \begin{enumerate}
    \item Obvious since $\chi_V(1) = \id_V$.
    \item Let $R_g$ be the matrix representing $g$. Then
      \[
        \chi(hgh^{-1}) = \tr(R_h R_g R_h^{-1}) = \tr(R_g) = \chi(g),
      \]
      as we know from linear algebra.
    \item Since $g \in G$ has finite order, we know $\rho(g)$ is represented by a diagonal matrix
      \[
        R_g =
        \begin{pmatrix}
          \lambda_1\\
          & \ddots\\
          && \lambda_n
        \end{pmatrix},
      \]
      and $\chi(g) = \sum \lambda_i$. Now $g^{-1}$ is represented by
      \[
        R_{g^{-1}} =
        \begin{pmatrix}
          \lambda_1^{-1}\\
          & \ddots\\
          && \lambda_n^{-1}
        \end{pmatrix},
      \]
      Noting that each $\lambda_i$ is an $n$th root of unity, hence $|\lambda_i| = 1$, we know
      \[
        \chi(g^{-1}) = \sum \lambda_i^{-1} = \sum \overline{\lambda_i} = \overline{\sum \lambda_i} = \overline{\chi(g)}.
      \]
    \item Suppose $V = V_1 \oplus V_2$, with $\rho: G \to \GL(V)$ splitting into $\rho_i: G \to \GL(V_i)$. Pick a basis $\mathcal{B}_i$ for $V_i$, and let $\mathcal{B} = B_1 \cup \mathcal{B}_2$. Then with respect to $\mathcal{B}$, we have
      \[
        [\rho(g)]_{\mathcal{B}} =
        \begin{pmatrix}
          [\rho_1(g)]_{\mathcal{B}_1} & 0\\
          0 & [\rho_2(g)]_{\mathcal{B}_2}
        \end{pmatrix}.
      \]
      So $\chi(g) = \tr(\rho(g)) = \tr(\rho_1(g)) + \tr(\rho_2(g)) = \chi_1(g) + \chi_2(g)$.
  \end{enumerate}
\end{proof}
\end{document}
