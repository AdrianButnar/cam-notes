\documentclass[a4paper]{article}

\def\npart {II}
\def\nterm {Lent}
\def\nyear {2016}
\def\nlecturer {S. Martin}
\def\ncourse {Representation Theory}
\def\nlectures {TTS.9}
\def\nnotready {}

\input{header}

\begin{document}
\maketitle
{\small
\noindent\textbf{Representations of finite groups}\\
Representations of groups on vector spaces, matrix representations. Equivalence of representations. Invariant subspaces and submodules. Irreducibility and Schur's Lemma. Complete reducibility for finite groups. Irreducible representations of Abelian groups.

\vspace{10pt}
\noindent\textbf{Character theory}\\
Determination of a representation by its character. The group algebra, conjugacy classes, and orthogonality relations. Regular representation. Permutation representations and their characters. Induced representations and the Frobenius reciprocity theorem. Mackey's theorem. Frobenius's Theorem.\hspace*{\fill}[12]

\vspace{10pt}
\noindent\textbf{Arithmetic properties of characters}\\
Divisibility of the order of the group by the degrees of its irreducible characters. Burnside's $p^a q^b$ theorem.\hspace*{\fill}[2]

\vspace{10pt}
\noindent\textbf{Tensor products}\\
Tensor products of representations and products of characters. The character ring. Tensor, symmetric and exterior algebras.\hspace*{\fill}[3]

\vspace{10pt}
\noindent\textbf{Representations of $S^1$ and $SU_2$}\\
The groups $S^1$, $\SU_2$ and $\SO(3)$, their irreducible representations, complete reducibility. The Clebsch-Gordan formula. *Compact groups.*\hspace*{\fill}[4]

\vspace{10pt}
\noindent\textbf{Further worked examples}\\
The characters of one of $\GL_2(F_q), S_n$ or the Heisenberg group.\hspace*{\fill}[3]}

\tableofcontents
\setcounter{section}{-1}
\section{Introduction}
The course studies how groups act as groups of linear transformations on vector spaces. Hopefully, you understand all the words in this sentence. If so, this is a good start.

In our case, groups are usually either finite groups or topological compact groups (to be defined later). Topological compact groups are typically subgroups of the general linear group over some infinite fields. It turns out the tools we have for finite groups often work well for these particular kinds of infinite groups. The vector spaces are always finite-dimensional, and usually over $\C$.

Prerequisites of this course include knowledge of group theory (as much as the IB Groups, Rings and Modules course), linear algebra, and, optionally, geometry, Galois theory and metric and topological spaces. There is one lemma where we must use something from Galois theory, but if you don't know about Galois theory, you can just assume the lemma to be true without bothering yourself too much about the proofs.

% C Curtis: pioneers of representation theory

\section{Group actions}

\subsection{Basic linear algebra}
We first set out our notations:

\begin{notation}
  $\F$ always represents a field.
\end{notation}

Usually, we take $\F = \C$, but sometimes it can also be $\R$ or $\Q$. These fields all have characteristic zero, and in this case, we call what we're doing \emph{ordinary} representation theory. Sometimes, we will take $F = \F_p$ or $\bar{\F}_p$, the algebraic closure of $\F_p$. This is called \emph{modular} representation theory.

\begin{notation}
  We write $V$ for a vector space over $\F$ --- this will always be finite dimensional over $\F$. We write $\GL(V)$ for the group of invertible linear maps $\theta: V \to V$. This is a group with the operation given by composition of maps, with the identity as the identity map (and inverse by inverse).
\end{notation}

\begin{notation}
  Let $V$ be a finite-dimensional vector space over $\F$. We write $\End(V)$ for the endomorphism algebra, the set of all linear maps $V \to V$.
\end{notation}

We recall a couple of facts from linear algebra:

If $\dim_\F V = n < \infty$, we can choose a basis $\mathbf{e}_1, \cdots, \mathbf{e}_n$ of $V$ over $\F$. So we can identify $V$ with $\F^n$. Then every endomorphism $\theta \in \GL(V)$ corresponds to a matrix $A_\theta = (a_{ij}) \in M_n(F)$ given by
\[
  \theta(\mathbf{e}_j) = \sum_i a_{ij} \mathbf{e}_i.
\]
In fact, we have $A_\theta \in \GL_n(\F)$, the general linear group. It is easy to see the following:
\begin{prop}
  As groups, $\GL(V) \cong \GL_n(\F)$, with the isomorphism given by $\theta \mapsto A_\theta$.
\end{prop}

Of course, picking a different basis of $V$ gives a different isomorphism to $\GL_n(\F)$, but we have the following fact:
\begin{prop}
  Matrices $A_1, A_2$ represent the same element of $\GL(V)$ with respect to different bases if and only if they are \emph{conjugate}, namely there is some $X \in \GL_n(\F)$ such that
  \[
    A_2 = XA_1 X^{-1}.
  \]
\end{prop}

Recall that $\tr(A) = \sum_i a_{ii}$, where $A = (a_{ij}) \in M_n(\F)$, is the trace of $A$. A nice property of the trace is that it doesn't notice conjugacy:
\begin{prop}
  \[
    \tr(XAX^{-1}) = \tr (A).
  \]
\end{prop}

Hence we can define the trace of an operator $\tr(\theta) = \tr(A_\theta)$, which is independent of our choice of basis. This is an important result. When we study representations, we will have matrices flying all over the place, and often we just look at the trace of these matrices. This reduces our problem of studying matrices to plain arithmetic.

When we have too many matrices, we get confused. So we want to put a matrix into a form as simple as possible. One of the simplest form a matrix can take is being diagonal. So we want to know something about diagonalizing matrices.

\begin{prop}
  Let $\alpha \in \GL(V)$, where $V$ is a finite-dimensional vector space over $\C$ and $\alpha^m = \id$ for some $m$. Then $\alpha$ is diagonalizable.
\end{prop}

\begin{prop}
  Let $V$ be a finite-dimensional vector space over $\C$, and $\alpha \in \End(V)$, not necessarily invertible. Then $\alpha$ is diagonalizable if and only if there is a polynomial $f$ with distinct linear factors with $f(\alpha) = 0$.
\end{prop}
This proposition allows us to prove the previous proposition immediately, noting that $X^m - 1 = \prod(X - \omega^j)$, where $\omega = e^{2\pi i/m}$.

Instead of just one endomorphism, we can look at many endomorphisms.

\begin{prop}
  A finite family of separately diagonalizable endomorphisms of a vector space over $\C$ can be simultaneously diagonalized if and only if they commute.
\end{prop}

\subsection{Basic group theory}
We start by listing all our favorite groups.

\begin{defi}[Symmetric group $S_n$]
  The \emph{symmetric group} $S_n$ is the set of all permutations of $X = \{1, \cdots, n\}$, ie. the set of all bijections $X \to X$. We have $|S_n| = n!$.
\end{defi}

\begin{defi}[Alternating group $A_n$]
  The \emph{alternating group} $A_n$ is the set of products of an even number of transpositions $(i\; j)$ in $S_n$. We know $|A_n| = \frac{n!}{2}$. So this is a subgroup of index 2 and hence normal.
\end{defi}

\begin{defi}[Cyclic group $C_m$]
  The \emph{cyclic group} of order $m$, written $C_m$ is
  \[
    C_m = \bra x: x^m = 1\ket.
  \]
  This also occurs naturally, as $\Z/m\Z$ over addition, and also the group of $n$th roots of unity in $\C$. We can view this as a subgroup of $\GL_1(\C) \cong \C^*$. Alternatively, this is the group of rotation symmetries of a regular $m$-gon in $\R^2$, and can be viewed as a subgroup of $\GL_2(\R)$.
\end{defi}

\begin{defi}[Dihedral group $D_{2m}$]
  The \emph{dihedral group} $D_{2m}$ of order $2m$ is
  \[
    D_{2m} = \bra x, y: x^m = y^2 = 1, yxy^{-1} = x^{-1}\ket.
  \]
  This is the symmetry group of a regular $m$-gon. The $x^i$ are the rotations and $x^i y$ are the reflections. For example, in $D_8$, $x$ is rotation by $\frac{\pi}{2}$ and $y$ is any reflection.

  This group can be viewed as a subgroup of $\GL_2(\R)$, but since it also acts on the vertices, it can be viewed as a subgroup of $S_m$.
\end{defi}

\begin{defi}[Quaternion group]
  The \emph{quaternion group} is given by
  \[
    Q_8 = \bra x, y: x^4 = 1, y^2 = x^2, yxy^{-1} = x^{-1}\ket.
  \]
  This has order $8$, and we write $i = x, j = y$, $k = ij$, $-1 = i^2$, with
  \[
    Q_8 = \{\pm 1, \pm i, \pm j, \pm k\}.
  \]
  We can view this as a subgroup of $\GL_2(\C)$ via
  \[
    1 = \begin{pmatrix}
      1&0\\0&1
    \end{pmatrix},\quad
    i = \begin{pmatrix}
      i & 0\\0&-i
    \end{pmatrix},\quad
    j = \begin{pmatrix}
      0&1\\-1&0
    \end{pmatrix},\quad
    k = \begin{pmatrix}
      0&i\\i&0
    \end{pmatrix}
  \]
\end{defi}

\begin{defi}[Conjugacy class]
  The \emph{conjugacy class} of $g \in G$ is
  \[
    \mathcal{C}_G(g)=\{xgx^{-1}: x \in G\}.
  \]
\end{defi}

\begin{defi}[Centralizer]
  The \emph{centralizer} of $g \in G$ is
  \[
    C_G(g) = \{x \in G: xg = gx\}.
  \]
\end{defi}
Then by the orbit-stabilizer theorem, we have $|\mathcal{C}_G(g)| = |G: C_G(G)|$.

\begin{defi}[Group action]
  Let $G$ be a group and $X$ a set. We say $G$ \emph{acts on} $X$ if there is a map $*: G \times X \to X$, written $(g, x) \mapsto g * x = gx$ such that
  \begin{enumerate}
    \item $1x = x$
    \item $g(hx) = (gh)x$
  \end{enumerate}
\end{defi}

The group action can also be characterised in terms of a homomorphism.
\begin{lemma}
  Given an action of $G$ on $X$, we obtain a homomorphism $\theta: G \to \Sym(X)$, where $\Sym(X)$ is the set of all permutations of $X$.
\end{lemma}

\begin{proof}
  For $g \in G$, define $\theta(g) = \theta_g \in \Sym (X)$ as the function $X \to X$ by $x \mapsto gx$. This is indeed a permutation of $X$ because $\theta_{g^{-1}}$ is an inverse.

  Moreover, for any $g_1, g_2 \in G$, we get $\theta_{g_1g_2} = \theta_{g_1} \theta_{g_2}$, since $(g_1g_2) x = g_1(g_2x)$.
\end{proof}

\begin{defi}[Permutation representation]
  The \emph{permutation representation} of a group action $G$ on $X$ is the homomorphism $\theta: G \to \Sym (X)$ obtained above.
\end{defi}

In this course, $X$ is often a finite-dimensional vector space over $F$, and we want the action to satisfy some more properties. We will require the action to be linear, ie. for all $g \in G$, $\mathbf{v}_1, \mathbf{v}_2 \in V$, and $\lambda \in \F$.
\[
  g(\mathbf{v}_1 + \mathbf{v}_2) = g \mathbf{v}_1 + g \mathbf{v}_2,\quad g(\lambda \mathbf{v}_1) = \lambda (g\mathbf{v}_1).
\]
\section{Basic definitions}
\subsection{Representations}
We finally get to something new. We will get some new definitions. As always, $G$ will be a finite group and $\F$ will be a field, usually $\C$.

\begin{defi}[Representation]
  Let $V$ be a finite-dimensional vector space over $\F$. A \emph{(linear) representation} of $G$ on $V$ is a group homomorphism
  \[
    \rho = \rho_V: G \to \GL(V).
  \]
  We sometimes write $\rho_g$ for $\rho_V(g)$, so for each $g \in G$, $\rho_g \in \GL(V)$, and $\rho_g \rho_h = \rho_{gh}$ and $\rho_{g^{-1}} = (\rho_g)^{-1}$ for all $g, h \in G$.
\end{defi}

\begin{defi}[Dimension or degree of representation]
  The \emph{dimension} (or \emph{degree}) of a representation $\rho: G \to \GL(V)$ is $\dim_\F(V)$.
\end{defi}

Recall that $\ker \rho \lhd G$ and $G/\ker \rho \cong \rho(G) \leq \GL(V)$. In the very special case where $\ker \rho$ is trivial, we give it a name:
\begin{defi}[Faithful representation]
  A \emph{faithful} representation is a representation $\rho$ such that $\ker \rho = 1$.
\end{defi}
These are the representations where the identity is the only element that does nothing.

An alternative (and of course equivalent) definition of a representation is to observe that a linear representation is ``the same'' as a linear action of $G$.
\begin{defi}[Linear action]
  A group $G$ \emph{acts linearly} on a vector space $V$ if it acts on $V$ such that
  \[
    g(\mathbf{v}_1 + \mathbf{v}_2) = g \mathbf{v}_1 + g \mathbf{v}_2,\quad g(\lambda \mathbf{v}_1) = \lambda (g\mathbf{v}_1)
  \]
  for all $g \in G$, $\mathbf{v}_1, \mathbf{v}_2 \in V$ and $\lambda \in \F$. We call this a \emph{linear action}.
\end{defi}
Now if $g$ acts linearly on $V$, the map $G \to \GL(V)$ defined by $g \mapsto \rho_g$, with $\rho_g: \mathbf{v} \mapsto g\mathbf{v}$, is a representation in the previous sense. Conversely, given a representation $\rho: G \to \GL(V)$, we have a linear action of $G$ on $V$ via $g\mathbf{v} = \rho(g) \mathbf{v}$.

In other words, a representation is just a linear action.

\begin{defi}[$G$-space/$G$-module]
  If there is a linear action $G$ on $V$, we say $V$ is a \emph{$G$-space} or \emph{$G$-module}.
\end{defi}

Alternatively, we can define the group action using the group algebra:
\begin{defi}[Group algebra]
  The \emph{group algebra} $\F G$ is defined to be the algebra (ie. a vector space with a bilinear multiplication operation) of formal sums
  \[
    \F G = \left\{ \sum_{g \in G} \alpha_g g: \alpha_g \in F\right\}
  \]
  with the obvious addition and multiplication.
\end{defi}
Then we can regard $\F G$ as a ring, and a $G$-space is just an $\F G$-module in the sense of IB Groups, Rings and Modules.

\begin{defi}[Matrix representation]
  $R$ is a \emph{matrix representation} of $G$ of degree $n$ if $R$ Is a homomorphism $G \to \GL_n(\F)$.
\end{defi}

Given a linear representation $\rho: G \to \GL(V)$ with $\dim V = n$, we can get a matrix representation by fixing a basis $\mathcal{B}$, and then define the matrix representation $G \to \GL_n(\F)$ by $g \mapsto [\rho(g)]_{\mathcal{B}}$.

Conversely, given a matrix representation $R$, we get a linear representation $\rho$ in the obvious way --- $\rho: G \to \GL(\F^n)$ by $g \mapsto \rho_g$ via $\rho_g(\mathbf{v}) = R_g \mathbf{v}$.

We have defined representations in four ways --- as a homomorphism to $\GL(V)$, as linear actions, as $\F G$-modules and as matrix representations. Now let's look at some examples.

\begin{eg}[Trivial representation]
  Given any group $G$, take $V = \F$ (the one-dimensional space), and $\rho: G \to \GL(V)$ by $g \mapsto (\id: \F \to \F)$ for all $g$. This is the \emph{trivial representation} of $G$, and has degree $1$.
\end{eg}
Despite being called trivial, trivial representations are highly non-trivial in representation theory. The way they interact with other representations geometrically, topologically etc, and cannot be disregarded. This is a very important representation, despite looking silly.

\begin{eg}
  Let $G = C_4 = \bra x: x^4 = 1\ket$. Let $n = 2$, and work over $\F = \C$. Then we can define a representation by $R: x \mapsto X$, and the action of other elements follows directly by $x^j \mapsto X^j$. Of course, we need $X^4 = I_2$. So we can take
  \begin{enumerate}
    \item $X$ diagonal: any choice of diagonal entries $\{\pm 1, \pm i\}$, in which we have $16$ choices; or
    \item $X$ is not diagonal: then it will be equivalent to a diagonal matrix since $X^4 = I_2$.
  \end{enumerate}
\end{eg}
What we would like to say above that any matrix representation in which $X$ is not diagonal is ``equivalent'' to one in which $X$ is. To make this notion precise, we need to define what it means for representations to be equivalent.

\begin{defi}[$G$-homomorphism/intertwine]
  Fix a group $G$ and a field $\F$. Let $V, V'$ be finite-dimensional vector spaces over $\F$ and $\rho: G \to \GL(V)$ and $\rho': G \to \GL(V')$ be representations of $G$. The linear map $\varphi: V \to V'$ is a \emph{$G$-homomorphism} if
  \[
    \varphi \circ \rho(g) = \rho'(g) \circ \varphi.\tag{$*$}
  \]
  In other words, the following diagram commutes:
  \[
    \begin{tikzcd}
      V \ar[r, "\rho_g"] \ar[d, "\varphi"] & V \ar[d, "\varphi"]\\
      V' \ar[r, "\rho_g'"] & V'
    \end{tikzcd}
  \]
  ie. no matter which way we go form $V$ (top left) to $V'$ (bottom right), we still get the same map.

  We say $\varphi$ \emph{intertwines} $\rho$ and $\rho'$. We write $\Hom_G(V, V')$ for the $\F$-space of all these maps.
\end{defi}

\begin{defi}[$G$-isomorphism]
  A $G$-homomorphism is a \emph{$G$-isomorphism} if $\varphi$ is bijective.
\end{defi}

\begin{defi}[Equivalent/isomorphic representations]
  Two representations $\rho, \rho'$ are \emph{equivalent} or \emph{isomorphic} if there is a $G$-isomorphism between them.
\end{defi}

If $\varphi$ is a $G$-isomorphism, then we can write $(*)$ as
\[
  \rho' = \varphi \rho \varphi^{-1}.\tag{$\dagger$}
\]
\begin{lemma}
  The relation of ``being isomorphic'' is an equivalence relation on the set of all linear representations of $G$ over $\F$.
\end{lemma}
This is an easy exercise left for the reader.

\begin{lemma}
  If $\rho, \rho'$ are isomorphic representations, then they have the same dimension.
\end{lemma}

\begin{proof}
  Trivial since isomorphisms between vector spaces preserve dimension.
\end{proof}

The converse is false.
\begin{eg}
  $C_4$ has four non-isomorphic one-dimensional representations: if $\omega = e^{2 \pi i/4}$, then we have the representations
  \[
    \rho_j (x^i) = \omega^{ij},
  \]
  for $0 \leq i \leq 3$.
\end{eg}
Note that given a group $G$, field $\F$, a vector space $V$ of dimension $n$, and a representation $\rho: G \to \GL(V)$, fix a basis $\mathcal{B}$ of $V$. Then we get a linear $G$-isomorphism $\varphi: V \to \F^n$ by $\mathbf{v} \mapsto [\mathbf{v}]_{\mathcal{B}}$, ie. by writing $\mathbf{v}$ as a column vector with respect to $\mathcal{B}$. Then we get a representation $\rho': G \to \GL(\F^n)$ isomorphic to $\rho$. In other words, every representation is isomorphic to a matrix representation.
\[
  \begin{tikzcd}
    V \ar[r, "\rho"] \ar[d, "\varphi"] & V \ar[d, "\varphi"]\\
    \F^n \ar[r, "\rho'"] & \F^n
  \end{tikzcd}
\]
This allows us to formulate equivalence in a different way. In terms of matrix representations, the representations $R: G \to \GL_n(\F)$ and $R': G \to \GL_n(\F)$ are $G$-isomorphic if there exists some non-singular matrix $X \in \GL_n(\F)$ such that
\[
  R'(g) = X R(g) X^{-1}
\]
for all $g$.

Alternatively, in terms of linear $G$-actions, the actions of $G$ on $V$ and $V'$ are $G$-isomorphic if there is some isomorphism $\varphi: V \to V'$ such that
\[
  g \varphi(\mathbf{v}) = \varphi(g\mathbf{v}).
\]
for all $g \in G, \mathbf{v} \in V$. It should be clear that this is just a reformulation of our previous definition.

\subsection{Subrepresentations}
\begin{defi}[$G$-subspace]
  Let $\rho: G \to \GL(V)$ be a representation of $G$. We say $W \leq V$ is a \emph{$G$-subspace} if it is a subspace that is $\rho(G)$-invariant, ie.
  \[
    \rho_g(W) \leq W
  \]
  for all $g \in G$.
\end{defi}

Obviously, $\{0\}$ and $V$ are $G$-subspaces. These are the trivial $G$-subspaces.

\begin{defi}[Irreducible/simple representation]
  A representation $\rho$ is \emph{irreducible} or \emph{simple} if there are no proper non-zero $G$-subspaces.
\end{defi}

\begin{eg}
  Any $1$-dimensional representation of $G$ is necessarily irreducible, but the converse does not hold, or else life would be very boring. We will later see that $D_8$ has a two-dimensional irreducible complex representation.
\end{eg}

\begin{defi}[Subrepresentation]
  If $W$ is a $G$-subspace, then the corresponding map $G \to \GL(W)$ given by $g \mapsto \rho(g)|_W$ gives us a new representation of $W$. This is a \emph{subrepresentation} of $\rho$.
\end{defi}

There is a nice way to characterize this in terms of matrices.
\begin{lemma}
  Let $\rho: G \to \GL(V)$ be a representation. If $W$ is a $G$-subspace of $V$. If $\mathcal{B} = \{\mathbf{v}_1, \cdots, \mathbf{v}_n\}$ is a basis containing a basis $\mathcal{B}_1 = \{\mathbf{v}_1, \cdots, \mathbf{v}_m\}$ of $W$ (with $0 < m < n$), then the matrix of $\rho(g)$ with respect to $\mathcal{B}$ has the block upper triangular form
  \[
    \begin{pmatrix}
      * & *\\
      0 & *
    \end{pmatrix}
  \]
  for each $g \in G$.
\end{lemma}
This follows directly from definition.

However, we do not like block triangular matrices. What we really like is block diagonal matrices, ie. we want the top-right block to vanish. In the next chapter, we will give conditions for when this can happen.

\begin{eg}
  Let $G = D_6$. Then every irreducible complex representation has dimension at most $2$.

  To show this, let $\rho: G \to \GL(V)$ be an irreducible $G$-representation. Let $r \in G$ be a (non-identity) rotation and $s\in G$ be a reflection. These generate $D_6$.

  Take an eigenvector $v$ of $\rho(r)$. So $\rho(r) v = \lambda v$ for some $\lambda \not= 0$ (since $\rho(r)$ is invertible, it cannot have zero eigenvalues). Let $W = \bra v, \rho(s) v\ket \leq V$ be the space spanned by the two vectors. We now check this is fixed by $\rho$. Firstly, we have
  \[
    \rho(s)\rho(s) \mathbf{v} = \rho(e) \mathbf{v} = \mathbf{v} \in W,
  \]
  and
  \[
    \rho(r)\rho(s) \mathbf{v} = \rho(s) \rho(r^{-1}) \mathbf{v} = \lambda^{-1} \rho(s) \mathbf{v} \in W.
  \]
  Also, $\rho(r) \mathbf{v} = \lambda \mathbf{v} \in W$ and $\rho(s) \mathbf{v} \in W$. So $W$ is $G$-invariant. Since $V$ is irreducible, we must have $W = V$. So $V$ has dimension at most $2$.
\end{eg}

We now have a definition similar to (ir)reducibility using direct sums.
\begin{defi}[(In)decomposable]
  A representation $\rho: G \to \GL(V)$ is \emph{decomposable} if there are proper $G$-invariant subspaces $U, W \leq V$ with
  \[
    V = U \oplus W.
  \]
  We say $\rho$ is a direct sum $\rho_u \oplus \rho_w$.

  If no such decomposition exists, we say that $\rho$ is indecomposable.
\end{defi}
It is clear that irreducibility implies indecomposability. The converse is not necessarily true. However, over a field of characteristic zero, it turns out irreducibility is the same as indecomposability, as we will later show.

Again, we can formulate this in terms of matrices.
\begin{lemma}
  Let $\rho: G \to \GL(V)$ be a decomposable representation with $G$-invariant decomposition $V = U \oplus W$. Let $\mathcal{B}_1 = \{\mathbf{u}_1, \cdots, \mathbf{u}_k\}$ and $\mathcal{B}_2 = \{\mathbf{w}_1, \cdots, \mathbf{w}_\ell\}$ be bases for $U$ and $W$, and $\mathcal{B} = \mathcal{B}_1 \cup \mathcal{B}_2$ be the corresponding basis for $V$. Then with respect to $\mathcal{B}$, we have
  \[
    [\rho(g)]_{\mathcal{B}} =
    \begin{pmatrix}
      [\rho_u(g)]_{\mathcal{B}_1} & 0\\
      0 & [\rho_u (g)]_{\mathcal{B}_2}
    \end{pmatrix}
  \]
\end{lemma}

The reverse operation of decomposition is taking direct sums.
\begin{defi}[Direct sum]
  Let $\rho: G\to \GL(V)$ and $\rho': G \to \GL(V')$ be representations of $G$. Then the \emph{direct sum} of $\rho, \rho'$ is the representation
  \[
    \rho \oplus \rho': G \to \GL(V \oplus V')
  \]
  given by
  \[
    (\rho \oplus \rho')(g)(\mathbf{v} + \mathbf{v}') = \rho(g) \mathbf{v} + \rho'(g) \mathbf{v}'.
  \]
\end{defi}
In terms of matrices, for matrix representations $R: G \to \GL_n(\F)$ and $R': G \to \GL_{n'}(\F)$, define $R \oplus R': G \to \GL_{n + n'}(\F)$ by
\[
  (R\oplus R') (g) =
  \begin{pmatrix}
    R(g) & 0\\
    0 & R'(g)
  \end{pmatrix}.
\]
The direct sum was easy to define. It turns out we can also multiply two representations, known as the tensor products. However, to do this, we need to know what the tensor product of two vector spaces is. We will not do this yet.

\section{Complete reducibility and Maschke's theorem}
\begin{defi}[Completely reducible/semisimple representation]
  A representation $\rho: G \to \GL(V)$ is \emph{completely reducible} or \emph{semisimple} if it is the direct sum of irreducible representations.
\end{defi}
Clearly, irreducible implies completely reducible.

On the other hand, not all representations are completely reducible. An example is to be found on example sheet 1. These are in fact not too hard to find. For example, there are representations of $\Z$ over $\C$ that are not completely reducible, and also a non-completely reducible representation of $C_p$ over $\F_p$.

However, it turns out we have the following theorem:
\begin{thm}
  Every finite-dimensional representation $V$ of a finite group over a field of characteristic $0$ is completely reducible, namely, $V \cong V_1 \oplus \cdots \oplus V_r$ is a direct sum of irreducible representations.
\end{thm}
By induction, it suffices to prove the following:
\begin{thm}[Maschke's theorem]
  Let $G$ be a finite group, and $\rho: G \to \GL(V)$ a representation over a finite-dimensional vector space $V$ over a field $\F $ with $\Char \F = 0$. If $W$ is a $G$-subspace of $V$, then there exists a $G$-subspace $U$ of $V$ such that $V = W \oplus U$.
\end{thm}

We will prove this many times
\begin{proof}
  From linear algebra, we know $W$ has a complementary sub\emph{space}. Let $W'$ be any vector subspace complement of $W$ in $V$, ie. $V = W \oplus W'$ \emph{as vector spaces}.

  Let $q: V \to W$ be the projection of $V$ onto $W$ along $W'$, ie. if $\mathbf{v} = \mathbf{w} + \mathbf{w}'$ with $\mathbf{w} \in W, \mathbf{w}' \in W'$, then $q(\mathbf{v}) = \mathbf{w}$.

  The clever bit is to take this $q$ and tweak it a little bit. Define
  \[
    \bar{q}: \mathbf{v} \mapsto \frac{1}{|G|} \sum_{g \in G} \rho(g) q (\rho(g^{-1})\mathbf{v}).
  \]
  This is in some sense an averaging operator, averaging over what $\rho(g)$ does. Here we need the field to have characteristic zero such that $\frac{1}{|G|}$ is well-defined. In fact, this theorem holds as long as $\Char F \nmid |G|$.

  For simplicity of expression, we drop the $\rho$'s, and simply write
  \[
    \bar{q}: \mathbf{v} \mapsto \frac{1}{|G|} \sum_{g \in G} g q (g^{-1}\mathbf{v}).
  \]
  We first claim that $\bar{q}$ has image in $W$. This is true since for $\mathbf{v} \in V$, $q(g^{-1} \mathbf{v}) \in W$, and $gW \leq W$. So this is a little bit like a projection.

  Next, we claim that for $\mathbf{w} \in W$, we have $\bar{q}(w) = w$. This follows from the fact that $q$ itself fixes $w$. We have
  \[
    \bar{q}(\mathbf{w}) = \frac{1}{|G|} \sum_{g \in G} g q(g^{-1}\mathbf{w}) = \frac{1}{|G|} \sum_{g \in G} gg^{-1}\mathbf{v} = \frac{1}{|G|} \sum_{g \in G}\mathbf{w} = \mathbf{w}.
  \]
  Putting these together, this tells us $\bar{q}$ is a projection onto $W$.

  Finally, we claim that for $h \in G$, we have $h \bar{q}(\mathbf{v}) = \bar{q}(h\mathbf{v})$, ie. it is invariant under the $G$-action. This follows easily from definition:
  \begin{align*}
    h \bar{q} (\mathbf{v}) &= h\frac{1}{|G|} \sum_{g \in G} g q (g^{-1}\mathbf{v})\\
    &= \frac{1}{|G|} \sum_{g \in G} hg q (g^{-1} \mathbf{v})\\
    &= \frac{1}{|G|} \sum_{g \in G} (hg) q ((hg)^{-1} h\mathbf{v})\\
    &= \frac{1}{|G|} \sum_{g' \in G} g' q(g'^{-1}(h\mathbf{v}))\\
    &= \bar{q} (h\mathbf{v}).
  \end{align*}
  We are pretty much done. We finally show that $\ker \bar{q}$ is $G$-invariant. If $\mathbf{v} \in \ker \bar{q}$ and $h \in G$, then $\bar{q}(h\mathbf{v}) = h\bar{q}(\mathbf{v}) = 0$. So $h\mathbf{v} \in \ker \bar{q}$.

  Thus
  \[
    V = \im \bar{q} \oplus \ker \bar{q} = W \oplus \ker\bar{q}
  \]
  is a $G$-subspace decomposition.
\end{proof}
The crux of the whole proof is the definition of $\bar{q}$. Once we have that, everything else follows easily.

Yet, for the whole proof to work, we need $\frac{1}{|G|}$ to exist, which in particular means $G$ must be a finite group. There is no obvious way to generalize this to infinite groups. So let's try a different proof.

The second proof uses inner products, and hence we must take $\F = \C$. This can be generalized to infinite compact groups, as we will later see.

Recall the definition of an inner product:
\begin{defi}[Hermitian inner product]
  For $V$ a complex space, $\bra\ph, \ph\ket$ is a \emph{Hermitian inner product} if
  \begin{enumerate}
    \item $\bra \mathbf{v}, \mathbf{w}\ket = \overline{\bra \mathbf{w}, \mathbf{v}\ket}$ \hfill (Hermitian)
    \item $\bra \mathbf{v}, \lambda_1 \mathbf{w}_1 + \lambda_2 \mathbf{w}_2\ket = \lambda_1 \bra \mathbf{v}, \mathbf{w}_1\ket + \lambda_2 \bra \mathbf{v}, \mathbf{w}_2\ket$ \hfill (sesquilinear)
    \item $\bra \mathbf{v}, \mathbf{v}\ket > 0$ if $\mathbf{v} \not= 0$\hfill (positive definite)
  \end{enumerate}
\end{defi}

\begin{defi}[$G$-invariant inner product]
  An inner product $\bra \ph, \ph \ket$ is in addition \emph{$G$-invariant} if
  \[
    \bra g\mathbf{v}, g\mathbf{w}\ket = \bra \mathbf{v}, \mathbf{w}\ket.
  \]
\end{defi}

\begin{prop}
  Let $W$ be $G$-invariant subspace of $V$, and $V$ have a $G$-invariant inner product. Then $W^\perp$ is also $G$-invariant.
\end{prop}

\begin{proof}
  To prove this, we have to show that for all $\mathbf{v} \in W^\perp$, $g \in G$, we have $g \mathbf{v} \in W^\perp$.

  This is not hard. We know $\mathbf{v} \in W^\perp$ if and only if $\bra \mathbf{v}, \mathbf{w}\ket = 0$ for all $\mathbf{w} \in W$. Thus, using the definition of $G$-invariance, for $\mathbf{v} \in W^\perp$, we know
  \[
    \bra g\mathbf{v}, g\mathbf{w}\ket = 0
  \]
  for all $g \in G, \mathbf{w}\in W$.

  Thus for all $\mathbf{w}' \in W$, pick $\mathbf{w} = g^{-1} \mathbf{w}' \in W$, and this shows $\bra g\mathbf{v}, \mathbf{w}'\ket = 0$. Hence $g\mathbf{v} \in W^\perp$.
\end{proof}

Hence if there is a $G$-invariant inner product on any complex $G$-space $V$, then we get another proof of Maschke's theorem.
\begin{thm}[Weyl's unitary trick]
  Let $\rho$ be a complex representation of a finite group $G$ on the complex vector space $V$. Then there is a $G$-invariant Hermitian inner product on $V$.
\end{thm}

Recall that the unitary group is defined by
\begin{align*}
  \U(V) &= \{f \in \GL(V): \bra f(\mathbf{u}), f(\mathbf{v})\ket = \bra \mathbf{u}, \mathbf{v}\ket \text{ for all }\mathbf{u}, \mathbf{v} \in V\}\\
  &= \{A \in \GL_n(\C): AA^\dagger = I\}\\
  &= \U(n).
\end{align*}
Then we have an easy corollary:
\begin{cor}
  Every finite subgroup of $\GL_n(\C)$ is conjugate to a subgroup of $\U(n)$.
\end{cor}
See also example sheet 1 question 12.

\begin{proof}
  We start by defining an arbitrary inner product on $V$: take a basis $\mathbf{e}_1, \cdots, \mathbf{e}_n$. Define $(\mathbf{e}_i, \mathbf{e}_j) = \delta_{ij}$, and extend it sesquilinearly. Define a new inner product
  \[
    \bra \mathbf{v}, \mathbf{w}\ket = \frac{1}{|G|} \sum_{g \in G} (g\mathbf{v}, g\mathbf{w}).
  \]
  We now check this is sesquilinear, positive-definite and $G$-invariant. Sesquilinearity and positive-definiteness are easy. So we just check $G$-invariance: we have
  \begin{align*}
    \bra h\mathbf{v}, h\mathbf{w}\ket &= \frac{1}{|G|} \sum_{g \in G} ((gh)\mathbf{v}, (gh)\mathbf{w})\\
    &= \frac{1}{|G|} \sum_{g' \in G} (g' \mathbf{v}, g' \mathbf{w})\\
    &= \bra \mathbf{v}, \mathbf{w}\ket.
  \end{align*}
\end{proof}
Again, we had to take the inverse $\frac{1}{|G|}$. To generalize this to compact groups, we will later replace the sum by an integral, and $\frac{1}{|G|}$ by a volume element. This is fine since $(g' \mathbf{v}, g'\mathbf{w})$ is a complex number and we know how to integrate complex numbers. This cannot be easily done in the case of $\bar{q}$.

Recall we defined the group algebra of $G$ to be the $F$-vector space
\[
  \F G = \bra \mathbf{e}_g: g \in G\ket,
\]
ie. its basis is in one-to-one correspondence with the elements of $G$. There is a linear $G$-action defined in the obvious way: for $h \in G$, we define
\[
  h \sum_g a_g \mathbf{e}_g = \sum_g a_g \mathbf{e}_{hg} = \sum_{g'} a_{h^{-1}g'} \mathbf{e}_{g'}.
\]
This gives a representation of $G$.
\begin{defi}[Regular representation and regular module]
  The \emph{regular representation} of a group $G$, written $\rho_{\mathrm{reg}}$, is the natural action of $G$ on $\F G$. $\F G$ is called the \emph{regular module}.
\end{defi}
It is a nice faithful representation of dimension $|G|$. Far more importantly, it turns out that \emph{every} irreducible representation of $G$ is a subrepresentation of the regular representation.
\begin{prop}
  Let $\rho$ be an irreducible representation of the finite group $G$ over a field of characteristic 0. Then $\rho$ is isomorphic to a subrepresentation of $\rho_{\mathrm{reg}}$
\end{prop}

\begin{proof}
  Take $\rho: G \to \GL(V)$ be irreducible, and pick our favorite $0 \not= \mathbf{v} \in V$. Now define $\theta: \F G \to V$ by
  \[
    \sum_g a_g \mathbf{e}_g \mapsto \sum a_g (g\mathbf{v}).
  \]
  It is not hard to see this is a $G$-homomorphism. We are now going to exploit the fact that $V$ is irreducible. Thus, since $\im \theta$ is a $G$-subspace of $V$ and non-zero, we must have $\im \theta = V$. Also, $\ker \theta$ is a $G$-subspace of $\F G$. Now let $W$ be the $G$-complement of $\ker \theta$ in $\F G$, which exists by Maschke's theorem. Then $W \leq \F G$ is a $G$-subspace and
  \[
    \F G = \ker \theta \oplus W.
  \]
  Then the isomorphism theorem gives
  \[
    W\cong \F G / \ker \theta \cong \im \theta = V.
  \]
\end{proof}
More generally, $G$ doesn't have to just act on the vector space generated by itself. If $G$ acts on any set, we can take that space and create a space acted on by $G$.
\begin{defi}[Permutation representation]
  Let $\F$ be a field, and let $G$ act on a set $X$. Let $\F X = \bra \mathbf{e}_x: x \in X\ket$ with a $G$-action given by
  \[
    g \sum_x a_x \mathbf{e}_x = \sum_x a_x \mathbf{e}_{gx}.
  \]
  So we have a $G$-space on $\F X$. The representation $G \to \GL(\F X)$ is the corresponding \emph{permutation representation}.
\end{defi}

\section{Schur's lemma}
\begin{thm}[Schur's lemma]\leavevmode
  \begin{enumerate}
    \item Assume $V$ and $W$ are irreducible $G$-spaces over a field $\F$. Then any $G$-homomorphism $\theta: V \to W$ is either zero or an isomorphism.
    \item If $\F$ is algebraically closed, and $V$ is an irreducible $G$-space, then any $G$-endomorphism $V \to V$ is a scalar multiple of the identity map $\iota_V$.
  \end{enumerate}
\end{thm}

\begin{proof}\leavevmode
  \begin{enumerate}
    \item Let $\theta: V \to W$ be a $G$-homomorphism between irreducibles. Then $\ker \theta$ is a $G$-subspace of $V$, and since $V$ is irreducible, either $\ker \theta = 0$ or $\ker \theta = V$. Similarly, $\im \theta$ is a $G$-subspace of $W$, and as $W$ is irreducible, we must have $\im \theta = 0$ or $\im \theta = W$. Hence either $\ker \theta = 0$, in which case $\theta = 0$, or $\ker \theta = 0$ and $\im \theta = W$, ie. $\theta$ is a bijection.
    \item Since $\F$ is algebraically closed, $\theta$ has an eigenvalue $\lambda$. Then $\theta - \lambda \iota_V$ is a singular $G$-endomorphism of $V$. So by (i), it must be the zero map. So $\theta = \lambda \iota_V$.
  \end{enumerate}
\end{proof}

Recall that the $\F$-space $\Hom_G(V, W)$ is the space of all $G$-homomorphisms $V \to W$. If $V = W$, we write $\End_G(V)$ for the $G$-endomorphisms of $V$.

\begin{cor}
  If $V, W$ are irreducible complex $G$-spaces, then
  \[
    \dim_\C \Hom_G(V, W) =
    \begin{cases}
      1 & V, W\text{ are $G$-isomorphic}\\
      0 & \text{otherwise}
    \end{cases}
  \]
\end{cor}

\begin{proof}
  If $V$ and $W$ are not isomorphic, then the only possible map between them is the zero map by Schur's lemma.

  Otherwise, suppose $V \cong W$ and let $\theta_1, \theta_2 \in \Hom_G(V, W)$ be both non-zero. By Schur's lemma, they are isomorphisms, and hence invertible. So $\theta_2^{-1}\theta_1 \in \End_G(V)$. Thus $\theta_2^{-1}\theta_1 = \lambda \iota_V$ for some $\lambda \in \C$. Thus $\theta_1 = \lambda \theta_2$.
\end{proof}

We have another less obvious corollary.
\begin{cor}
  If $G$ is a finite group and has a faithful complex irreducible representation, then its center $Z(G)$ is cyclic.
\end{cor}
This is a useful result --- it allows us transfer our representation-theoretic knowledge (the existence of a faithful complex irreducible representation) to group theoretic knowledge (center of group being cyclic). This will become increasingly common in the future, and is a good thing since representations are easy and groups are hard.

The converse, however, is not true. For this, see example sheet 1, question 10.
\begin{proof}
  Let $\rho: G \to \GL(V)$ be a faithful irreducible complex representation. Let $z \in \Z(G)$. So $zg = gz$ for all $g \in G$. Hence $\phi_z: \mathbf{v} \mapsto z\mathbf{v}$ is a $G$-endomorphism on $V$. Hence by Schur's lemma, it is multiplication by a scalar $\mu_z$, say. Thus $z\mathbf{v} = \mu_z \mathbf{v}$ for all $\mathbf{v}\in V$.

  Then the map
  \begin{align*}
    \sigma: Z(G) &\to \C^*\\
    z &\mapsto \mu_g
  \end{align*}
  is a representation of $\Z$. Since $\rho$ is faithful, so is $\sigma$. So $Z(G) = \{\mu_z: z \in Z(G)\}$ is isomorphic to a finite subgroup of $\C^*$, hence cyclic.
\end{proof}

\begin{cor}
  The irreducible complex representations of a finite abelian group $G$ are all $1$-dimensional.
\end{cor}

\begin{proof}
  We can either use the fact that commuting diagonalizable matrices are simultaneously diagonalizable. Thus for every irreducible $V$, we can pick some $\mathbf{v} \in V$ that is an eigenvector for each $g \in G$. Thus $\bra \mathbf{v}\ket$ is a $G$-subspace. As $V$ is irreducible, we must have $V = \bra \mathbf{v}\ket$.

  Alternatively, we can prove this in a representation-theoretic way. Let $V$ be an irreducible complex representation. For each $g \in G$, the map
  \begin{align*}
    \theta_g: V &\to V\\
    \mathbf{v} &\mapsto g\mathbf{v}
  \end{align*}
  is a $G$-endomorphism of $V$, since it commutes with the other group elements. Since $V$ is irreducible, $\theta_g = \lambda_g \iota_V$ for some $\lambda_g \in \C$. Thus
  \[
    g\mathbf{v} = \lambda_g \mathbf{v}
  \]
  for any $g$. As $V$ is irreducible, we must have $V = \bra \mathbf{v}\ket$.
\end{proof}
Note that this result fails over $\R$. For example, $C_3$ has a two irreducible real representations, one of dimension $1$ and one of dimension $2$.

We can do something else. Recall that every finite abelian group $G$ isomorphic to a product of abelian groups. In fact, it can be written as a product of $C_{p^\alpha}$ for various primes $p$ and $\alpha \geq 1$, and the factors are uniquely determined up to order.

This you already know from IB Groups Rings and Modules. You might be born knowing it --- it's such a fundamental fact of nature.

\begin{prop}
  The finite abelian group $G = C_{n_1} \times \cdots \times C_{n_r}$ has precisely $|G|$ irreducible representations over $\C$.
\end{prop}
This is not a coincidence. We will later show that the number of irreducible representations is the number of conjugacy classes of the group. In abelian groups, each conjugacy class is just a singleton, and hence this result.

\begin{proof}
  Write
  \[
    G = \bra x_1\ket \times \cdots \times \bra x_r\ket,
  \]
  where $|x_j| = n_j$. Any irreducible representation $\rho$ must be one-dimensional. So we have
  \[
    \rho: G \to \C^*.
  \]
  Let $\rho(1, \cdots, x_j, \cdots, 1) = \lambda_j$. Then since $\rho$ is a homomorphism, we must have $\lambda_j^{n_j} = 1$. Therefore $\lambda_j$ is an $n_j$th root of unity.

  Now the values $(\lambda_1, \cdots, \lambda_r)$ determine $\rho$ completely, namely
  \[
    \rho(x_1^{j_1}, \cdots, x_r^{j_r}) = \lambda_1^{j_1} \cdots \lambda_r ^{j_r}.
  \]
  Also, whenever $\lambda_i$ is an $n_i$th root of unity for each $i$, then the above formula gives a well-defined representation. So there is a one-to-one correspondence $\rho \leftrightarrow (\lambda_1, \cdots, \lambda_r)$, with $\lambda_j^{n_j} = 1$.

  Since for each $j$, there are $n_j$ many $n_j$th roots of unity, it follows that there are $|G| = n_1\cdots n_r$ many choices of the $\lambda_i$. Thus the proposition.
\end{proof}

\begin{eg}\leavevmode
  \begin{enumerate}
    \item Consider $G = C_4 \bra x\ket$. The four $1$-dimensional irreducible representations are given by
      \begin{center}
        \begin{tabular}{ccccc}
          \toprule
          & $1$ & $x$ & $x^2$ & $x^3$\\
          \midrule
          $\rho_1$ & $1$ & $1$ & $1$ & $1$\\
          $\rho_2$ & $1$ & $i$ & $-1$ & $-i$\\
          $\rho_2$ & $1$ & $-1$ & $1$ & $-1$\\
          $\rho_2$ & $1$ & $-i$ & $-1$ & $i$\\
          \bottomrule
        \end{tabular}
      \end{center}
    \item Consider the Klein four group $G = V_R = \bra x_1 \ket \times \bra x_2\ket$. The irreducible representations are
      \begin{center}
        \begin{tabular}{ccccc}
          \toprule
          & $1$ & $x_1$ & $x_2$ & $x_1x_2$\\
          \midrule
          $\rho_1$ & $1$ & $1$ & $1$ & $1$\\
          $\rho_2$ & $1$ & $1$ & $-1$ & $-1$\\
          $\rho_2$ & $1$ & $-1$ & $1$ & $-1$\\
          $\rho_2$ & $1$ & $-1$ & $-1$ & $1$\\
          \bottomrule
        \end{tabular}
      \end{center}
  \end{enumerate}
\end{eg}
These are also known as character tables, and we will spend quite a lot of time computing these for non-abelian groups.

Note that there is no ``natural'' one-to-one correspondence between the elements of $G$ and the representations of $G$ (for $G$ finite-abelian). If we choose an isomorphism $G \cong C_{n_1} \times \cdots C_{n_r}$, then we can identify the two sets, but it depends on the choice of the isomorphism (while the decomposition is unique, we can pick a different generator of, say, $C_{n_1}$ and get a different isomorphism to the same decomposition).

\subsubsection*{Isotypical decompositions}
Recall that we proved we can decompose any $G$-representation into a product of irreducible representations. Is this decomposition unique? If it isn't, can we say anything about, say, the size of the irreducible representations, or the number of factors in the decomposition?

We know any diagonalizable endomorphism $\alpha: V \to V$ for a \emph{vector space} $V$ gives us a vector space decomposition
\[
  V = \bigoplus_{\lambda} V(\lambda),
\]
where
\[
  V(\lambda) = \{\mathbf{v} \in V: \alpha(\mathbf{v}) = \lambda \mathbf{v}\}.
\]
This is canonical in that it depends on $\alpha$ alone, and nothing else.

If $V$ is moreover a $G$-representation, how does this tie in to the decomposition of $V$ into the irreducible representations?

Let's do an example.
\begin{eg}
  Consider $G = D_6 \cong S_3 = \bra r, s: r^3 = s^2 = 1, rs = sr^{-1}\ket$. We have previously that each irreducible representation has dimension at most $2$. We spot at least three irreducible representations:
  \begin{center}
    \begin{tabular}{cccc}
      1 & triad & $r \mapsto 1$ & $s \mapsto 1$\\
      S & sign & $r \mapsto 1$ & $s \mapsto -1$\\
      W & $2$-dimensional &
    \end{tabular}
  \end{center}
  The last representation is the action of $D_6$ on $\R^2$ in the natural way. It is helpful to view this as a complex representation in order to make the matrix look nice. The $2$-dimensional representation $\rho, W$ is defined by $W = \C^2$, where $r$ and $s$ act on $W$ as
  \[
    \rho(r) =
    \begin{pmatrix}
      \omega & 0\\
      0 & \omega^2
    \end{pmatrix},\quad
    \rho(s) =
    \begin{pmatrix}
      0 & 1\\
      1 & 0
    \end{pmatrix},
  \]
  and $\omega = e^{2\pi i/3}$ is a third root of unity. We will soon show that these are indeed all the irreducible representations, by decomposing any representation into sum of these.

  Now let's decompose a random representation. Let $(\rho', V)$ be any complex representation of $G$. Since $\rho'(r)$ has order $3$, it is diagonalizable has eigenvalues $1, \omega, \omega^2$. We diagonalize $\rho'(r)$ and then $V$ splits as a vector space into the eigenspaces
  \[
    V = V(1) \oplus V(\omega) \oplus V(\omega^2).
  \]
  Since $srs^{-1}= r^{-1}$, we know $\rho'(s)$ preserves $V(1)$ and interchanges $V(\omega)$ and $V(\omega^2)$.

  Now we decompose $V(1)$ into $\rho'(s)$ eigenspaces, with eigenvalues $\pm1$. Since $r$ has to act trivially on these eigenspaces, $V(1)$ splits into sums of copies of the irreducible representations 1 and S.

  For the remaining mess, choose a basis $\mathbf{v}_1, \cdots, \mathbf{v}_n$ of $V(\omega)$, and let $\mathbf{v}_j' = \rho'(s) \mathbf{v}_j$. Then $\rho'(s)$ acts on the two-dimensional space $\bra \mathbf{v}_j, \mathbf{v}_j'\ket$ as $\begin{pmatrix}0 & 1\\1 & 0\end{pmatrix}$, while $\rho'(r)$ acts as $\begin{pmatrix} \omega & 0\\0 & \omega^2\end{pmatrix}$. This means $V(\omega) \oplus V(\omega^2)$ decomposes into many copies of W.
\end{eg}

How do we generalize this? We first have the following lemma:
\begin{lemma}
  Let $V, V_1, V_2$ be $G$ vector spaces over $F$. Then
  \begin{enumerate}
    \item $\Hom_G(V, V_1 \oplus V_2) \cong \Hom_G(V, V_1) \oplus \Hom_G(V, V_2)$
    \item $\Hom_G(V_1 \oplus V_2, V) \cong \Hom_G(V_1, V) \oplus \Hom_G(V_2, V)$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  The proof is to write down the obvious homomorphisms and inverses.

  Define the projection map
  \[
    \pi_i: V_1 \oplus V_2 \to V_i,
  \]
  which is the $G$-linear projection onto $V_i$. Then we can define the $G$-homomorphism
  \begin{align*}
    \Hom_G (V, V_1 \oplus V_2) &\mapsto \Hom_G(V, V_1) \oplus \Hom_G(V, V_2)\\
    \varphi &\mapsto (\pi_1 \varphi, \pi_2 \varphi).
  \end{align*}
  Then the map $(\psi_1, \psi_2) \mapsto \psi_1 + \psi_2$ is an inverse.

  For the second part, we have the homomorphism $\varphi \mapsto (\varphi|_{V_1}, \varphi|_{V_2})$ with inverse $(\psi_1, \psi_2) \mapsto \psi_1 \pi_1 + \psi_2 \pi_2$.
\end{proof}

\begin{lemma}
  Let $\F$ be an algebraically closed field, and $V$ be a representation of $G$. Suppose $V = \bigoplus_{i = 1}^n V_i$ is its decomposition into irreducible components. Then for each irreducible representation $S$ of $G$,
  \[
    |\{j: V_j \cong S\}| = \dim \Hom_G(S, V).
  \]
\end{lemma}
This tells us we can count the multiplicity of $S$ in $V$ by looking at the homomorphisms.

\begin{proof}
  We induct on $n$. If $n = 0$, then this is a trivial space. If $n = 1$, then $V$ itself is irreducible, and by Schur's lemma, $\dim \Hom_G(S, V) = 1$ if $V = S$, $0$ otherwise. Otherwise, for $n > 1$, we have
  \[
    V = \left(\bigoplus_{i = 1}^{n - 1} V_i\right) \oplus V_n.
  \]
  By the previous lemma, we know
  \[
    \dim \hom_G\left(S, \left(\bigoplus_{i = 1}^{n - 1} V_i\right) \oplus V_n\right) = \dim \Hom_G\left(S, \bigoplus_{i = 1}^{n - 1} V_i\right) + \dim \hom_G(S, V_n).
  \]
  The result then follows by induction.
\end{proof}

\begin{defi}[Canonical decomposition/decomposition into isotypical components]
  A decomposition of $V$ as $\bigoplus W_j$, where each $W_j$ is (isomorphic to) $n_j$ copies of the irreducible $S_j$ (with $S_j \not \cong S_i$ for $i \not= j$) is the \emph{canonical decomposition} or \emph{decomposition into isotypical components}.
\end{defi}
For an algebraically closed field $\F$, we know we must have
\[
  n_j = \dim \Hom_G(S_j, V),
\]
and hence this decomposition is well-defined.

We've finally all the introductory stuff. The course now begins.

\section{Character theory}
In topology, we want to classify spaces. To do so, we come up with invariants of spaces, like the number of holes. Then we know that a torus is not the same as a sphere. Here, we want to attach invariants to a representation $\rho$ of a finite group $G$ on $V$.

One thing we might want to do is to look at the matrix coefficients of $\rho(g)$. However, this is bad, since this is highly highly highly basis dependent. It is not a true invariant. We need to do something better than that.

Let $\F = \C$, and $G$ be a finite group. Let $\rho = \rho_V: G \to \GL(V)$ be a representation of $G$. The clue is to look at the characteristic polynomial of the matrix. The coefficients are functions of the eigenvalues --- on one extreme, the determinant is the product of all eigenvalues; on the other extreme, and the trace is the sum of all of them. Surprisingly, it is the trace that works. We don't have to bother ourselves with the other coefficients.

\begin{defi}[Character]
  The \emph{character} of a representation $\rho: G \to \GL(V)$, written $\chi_\rho = \chi_v = \chi$, is defined as
  \[
    \chi(g) = \tr \rho(g).
  \]
  We say $\rho$ \emph{affords} the character $\chi$.

  Alternatively, the character is $\tr R(g)$, where $R(g)$ is any matrix representing $\rho(g)$ with respect to any basis.
\end{defi}

\begin{defi}[Degree of character]
  The \emph{degree} of $\chi_v$ is $\dim V$.
\end{defi}

Thus, $\chi$ is a function $G \to \C$.
\begin{defi}[Linear character]
  We say $\chi$ is \emph{linear} if $\dim V = 1$, in which case $\chi$ is a homomorphism $G \to \C^* = \GL_1(\C)$.
\end{defi}

Various properties of representations are inherited by characters.
\begin{defi}[Irreducible/faithful character]
  A character $\chi$ is \emph{irreducible/faithful} if $\rho$ is \emph{irreducible/faithful}.
\end{defi}

\begin{defi}[Trivial/principal representation]
  A character $\chi$ is \emph{trivial} or \emph{principal} if $\rho$ is the trivial representation. We write $\chi = 1_G$.
\end{defi}

$\chi$ is a complete invariant in the sense that it determines $\rho$ up to isomorphism. This is staggering. This is a very simple function --- trace of a matrix, and it tells you all about the representation. We will prove this later.

We first prove some useful facts.
\begin{thm}\leavevmode
  \begin{enumerate}
    \item $\chi_V(1) = \dim V$.
    \item $\chi_V$ is a \emph{class function}, namely it is conjugation invariant, ie.
      \[
        \chi_V(hgh^{-1}) = \chi_V(g)
      \]
      for all $g, h \in G$. Thus $\chi_V$ is constant on conjugacy classes.
    \item $\chi_V(g^{-1}) = \overline{\chi_V(g)}$.
    \item For two representations $V, W$, we have
      \[
        \chi_{V \oplus W} = \chi_V + \chi_W.
      \]
  \end{enumerate}
\end{thm}
These results, despite being rather easy to prove, are very useful, since they save us a lot of work when computing the characters of representations

\begin{proof}\leavevmode
  \begin{enumerate}
    \item Obvious since $\chi_V(1) = \id_V$.
    \item Let $R_g$ be the matrix representing $g$. Then
      \[
        \chi(hgh^{-1}) = \tr(R_h R_g R_h^{-1}) = \tr(R_g) = \chi(g),
      \]
      as we know from linear algebra.
    \item Since $g \in G$ has finite order, we know $\rho(g)$ is represented by a diagonal matrix
      \[
        R_g =
        \begin{pmatrix}
          \lambda_1\\
          & \ddots\\
          && \lambda_n
        \end{pmatrix},
      \]
      and $\chi(g) = \sum \lambda_i$. Now $g^{-1}$ is represented by
      \[
        R_{g^{-1}} =
        \begin{pmatrix}
          \lambda_1^{-1}\\
          & \ddots\\
          && \lambda_n^{-1}
        \end{pmatrix},
      \]
      Noting that each $\lambda_i$ is an $n$th root of unity, hence $|\lambda_i| = 1$, we know
      \[
        \chi(g^{-1}) = \sum \lambda_i^{-1} = \sum \overline{\lambda_i} = \overline{\sum \lambda_i} = \overline{\chi(g)}.
      \]
    \item Suppose $V = V_1 \oplus V_2$, with $\rho: G \to \GL(V)$ splitting into $\rho_i: G \to \GL(V_i)$. Pick a basis $\mathcal{B}_i$ for $V_i$, and let $\mathcal{B} = B_1 \cup \mathcal{B}_2$. Then with respect to $\mathcal{B}$, we have
      \[
        [\rho(g)]_{\mathcal{B}} =
        \begin{pmatrix}
          [\rho_1(g)]_{\mathcal{B}_1} & 0\\
          0 & [\rho_2(g)]_{\mathcal{B}_2}
        \end{pmatrix}.
      \]
      So $\chi(g) = \tr(\rho(g)) = \tr(\rho_1(g)) + \tr(\rho_2(g)) = \chi_1(g) + \chi_2(g)$.
  \end{enumerate}
\end{proof}
We will see later that if we take characters $\chi_1, \chi_2$ of $G$, then $\chi_1 \chi_2$ is also a character of $G$. This uses the notion of tensor products, which we will do later.

\begin{lemma}
  Let $\rho: G \to \GL(V)$ be a complex representation affording the character $\chi$. Then
  \[
    |\chi(g)| \leq \chi(1),
  \]
  with equality if and only if $\rho(g) = \lambda I$ for some $\lambda \in \C$, a root of unity. Moreover, $\chi(g) = \chi(1)$ if and only if $g \in \ker \rho$.
\end{lemma}

\begin{proof}
  Fix $g$, and pick a basis of eigenvectors of $\rho(g)$. Then the matrix of $\rho(g)$ is diagonal, say
  \[
    \rho(g) =
    \begin{pmatrix}
      \lambda_1\\
      & \ddots\\
      && \lambda_n
    \end{pmatrix},
  \]
  Hence
  \[
    |\chi(g)| = \left|\sum \lambda_i\right| \leq \sum |\lambda_i| = \sum 1 = \dim V = \chi(1).
  \]
  In the triangle inequality, we have equality if and only if all the $\lambda_i$'s are equal, to $\lambda$, say. So $\rho(g) = \lambda I$. Since all the $\lambda_i$'s are roots of unity, so is $\lambda$.

  And, if $\chi(g) = \chi(1)$, then since $\rho(g) = \lambda I$, taking the trace gives $\chi(g) = \lambda \chi(1)$. So $\lambda = 1$, ie. $\rho(g) = I$. So $g \in \ker \rho$.
\end{proof}

The following lemma allows us to generate new characters from old.
\begin{lemma}\leavevmode
  \begin{enumerate}
    \item If $\chi$ is a complex (irreducible) character of $G$, then so is $\bar{\chi}$.
    \item If $\chi$ is a complex (irreducible) character of $G$, then so is $\varepsilon \chi$ for any linear ($1$-dimensional) character $\varepsilon$.
  \end{enumerate}
\end{lemma}

\begin{proof}\leavevmode
  \begin{enumerate}
    \item If $R: G \to \GL_n(\C)$ is a complex matrix representation, then so is $\bar{R}: G \to \GL_n(\C)$, where $g \mapsto \overline{R(g)}$. Then the character of $\bar{R}$ is $\bar{\chi}$
    \item Similarly, $R': g \mapsto \varepsilon(g) R(g)$ for $g \in G$ is a representation with character $\varepsilon \chi$.
  \end{enumerate}
  It is left as an exercise for the reader to check the details.
\end{proof}

We now have to justify why we care about characters. We said it was a complete invariant, as in two representations are isomorphic if and only if they have the same character. Before we prove this, we first need some definitions
\begin{defi}[Space of class functions]
  Define the \emph{complex space of class functions} of $G$ to be
  \[
    \mathcal{C}(G) = \{f: G \to \C: f(hgh^{-1}) = f(g)\text{ for all }h, g \in G\}.
  \]
  This is a vector space by $f_1 + f_2 : g \mapsto f_1(g) + f_2(g)$ and $\lambda f: g \mapsto \lambda f(g)$.
\end{defi}

\begin{defi}[Class number]
  The \emph{class number} $k = k(G)$ is the number of conjugacy classes of $G$.
\end{defi}
We can list the conjugacy classes as $\mathcal{C}_1, \cdots, \mathcal{C}_k$. wlog, we let $\mathcal{C}_1 = \{1\}$. We choose $g_1, g_2, \cdots, g_k$ to be representatives of the conjugacy classes. Note also that $\dim \mathcal{C}(G) = k$, since the characteristic function $\delta_j$ of the classes form a basis where
\[
  \delta_j(g) =
  \begin{cases}
    1 & g \in \mathcal{C}_j\\
    0 & g \not\in \mathcal{C}_j.
  \end{cases}
\]
We define a Hermitian inner product on $\mathcal{C}(G)$ by
\begin{align*}
  \bra f, f'\ket &= \frac{1}{|G|} \sum_{g \in G}\overline{f(g)} f'(g) \\
  &= \frac{1}{|G|} \sum_{j = 1}^k |\mathcal{C}_j|\overline{f(g_j)} f'(g_j)\\
  \intertext{By the orbit stabilizer, we can write this as}
  &= \sum_{j = 1}^k \frac{1}{|C_G(g_j)|} \overline{f(g_j)} f'(g_j).
\end{align*}
In particular, for characters,
\[
  \bra \chi, \chi'\ket = \sum_{j = 1}^k \frac{1}{|C_G(g_j)|} \chi(g_j^{-1}) \chi'(g_j).
\]
It should be clear (especially using the original formula) that $\bra \chi, \chi'\ket = \bra \chi', \chi\ket$. So when restricted to characters, this is a real symmetric form.

The main result is the following theorem:
\begin{thm}[Completeness of characters]
  The complex irreducible characters of $G$ form an orthonormal basis of $\mathcal{C}(G)$, namely
  \begin{enumerate}
    \item If $\rho: G \to \GL(V)$ and $\rho': G \to \GL(V')$ are two complex irreducible representations affording characters $\chi, \chi'$ respectively, then
      \[
        \bra \chi, \chi'\ket =
        \begin{cases}
          1 & \text{if $\rho$ and $\rho'$ are isomorphic representations}\\
          0 & \text{otherwise}
        \end{cases}
      \]
      The is the (row) orthogonality of characters.
    \item Each class function of $G$ can be expressed as a linear combination of irreducible characters of $G$.
  \end{enumerate}
\end{thm}
Proof is deferred. We first look at some corollaries.
\begin{cor}
  Complex representations of finite groups are characterised by their characters.
\end{cor}

\begin{proof}
  Let $\rho: G \to \GL(V)$ afford the character $\chi$. We know we can write $\rho = m_1 \rho_1 \oplus \cdots \oplus m_k \rho_k$, where $\rho_1, \cdots, \rho_k$ are (distinct) irreducible and $m_j \geq 0$ are the multiplicities. Then we have
  \[
    \chi = m_1 \chi_1 + \cdots + m_k \chi_k,
  \]
  where $\chi_j$ is afforded by $\rho_j$. Then by orthogonality, we know
  \[
    m_j = \bra \chi, \chi_j\ket.
  \]
  So we can obtain the multiplicity of each $\rho_j$ in $\rho$ just by looking at the inner products of the characters.
\end{proof}
This is not true for infinite groups. For example, if $G = \Z$, then the representations
\[
  1 \mapsto
  \begin{pmatrix}
    1 & 0\\
    0 & 1
  \end{pmatrix},\quad
  1 \mapsto
  \begin{pmatrix}
    1 & 1\\
    0 & 1
  \end{pmatrix}
\]
are non-isomorphic, but have the same character $2$.

\begin{cor}[Irreducibility criterion]
  If $\rho: G \to \GL(V)$ is a complex representation of $G$ affording the character $\chi$, then $\rho$ is irreducible if and only if $\bra \chi, \chi \ket = 1$.
\end{cor}

\begin{proof}
  If $\rho$ is irreducible, then orthogonality says $\bra \chi, \chi \ket = 1$. For the other direction, suppose $\bra \chi, \chi\ket = 1$. We use complete reducibility to get
  \[
    \chi = \sum m_j \chi_j,
  \]
  with $\chi_j$ irreducible, and $m_j \geq 0$ the multiplicities. Then by orthogonality, we get
  \[
    \bra \chi, \chi\ket = \sum m_j^2.
  \]
  But $\bra \chi, \chi\ket = 1$. So exactly one of $m_j$ is $1$, while the others are all zero, and $\chi = \chi_j$. So $\chi$ is irreducible.
\end{proof}

\begin{thm}
  Let $\rho_1, \cdots, \rho_k$ be the irreducible complex representations of $G$, and let their dimensions be $n_1, \cdots, n_k$. Then
  \[
    |G| = \sum n_i^2.
  \]
\end{thm}
Recall that for abelian groups, each irreducible character has dimension $1$, and there are $|G|$ representations. So this is trivially satisfied.

\begin{proof}
  Recall that $\rho_{\mathrm{reg}}: G \to \GL(\C G)$, given by $G$ acting on itself by multiplication, is the regular representation of $G$ of dimension $|G|$. Let its character be $\pi_{\mathrm{reg}}$, the \emph{regular character} of $G$.

  First note that we have $\pi_{\mathrm{reg}}(1) = |G|$, and $\pi_{\mathrm{reg}}(h) = 0$ if $h\not= 1$. The first part is obvious, and the second is easy to show, since we have only $0$s along the diagonal.

  Next, we decompose $\pi_{\mathrm{reg}}$ as
  \[
    \pi_{\mathrm{reg}} = \sum a_j \chi_j,
  \]
  We now want to find $a_j$. We have
  \[
    a_j = \bra \pi_{\mathrm{reg}}, \chi_j\ket = \frac{1}{|G|} \sum_{g \in G} \overline{\pi_{\mathrm{reg}}(g)} \chi_j(g) = \frac{1}{|G|} \cdot |G| \chi_j(1) = \chi_j(1).
  \]
  Then we get
  \[
    |G| = \pi_{\mathrm{reg}}(1) = \sum a_j \chi_j(1) = \sum \chi_j(1)^2 = \sum n_j^2.
  \]
\end{proof}

\begin{cor}
  The number of irreducible characters of $G$ (up to equivalence) is $k$, the number of conjugacy classes.
\end{cor}

\begin{proof}
  The irreducible characters and the characteristic functions of the conjugacy classes are both bases of $\mathcal{C}(G)$.
\end{proof}

\begin{cor}
  Two elements $g_1, g_2$ are conjugate if and only if $\chi(g_1) = \chi(g_2)$ for all irreducible characters $\chi$ of $G$.
\end{cor}

\begin{proof}
  If $g_1, g_2$ are conjugate, since characters are class functions, we must have $\chi(g_1) = \chi(g_2)$.

  For the other direction, let $\delta$ be the characteristic function of the class of $g_1$. Then since $\delta$ is a class function, we can write
  \[
    \delta = \sum m_j \chi_j,
  \]
  where $\chi_j$ are the irreducible characters of $G$. Then
  \[
    \delta(g_2) = \sum m_j \chi_j(g_2) = \sum m_j \chi_j(g_1) = \delta(g_1) = 1.
  \]
  So $g_2$ is in the same conjugacy class as $g_1$.
\end{proof}

Before we move on to the proof of the completeness of characters, we first make a few more definitions:
\begin{defi}[Character table]
  The \emph{character table} of $G$ is the $k \times k$ matrix $X = (\chi_i (g_j))$, where $1 = \chi_1, \chi_2, \cdots, \chi_k$ are the irreducible characters of $G$, and $\mathcal{C}_1 = \{1\}, \mathcal{C}_2, \cdots, \mathcal{C}_k$ are the conjugacy classes with $g_j \in \mathcal{C}_j$.
\end{defi}
We will spend the next few lectures coming up with techniques to compute these character tables.

\begin{eg}
  Consider $G = D_6 \cong S_3 = \bra r, s\mid r^3 = s^2 = 1, srs^{-1} = r^{-1}\ket$. As in all computations, the first thing to do is to compute the conjugacy classes. This is not too hard. We have
  \[
    \mathcal{C}_1 = \{1\},\quad \mathcal{C}_2 = \{s, sr, sr^2\},\quad \mathcal{C}_2 = \{r, r^{-1}\}.
  \]
  Alternatively, we can view this as $S_3$ and use the fact that two elements are conjugate if and only if they have the same cycle types. We have found the three representations: 1, the trivial representation; S, the sign; and W, the two-dimensional representation. In $W$, the reflections $sr^j$ acts by matrix with eigenvalues $\pm 1$. Since the entries are in the opposite diagonals, we have $\chi_w(sr^2)= 0$. It also also not hard to see
  \[
    r^m \mapsto
    \begin{pmatrix}
      \cos \frac{2m \pi}{3} & - \sin \frac{2m\pi}{3}\\
      \sin \frac{2m\pi}{3} & \cos \frac{2m \pi}{3}
    \end{pmatrix}.
  \]
  So $\chi_w(r^m) = -1$.

  Fortunately, after developing some theory, we will not need to find all the irreducible representations in order to compute the character table.
  \begin{center}
    \begin{tabular}{cccc}
      \toprule
      & 1 & $\mathcal{C}_2$ & $\mathcal{C}_3$\\
      \midrule
      1 & $1$ & $1$ & $1$\\
      S & $1$ & $-1$ & $1$\\
      $\chi_w$ & $2$ & $0$ & $-1$\\
      \bottomrule
    \end{tabular}
  \end{center}
  We see that the sum of the squares of the first column is $1^2 + 1^2 + 2^2 = 6 = |D_6|$, as expected. We can also check that W is genuinely an irreducible representation. Noting that the centralizers of $\mathcal{C}_1, \mathcal{C}_2$ and $\mathcal{C}_3$ are $6, 2, 3$. So the inner product is
  \[
    \bra \chi_W, \chi_W\ket = \frac{2^2}{6} + \frac{0^2}{2} + \frac{(-1)^2}{3} = 1,
  \]
  as expected.
\end{eg}
So we now need to prove orthogonality.
\section{Proof and orthogonality}
We will do the proof in parts.

\begin{thm}[Row orthogonality relations]
  If $\rho: G \to \GL(V)$ and $\rho': G \to \GL(V')$ are two complex irreducible representations affording characters $\chi, \chi'$ respectively, then
  \[
    \bra \chi, \chi'\ket =
    \begin{cases}
      1 & \text{if $\rho$ and $\rho'$ are isomorphic representations}\\
      0 & \text{otherwise}
    \end{cases}.
  \]
\end{thm}

\begin{proof}
  We fix a basis of $V$ and of $V'$. Write $R(g), R'(g)$ for the matrices of $\rho(g)$ and $\rho'(g)$ with respect to these bases respectively. Then by definition, we have
  \begin{align*}
    \bra \chi', \chi\ket &= \frac{1}{|G|} \sum_{g \in G} \chi'(g^{-1}) \chi(g)\\
    &= \frac{1}{|G|} \sum_{g \in G}\;\;\sum_{\substack{\mathllap{1 \leq}i\mathrlap{\leq n'}\\ \mathllap{1\leq}j\mathrlap{\leq n}}}R'(g^{-1})_{ii} R(g)_{jj}.
  \end{align*}
  For any linear map $\varphi: V \to V'$, we define a new map
  \begin{align*}
    \tilde{\phi}: V &\to V'\\
    \mathbf{v} &\mapsto \frac{1}{|G|} \sum \rho'(g^{-1}) \varphi \rho(g) \mathbf{v}
  \end{align*}
  We first check $\tilde{\varphi}$ is a $G$-homomorphism --- if $h \in G$, we need to show $\rho(h^{-1}) \tilde{\varphi} \rho(h) (\mathbf{v}) = \tilde{\phi}(\mathbf{v})$. We have
  \begin{align*}
    \rho'(h^{-1})\tilde{\varphi}\rho(h) (\mathbf{v}) &= \frac{1}{|G|} \sum_{g \in G} \rho'((gh)^{-1})\varphi(\rho(gh))\mathbf{v}\\
    &= \frac{1}{|G|} \sum_{g' \in G} \rho'(g'^{-1}) \phi \rho(g') \mathbf{v}\\
    &= \tilde{\varphi}(\mathbf{v}).
  \end{align*}
  \begin{enumerate}
    \item Now we first consider the case where $\rho, \rho'$ is \emph{not} isomorphic. Then by Schur's lemma, we must have $\tilde{\varphi} = 0$ for any linear $\phi: V \to V'$.

      We now pick a very nice $\phi$, where everything disappears. We let $\varphi = \varepsilon_{\alpha\beta}$, the operator having matrix $E_{\alpha\beta}$ with entries $0$ everywhere except $1$ in the $(\alpha,\beta)$ position.

      Then $\tilde{\varepsilon}_{\alpha\beta} = 0$. So
      \[
        \frac{1}{|G|} \sum_{g \in G} (R'(g^{-1}) E_{\alpha\beta}R(g))_{ij} = 0.
      \]
      Using our choice of $\varepsilon_{\alpha\beta}$, we get
      \[
        \frac{1}{|G|} \sum_{g \in G} R'(g^{-1})_{i\alpha} R(g)_{\beta j} = 0
      \]
      for all $i = j$. We now pick $\alpha = i$ and $\beta = j$. Then
      \[
        \frac{1}{|G|} \sum_{g \in G}R'(g^{-1})_{ii} R(g)_{jj} = 0.
      \]
      We can sum this guy over all $i$ and $j$ to get that $\bra \chi', \chi\ket = 0$.

    \item Now suppose $\rho, \rho'$ are isomorphic. So we might as well take $\chi = \chi'$, $V = V'$ and $\rho = \rho'$. If $\varphi: V \to V$ is linear, then $\tilde{\varphi} \in \End_G(V)$.

      We first claim that $\tr \tilde{\varphi} = \tr{\varphi}$. To see this, we have
      \[
        \tr \tilde{\varphi} = \frac{1}{|G|} = \sum \tr(\rho(g^{-1}) \varphi \rho(g)) = \frac{1}{|G|} \sum_{g \in G} \tr \varphi = \tr \varphi,
      \]
      using the fact that traces don't see conjugacy (and $\rho(g^{-1}) = \rho(g)^{-1}$ since $\rho$ is a group homomorphism).

      By Schur's lemma, we know $\tilde{\varphi} = \lambda \iota_v$ for some $\lambda \in \C$ (which depends on $\varphi$). Then if $n \dim V$, then
      \[
        \lambda = \frac{1}{n} \tr \varphi.
      \]
      Let $\varphi = \varepsilon_{\alpha\beta}$. Then $\tr \varphi = \delta_{\alpha\beta}$. Hence
      \[
        \tilde{\varepsilon}_{\alpha\beta} = \frac{1}{|G|} \sum_g \rho(g^{-1}) \varepsilon_{\alpha\beta}\rho(g) = \frac{1}{n} \delta_{\alpha\beta} \iota.
      \]
      In terms of matrices, we take the $(i, j)$th entry to get
      \[
        \frac{1}{|G|} = \sum R(g^{-1})_{i\alpha} R(g)_{\beta j} = \frac{1}{n} \delta_{\alpha\beta} \delta_{ij}.
      \]
      We now put $\alpha = i$ and $\beta = j$. Then we are left with
      \[
        \frac{1}{|G|} \sum_g R(g^{-1})_{ii} R(g)_{jj} = \frac{1}{n} \delta_{ij}.
      \]
      Summing over all $i$ and $j$, we get $\bra \chi, \chi \ket = 1$.
  \end{enumerate}
\end{proof}

What we have done is show the orthogonality of the rows. There is a similar one for the columns. We shall prove column orthogonality:

\begin{thm}[Column orthogonality relations]
  We have
  \[
    \sum_{i = 1}^k \overline{\chi_i (g_j)}\chi_i (g_\ell) = \delta_{j\ell} |C_G(g_\ell)|.
  \]
\end{thm}
This has an easy corollary:
\begin{cor}
  \[
    |G| = \sum_{i = 1}^k \chi_i^2 (1).
  \]
\end{cor}

\begin{proof}(of column orthogonality)
  Consider the character table $X = (\chi_i(g_j))$. We know
  \[
    \delta_{ij} = \bra \chi_i, \chi_j\ket = \sum \frac{1}{|C_G(g_\ell)|}\overline{\chi_i(g_\ell)} \chi_k(g_\ell).
  \]
  Then
  \[
    \bar{X} D^{-1} X^T = I_{k\times k},
  \]
  where
  \[
    D =
    \begin{pmatrix}
      |C_G(g_1)| & \cdots & 0\\
      \vdots & \ddots & \vdots\\
      0 & \cdots & |C_G(g_k)|
    \end{pmatrix}.
  \]
  Since $X$ is square, it follows that $D^{-1} \bar{X}^T$ is the inverse of $X$. So $\bar{X}^T X = D$. So $\bar{X}^T X = D$, which is exactly the theorem.
\end{proof}
The proof requires that $X$ is square, ie. there are $k$ many irreducible representations. So we need to prove the last part of the completeness of characters.

\begin{thm}
  Each class function of $G$ can be expressed as a linear combination of irreducible characters of $G$.
\end{thm}

\begin{proof}
  We list all the irreducible characters $\chi_1, \cdots, \chi_\ell$ of $G$. Note that we don't know the number of irreducibles is $k$. This is essentially what we have to prove here. We now claim these generate $\mathcal{C}(G)$, the ring of class functions.

  Now recall that $\mathcal{C}(G)$ has an inner product. So it suffices to show that the orthogonal complement to the span $\bra \chi_1, \cdots, \chi_\ell\ket$ in $\mathcal{C}(G)$ is trivial. To see this, assume $f \in \mathcal{C}(G)$ satisfies
  \[
    \bra f, \chi_j\ket = 0
  \]
  for all $\chi_j$ irreducible. We let $\rho: G \to \GL(V)$ be an irreducible representation affording $\chi \in \{\chi_1, \cdots, \chi_\ell\}$. Then $\bra f, \chi\ket = 0$.

  Consider the function
  \[
    \frac{1}{|G|} \sum_g \overline{f}(g) \rho(g): V \to V.
  \]
  This is a $G$-homomorphism. So as $\rho$ is irreducible, Schur's lemma says it must be of the form $\lambda \iota_V$ for some $\lambda \in \C$.

  Now we take the trace of this thing. So we have
  \[
    n\lambda = \tr\left(\frac{1}{|G|} \sum_g \overline{f(g)} \rho(g)\right) = \frac{1}{|G|} \sum_g \overline{f(g)} \chi(g) = \bra f, \chi\ket = 0.
  \]
  So $\lambda = 0$, ie. $\sum_g \overline{f(g)} \rho(g) = 0$, the zero endomorphism on $V$. This is valid for any irreducible representation, and hence for every representation, by complete reducibility.

  In particular, take $\rho = \rho_{\mathrm{reg}}$, where $\rho_{\mathrm{reg}}(g): \mathbf{e}_1 \mapsto \mathbf{e}_g$ for each $g \in G$. Hence
  \[
    \sum \overline{f(g)} \rho_{\mathrm{reg}}(g): \mathbf{e}_1 \mapsto \sum_g \overline{f(g)} \mathbf{e}_g.
  \]
  Since this is zero, it follows that we must have $\sum \overline{f(g)} \mathbf{e}_g = 0$. Since the $\mathbf{e}_g$'s are linearly independent, we must have $\overline{f(g)} = 0$ for all $g \in G$, ie. $f = 0$.
\end{proof}

\section{Permutation representations}
This is particularly useful if we are dealing with the symmetric group. We've had a preview before: let $G$ be a finite group acting on a finite set $X = \{x_1, \cdots, x_n\}$ (sometimes known as a $G$-set). We define $\C X$ to be the complex vector space with basis $\{\mathbf{e}_{x_1}, \cdots, \mathbf{e}_{x_n}\}$. More explicitly,
\[
  \C X = \left\{ \sum_g a_g \mathbf{e}_{x_j}: a_j \in \C\right\}.
\]
There is a corresponding representation permutation
\begin{align*}
  \rho_X: G &\to \GL(\C X)\\
  g &\mapsto \rho(g)
\end{align*}
where $\rho(g): \mathbf{e}_{x_j} \mapsto \mathbf{e}_{g x_j}$, extended linearly. We say $\rho_X$ is the representation representation corresponding to the action of $G$ on $X$.

This is a generalization of the group algebra --- if we let $G$ act on itself by left multiplication, then this is in fact the group algebra.

The corresponding matrix representations $\rho_X(g)$ with respect to the basis $\{\mathbf{e}_x\}_{x \in X}$ are permutation matrices --- it is $0$ everywhere except for one $1$ in each row and column. In particular, $(\rho(g))_{ij} = 1$ precisely when $g x_j = x_i$.

\begin{defi}[Permutation character]
  The \emph{permutation character} $\pi_X$ is
  \[
    \pi_X(g) = |\fix(g)| = |\{x \in X: gx = x\}|.
  \]
\end{defi}
It is easy to see this is in fact the usual notion of character.

\begin{lemma}
  $\pi_X$ always contains the trivial character $1_G$ (when decomposed in the basis of irreducible characters). Moreover, $\spn\{\mathbf{e}_{x_1}, \cdots, \mathbf{e}_{x_n}\}$ is a trivial $G$-subspace of $\C X$, with $G$-invariant complement $\left\{\sum_x a_x \mathbf{e}_x: \sum a_x = 0\right\}$.
\end{lemma}
This is rather obvious, and we will not prove it.

\begin{lemma}
  $\bra \pi_X, 1\ket$, which is the multiplicity of $1$ in $\pi_X$, is the number of orbits of $G$ on $X$.
\end{lemma}

\begin{proof}
  We write $X$ as the disjoint union of orbits, $X = X_1 \cup \cdots \cup X_\ell$. Then it is clear that the permutation representation on $X$ is just the sum of the permutation representations on the $X_i$, ie.
  \[
    \pi_X = \pi_{X_1} + \cdots + \pi_{x_\ell},
  \]
  where $\pi_{X_j}$ is the permutation character of $G$ on $X_j$. So to prove the lemma, it is enough to consider the case where the action is transitive, ie. there is just one orbit.

  So suppose $G$ acts transitively on $X$. We want to show $\bra \pi_X, 1\ket = 1$. By definition, we have
  \begin{align*}
    \bra \pi_X, 1 \ket &= \frac{1}{|G|} \sum_g \pi_X(g) \\
    &= \frac{1}{|G|} \left|\{(g, x) \in G\times X: gx = x\}\right|\\
    &= \frac{1}{|G|} \sum_{x \in X} |G_x|,\\
    \intertext{where $G_x$ is the stabilizer of $x$}
    &= \frac{1}{|G|} \cdot |X| |G_x| \\
    &= \frac{1}{|G|} \cdot |G|\\
    &= 1,
  \end{align*}
  where we used the orbit-stabilizer theorem. So done.
\end{proof}

\begin{lemma}
  Let $G$ act on the sets $X_1, X_2$. Then $G$ acts on $X_1 \times X_2$ by
  \[
    g(x_1, x_2) = (g x_1, g x_2).
  \]
  Then the character
  \[
    \pi_{X_1 \times X_2} = \pi_{X_1}\pi_{X_2},
  \]
  and so
  \[
    \bra \pi_{x_1}, \pi_{x_2}\ket = \text{ number of orbits of }G\text{ on }X_1 \times X_2.
  \]
\end{lemma}

\begin{proof}
  If $g \in G$, then a direct check gives
  \[
    \pi_{X_1 \times X_2}(g) = \pi_{X_1}(g) \pi_{X_2}(g). % expand
  \]
  Then using the fact that $\pi_1, \pi_2$ are real, we get
  \begin{align*}
    \bra \pi_{X_1}, \pi_{X_2}\ket &= \frac{1}{|G|} \sum_g \overline{\pi_{X_1}(g)}\pi_{X_2}(g)\\
    &= \frac{1}{|G|} \sum_g \overline{\pi_{X_1}(g) \pi_{X_2}(g)} 1_G(g)\\
    &= \bra \pi_{X_1}\pi_{X_2}, 1\ket \\
    &= \bra \pi_{X_1\times X_2}, 1\ket.
  \end{align*}
  So the previous lemma gives the desired result.
\end{proof}

Recall the following definition:
\begin{defi}[$2$-transitive]
  Let $G$ act on $X$, $|X| > 2$. Then $G$ is \emph{$2$-transitive} on $X$ if $G$ has two orbits on $X \times X$, namely $\{(x, x): x \in X\}$ and $\{(x_1, x_2): x_i \in X, x_1 \not= x_2\}$.
\end{defi}
Then we have the following lemma:

\begin{lemma}
  Let $G$ act on $X$, with $|X| > 2$. Then
  \[
    \pi_X = 1_G + \chi,
  \]
  with $\chi$ irreducible if and only if $G$ is $2$-transitive on $X$.
\end{lemma}

\begin{proof}
  We know
  \[
    \pi_X = m_1 1_G + m_2 \chi_2 + \cdots + m_\ell \chi_\ell,
  \]
  with $1_G, \chi_2, \cdots, \chi_\ell$ distinct irreducible characters and $m_i \in \N$ are non-zero. Then by orthogonality,
  \[
    \bra \pi_X, \pi_X\ket = \sum_{i = 1}^j m_i^2.
  \]
  So $G$ is $2$-transitive on $X$ if and only if $\ell = 2$ and $m_1 = m_2 = 1$.
\end{proof}
What are the implications these for the symmetric group?

\begin{eg}
  $S_n$ acting on $X = \{1, \cdots, n\}$ is $2$-transitive. So $\pi_X = 1 + \chi$, with $\chi$ irreducible of degree $n - 1$ (since $\pi_X$ has degree $n$). This works similarly for $A_n$, whenever $n \geq 3$.
\end{eg}
This tells us we can find an irreducible character of $S_n$ by finding $\pi_X$, and then subtracting $1$ off.

\begin{eg}
  Consider $G = S_4$. The conjugacy classes correspond to different cycle types. We already know three characters --- the trivial one, the sign, and $\pi_X - 1_G$.
  \begin{center}
    \begin{tabular}{ccccccc}
      \toprule
      & & 1 & 3 & 8 & 6 & 6\\
      & & $1$ & $(1\; 2)(3\; 4)$ & $(1\; 2\; 3)$ & $(1\; 2\; 3\; 4)$ & $(1\; 2)$\\
      \midrule
      trivial & $\chi_1$ & $1$ & $1$ & $1$ & $1$ & $1$\\
      sign & $\chi_2$ & $1$ & $1$ & $1$ & $-1$ & $-1$\\
      $\pi_X - 1_G$ & $\chi_3$ & $3$ & $-1$ & $0$ & $-1$ & $1$\\
      & $\chi_4$\\
      & $\chi_5$\\
      \bottomrule
    \end{tabular}
  \end{center}
  We know the product of a one-dimensional irreducible character and another character is another irreducible character, as shown on the first example sheet. So we get
  \begin{center}
    \begin{tabular}{ccccccc}
      \toprule
      & & 1 & 3 & 8 & 6 & 6\\
      & & $1$ & $(1\; 2)(3\; 4)$ & $(1\; 2\; 3)$ & $(1\; 2\; 3\; 4)$ & $(1\; 2)$\\
      \midrule
      trivial & $\chi_1$ & $1$ & $1$ & $1$ & $1$ & $1$\\
      sign & $\chi_2$ & $1$ & $1$ & $1$ & $-1$ & $-1$\\
      $\pi_X - 1_G$ & $\chi_3$ & $3$ & $-1$ & $0$ & $-1$ & $1$\\
      $\chi_3 \chi_2$ & $\chi_4$ & $3$ & $-1$ & $0$ & $1$ & $-1$\\
      & $\chi_5$ &\\
      \bottomrule
    \end{tabular}
  \end{center}
  For the last representation we can find the dimension by computing $24 - (1^2 + 1^2 + 3^2 + 3^2 + 2^2) = 2^2$. So it has dimension $2$. To obtain the whole of $\chi_5$, we can use column orthogonality --- for example, we let the entry in the second column be $x$. Then column orthogonality says $1 + 1 - 3 - 3 + 2x = 0$ . So $x = 2$. In the end, we find
  \begin{center}
    \begin{tabular}{ccccccc}
      \toprule
      & & 1 & 3 & 8 & 6 & 6\\
      & & $1$ & $(1\; 2)(3\; 4)$ & $(1\; 2\; 3)$ & $(1\; 2\; 3\; 4)$ & $(1\; 2)$\\
      \midrule
      trivial & $\chi_1$ & $1$ & $1$ & $1$ & $1$ & $1$\\
      sign & $\chi_2$ & $1$ & $1$ & $1$ & $-1$ & $-1$\\
      $\pi_X - 1_G$ & $\chi_3$ & $3$ & $-1$ & $0$ & $-1$ & $1$\\
      $\chi_3 \chi_2$ & $\chi_4$ & $3$ & $-1$ & $0$ & $1$ & $-1$\\
      & $\chi_5$ & $2$ & $2$ & $-1$ & $0$ & $0$\\
      \bottomrule
    \end{tabular}
  \end{center}
  Alternatively, we have previously shown that $\chi_{\mathrm{reg}} = \chi_1 + \chi_2 + 3\chi_3 + 3 \chi_4 + 2\chi_5$. By computing $\chi_{\mathrm{reg}}$ directly, we can find $\chi_5$.

  Finally, we can obtain $\chi_5$ by observing $S_4 / V_4 \cong S_3$, and ``lifting'' characters. We will do this in the next chapter. In fact, this $\chi_5$ is the degree-$2$ irreducible representation of $S_3 \cong D_6$ lifted up.
\end{eg}

We can also do similar things with the alternating group. The issue of course is that the conjugacy classes of the symmetric group may split when we move to the alternating group.

Suppose $g \in A_n$. Then
\begin{align*}
  |\mathcal{C}_{S_n}(g)| &= |S_n: C_{S_n}(g)|\\
  |\mathcal{C}_{A_n}(g)| &= |A_n: C_{A_n}(g)|.
\end{align*}
We know $\mathcal{C}_{S_n}(g) \supseteq \mathcal{C}_{A_n}(g)$, but we need not have equality, since elements needed to conjugate $g$ to $h \in \mathcal{C}_{S_n}(g)$ might not be in $A_n$. For example, consider $\sigma = (1\; 2\; 3) \in A_3$. We have $\mathcal{C}_{A_3}(\sigma) = \{\sigma\}$ and $\mathcal{C}_{S_3} (\sigma) = \{\sigma, \sigma^{-1}\}$.

We know $A_n$ is an index 2 subgroup of $S_n$. So $C_{A_n}(g) \subseteq C_{S_n}(g)$ either has index $2$ or $1$. If the index is $1$, then $|\mathcal{C}_{A_n}| = \frac{1}{2}|\mathcal{C}_{S_n}|$. Otherwise, the sizes are equal.

A useful criterion for determining which case happens is the following:

\begin{lemma}
  Let $g \in A_n$, $n > 1$. If $g$ commutes with some odd permutation in $S_n$, then $\mathcal{C}_{S_n}(g) = \mathcal{C}_{A_n}(g)$. Otherwise, $\mathcal{C}_{S_n}$ splits into two conjugacy classes in $A_n$ of eqeual size.
\end{lemma}

This is quite useful for doing the examples on the example sheet, but we will not go through any more examples here.

\section{Normal subgroups and lifting}
The idea of this section is that there is some correspondence between the irreducible characters of $G/N$ (with $N \lhd G$) and those of $G$ itself. In most cases, $G/N$ is a simpler group, and hence we can use this correspondence to find irreducible characters of $G$.

The main result is the following lemma:

\begin{lemma}
  Let $N \lhd G$. Let $\tilde{\rho}: G/N \to \GL(V)$ be a representation of $G/N$. Then the composition
  \[
    \begin{tikzcd}
      \rho: G \ar[r, "\text{natural}"] & G/N \ar[r, "\tilde{\rho}"] & \GL(V)
    \end{tikzcd}
  \]
  is a representation of $G$, where $\rho(g) = \tilde{\rho}(gN)$. Moreover,
  \begin{enumerate}
    \item $\rho$ is irreducible if and only if $\tilde{\rho}$ is irreducible.
    \item The corresponding characters satisfy $\chi(g) = \tilde{\chi}(gN)$.
    \item $\deg \chi = \deg \tilde{\chi}$.
    \item The lifting operation $\tilde{\chi} \mapsto \chi$ is a bijection
      \[
        \{\text{irreducibles of }G/N\} \longleftrightarrow \{\text{irreducibles of $G$ with $N$ in their kernel}\}.
      \]
  \end{enumerate}
  We say $\tilde{\chi}$ \emph{lifts to} $\chi$.
\end{lemma}

\begin{proof}
  The ability to lift the representation was done on example sheet 1, question 4. % include

  Next, note that $\chi(g) = \tr \rho(g) = \tr (\tilde{\rho}(gN)) = \tilde{\chi}(gN)$ for all $g \in G$, and thus
  \[
    \deg \chi = \chi(1) = \tilde{\chi}(N) = \deg \tilde{\chi}.
  \]
  Alternatively, to show they have the dimension, just note that $\rho$ and $\tilde{\rho}$ map to the general linear group of the same vector space.

  To show this is a bijection, suppose $\tilde{\chi}$ is a character of $G/N$ and $\chi$ is its lift to $G$. We need to show the kernel contains $N$. By definition, we know $\tilde{\chi}(N) = \chi(1)$. Also, if $k \in N$, then $\chi(k) = \tilde{\chi}(kN) = \tilde{\chi}(N) = \chi(1)$. So $N \leq \ker \chi$.

  Now let $\chi$ be a character of $G$ with $N \leq \ker \chi$. Suppose $\rho: G \to \GL(V)$ affords $\chi$. Define
  \begin{align*}
    \tilde{\rho}: G/N &\to \GL(V)\\
    gN &\mapsto \rho(g)
  \end{align*}
  Of course, we need to check this is well-defined. If $gN = g'N$, then $g^{-1} g' \in N$. So $\rho(g) = \rho(g')$ since $N \leq \ker \rho$. So this is indeed well-defined. It is also easy to see that $\tilde{\rho}$ is a homomorphism, hence a representation of $G/N$.

  Finally, if $\tilde{\chi}$ is a character of $\tilde{\rho}$, then $\tilde{\chi}(gN) = \chi(g)$ for all $g \in G$ by definition. So $\tilde{\chi}$ lifts to $\chi$. It is clear that these two operations are inverses to each other.
\end{proof}
There is one particular normal subgroup lying around that proves to be useful.

\begin{lemma}
  Given a group $G$, the derived subgroup $G' = \bra [a, b]: a, b \in G\ket$ (where $[a, b] = aba^{-1}b^{-1}$) is the unique minimal normal subgroup of $G$ such that $G/G'$ is abelian. So if $G/N$ is abelian, then $G' \leq N$.

  Moreover, $G$ has precisely $\ell = |G:G'|$ representations of dimension $1$, all with kernel containing $G'$, and are obtained by lifting from $G/G'$.

  In particular, by Lagrange's theorem, $\ell \mid G$.
\end{lemma}

\begin{proof}
  It is an exercise for the reader to show that $G' \lhd G$. % complete

  Let $N \lhd G$. Let $g, h \in G$. Then $[g, h] \in N$ if and only if $ghg^{-1}h^{-1} \in N$ if and only if $gh N = hg N$, if and only if $(gN)(hN) = (hN)(gN)$ by normality.

  Since $G'$ is generated by all $[g, h]$, we know $G' \leq N$ if and only if $G/N$ is abelian.

  Since $G/G'$, is abelian, we know it has exactly $\ell$ irreducible characters, $\tilde{\chi}_1, \cdots, \tilde{\chi}_{\ell}$, all of degree $1$. The lifts of these to $G$ also have degree $1$, and by the previous lemma, these are precisely the irreducible characters $\chi_i$ of $G$ such that $G' \leq \ker \chi_i$.

  But any degree $1$ character of $G$ is a homomorphism $\chi: G \to \C^\times$, hence $\chi(ghg^{-1}h^{-1}) = 1$. So for any $1$-dimensional character, $\chi$, we must have $G' \leq \ker \chi$. So the lifts $\chi_1, \cdots, \chi_\ell$ are all $1$-dimensional characters of $G$.
\end{proof}

\begin{eg}
  Let $G$ be $S_n$. It is easy to show $S_n' = A_n$. Since $S_n'/A_n \cong C_2$, $\ell = 2$. So $S_n$ must have exactly two linear characters, namely the trivial character and the sign.
\end{eg}

\begin{lemma}
  $G$ is not simple if and only if $\chi(g) = \chi(1)$ for some irreducible character $\chi \not= 1_G$ and some $1 \not= g \in G$. Any normal subgroup of $G$ is the intersection of the kernels of some of the irreducible characters of $G$, ie. $N = \bigcap \ker \chi_i$.
\end{lemma}
In other words, $G$ is simple if and only if all non-trivial irreducible characters have trivial kernel.

\begin{proof}
  Suppose $\chi(g) = \chi(1)$ for some non-trivial irreducible character $\chi$, and $\chi$ is afforded by $\rho$. Then $g \in \ker \rho$. So if $g \not= 1$, then $1 \not= \ker \rho \lhd G$, and $\ker \rho \not= G$. So $G$ cannot be simple.

  If $1 \not= N \lhd G$ is a non-trivial proper subgroup, take an irreducible character $\tilde{\chi}$ of $G/N$, and suppose $\tilde{\chi} \not= 1_{G/N}$. Lift this to get an irreducible character $\chi$, afforded by the representation $\rho$ of $G$. Then $N \leq \rho \lhd G$. So $\chi(g) = (1)$ for $g \in N$.

  Finally, let $1 \not= N \lhd G$. We claim that $N$ is the intersection of the kernels of the lifts $\chi_1, \cdots, \chi_\ell$ of all the irreducibles of $G/N$. Clearly, we have $N \leq \bigcap_i \ker \chi_i$. If $g \in G \setminus N$, then $gN \not= N$. So $\tilde{\chi}(gN) \not= \tilde{\chi}(N)$ for some irreducible $\tilde{\chi}$ of $G/N$. Lifting $\tilde{\chi}$ to $\chi$, we have $\chi(g) \not= \chi(1)$. So $g$ is not in the intersection of the kernels. % why
\end{proof}

\section{Dual spaces and tensor products of representations} % too long
Recall some basic properties of the complex space of complex-valued class functions, $\mathcal{C}(G)$. The dimension of $\mathcal{C}(G)$ is $k$, the number of conjugacy classes, and the irreducible characters $\chi_1, \cdots, \chi_k$ give a nice orthonormal basis for $\mathcal{C}(G)$. This also comes equipped with an involution (ie. ring homomorphism of order $2$), $f \mapsto f^*$, given by $f^*(g) = f(g^{-1})$. We had the inner product
\[
  \bra f_1, f_2\ket = \frac{1}{|G|} \sum_g f^*_1(g) f_2(g).
\]
\end{document}
