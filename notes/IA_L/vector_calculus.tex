\documentclass[a4paper]{article}

\usepackage[pdftex,
  hidelinks,
  pdfauthor={Dexter Chua},
  pdfsubject={Cambridge Maths Notes: Part IA - Vector Calculus},
  pdftitle={Part IA - Vector Calculus},
pdfkeywords={Cambridge Mathematics Maths Math IA Lent Vector Calculus}]{hyperref}

\input{header}

\title{Part IA - Vector Calculus}
\author{Lectured by B. Allanach}
\date{Lent 2015}

\begin{document}
\maketitle
{\small
  \noindent\textbf{Curves in $\R^3$}\\ 
  Parameterised curves and arc length, tangents and normals to curves in $\R^3$, the radius of curvature.\hspace*{\fill} [1]

  \vspace{10pt}
  \noindent\textbf{Integration in $\R^2$ and $\R^3$}\\
  Line integrals. Surface and volume integrals: definitions, examples using Cartesian, cylindrical and spherical coordinates; change of variables.\hspace*{\fill} [4]

  \vspace{10pt}
  \noindent\textbf{Vector operators}\\
  Directional derivatives. The gradient of a real-valued function: definition; interpretation as normal to level surfaces; examples including the use of cylindrical, spherical *and general orthogonal curvilinear* coordinates.

  \vspace{5pt}
  \noindent Divergence, curl and $\nabla^2$ in Cartesian coordinates, examples; formulae for these operators (statement only) in cylindrical, spherical *and general orthogonal curvilinear* coordinates. Solenoidal fields, irrotational fields and conservative fields; scalar potentials. Vector derivative identities.\hspace*{\fill} [5]

  \vspace{10pt}
  \noindent\textbf{Integration theorems}\\
  Divergence theorem, Green's theorem, Stokes's theorem, Green's second theorem: statements; informal proofs; examples; application to fluid dynamics, and to electromagnetism including statement of Maxwell's equations.\hspace*{\fill} [5]

  \vspace{10pt}
  \noindent\textbf{Laplace's equation}\\
  Laplace's equation in $\R^2$ and $\R^3$: uniqueness theorem and maximum principle. Solution of Poisson's equation by Gauss's method (for spherical and cylindrical symmetry) and as an integral.\hspace*{\fill} [4]

  \vspace{10pt}
  \noindent\textbf{Cartesian tensors in $\R^3$}\\
  Tensor transformation laws, addition, multiplication, contraction, with emphasis on tensors of second rank. Isotropic second and third rank tensors. Symmetric and antisymmetric tensors. Revision of principal axes and diagonalization. Quotient theorem. Examples including inertia and conductivity.\hspace*{\fill} [5]}

\tableofcontents

\setcounter{section}{-1}
\section{Introduction}
In the differential equations class, we learnt how to do calculus in one dimension (mostly). However, (apparently) the world has more than one dimension. We live in a 3 (or 4) dimensional worlds, and string theorists think that the world have more than 10 dimensions. In this course, we are mostly going to learn about doing calculus in many dimensions. In the last few lectures, we are going to learn about Cartesian tensors, which is a generalization of vectors.

Note that throughout the course (and lecture notes), summation convention is implied unless otherwise stated.

\section{Derivatives and coordinates}
\subsection{Differentiable functions \texorpdfstring{$\R\to\R^n$}{R to Rn}}
\begin{defi}
  A \emph{vector function} is a function $\mathbf{F}: \R\to \R^n$.
\end{defi}

While we used to define a derivative as a limit and a function as differentiable if the derivative exists, we now want to do it in a way that can capture differentiability in a way that is easily extensible to vector functions.

We say a function $f(x)$ is differentiable if, when we perturb its argument $x$ slightly by $\delta x$, then the change in $f(x)$ is proportional to $\delta x$, where ``proportional to'' means equal to ``something'' times $\delta x$, and the ``something'' can be anything from a scalar to a matrix. Then we call that ``something'' the derivative.

In particular, for vector functions, we define:
\begin{defi}[Derivative of vector function]
  A vector function $\mathbf{F}(x)$ is \emph{differentiable} if
  \[
    \delta \mathbf{F} \stackrel{\text{def}}{=}\mathbf{F}(x + \delta x)- \mathbf{F}(x) = \mathbf{F}'(x)\delta u + o(\delta x)
  \]
  for some $\mathbf{F}'(x)$. $\mathbf{F}'(x)$ is called the \emph{derivative} of $\mathbf{F}(x)$.

  Clearly, if $\mathbf{F}'(x)$ exists, then it is given by
  \[
    \mathbf{F}' = \frac{\d \mathbf{F}}{\d x} = \lim_{\delta x \to 0} \frac{1}{\delta x}[\mathbf{F}(x + \delta x) - \mathbf{F}(x)].
  \]
\end{defi}
Using differential notation, the differentiability condition can be written as
\[
  \d\mathbf{F} = \mathbf{F}'(x)\d x.
\]

Given a basis $\mathbf{e}_i$ that is independent of $x$, vector differentiation is performed componentwise, i.e.
\begin{prop}
 \[
   \mathbf{F}'(x) = F'_i(x)\mathbf{e}_i.
 \]
\end{prop}
Leibnitz identities hold for the products of scalar and vector functions.
\begin{prop}
  \begin{align*}
    \frac{\d}{\d t}(f\mathbf{g}) &= \frac{\d f}{\d t}\mathbf{g} + f\frac{\d \mathbf{g}}{\d t}\\
    \frac{\d}{\d t}(\mathbf{g}\cdot \mathbf{h}) &= \frac{\d \mathbf{g}}{\d t}\cdot \mathbf{h} + \mathbf{g}\cdot \frac{\d \mathbf{h}}{\d t}\\
    \frac{\d}{\d t}(\mathbf{g}\times \mathbf{h}) &= \frac{\d \mathbf{g}}{\d t}\times \mathbf{h} + \mathbf{g}\times \frac{\d \mathbf{h}}{\d t}
  \end{align*}
  Note that the order of multiplication must be retained in the case of the cross product.
\end{prop}

\begin{eg}
  Consider a particle with mass $m$. It has position $\mathbf{r}(t)$, velocity $\dot{\mathbf{r}}(t)$ and acceleration $\ddot{\mathbf{r}}$. Its momentum is $\mathbf{p} = m\dot{\mathbf{r}}(t)$.

  \note that derivatives with respect to $t$ are usually denoted by dots instead of dashes.

  If $\mathbf{F}(\mathbf{r})$ is the force on a particle, then Newton's second law states that
  \[
    \dot{\mathbf{p}} = m\ddot{\mathbf{r}} = \mathbf{F}(\mathbf{r}).
  \]
  We can define the angular momentum about the origin to be
  \[
    \mathbf{L} = \mathbf{r}\times \mathbf{p} = m\mathbf{r} \times \dot{\mathbf{r}}.
  \]
  If we want to know how the angular momentum changes over time, then
  \[
    \dot{\mathbf{L}} = m\dot{\mathbf{r}}\times \dot{\mathbf{r}} + m\mathbf{r}\times \ddot{\mathbf{r}} = m + \mathbf{r}\times \ddot{\mathbf{r}} = \mathbf{r}\times \mathbf{F}.
  \]
  which is the \emph{torque} of $\mathbf{F}$ about the origin.
\end{eg}

\subsection{Differentiable functions \texorpdfstring{$\R^n\to \R$}{Rn to R}}
\begin{defi}
  A \emph{scalar function} is a function $f: \R^n \to \R$.
\end{defi}

Before we define the derivative of a scalar function, we have to first define what it means to take a limit of a vector.
\begin{defi}[Limit of vector]
  The \emph{limit of vectors} is defined using the norm. So $\mathbf{v}\to \mathbf{c}$ iff $|\mathbf{v} - \mathbf{c}| \to 0$.
\end{defi}

\begin{defi}[Gradient of scalar function]
  A scalar function $f(\mathbf{r})$ is \emph{differentiable} at $\mathbf{r}$ if
  \[
    \delta f \stackrel{\text{def}}{=} f(\mathbf{r} + \delta \mathbf{r}) - f(\mathbf{r}) = (\nabla f)\cdot \delta \mathbf{r} + o(\delta \mathbf{r})
  \]
  for some vector $\nabla f$, the \emph{gradient} of $f$ at $\mathbf{r}$.
\end{defi}
Taking $\delta \mathbf{r} = h\mathbf{n}$, with $\mathbf{n}$ a unit vector,
\[
  f(\mathbf{r} + h\mathbf{n}) - f(\mathbf{r}) = \nabla f \cdot (h\mathbf{n}) + o(h),
\]
which gives
\begin{defi}[Directional derivative]
  The \emph{directional derivative} of $f$ along $\mathbf{n}$ is
  \[
    \mathbf{n}\cdot \nabla f = \lim_{h \to 0} \frac{1}{h}[f(\mathbf{r} + h\mathbf{n}) - f(\mathbf{r})],
  \]
  It refers to how fast $f$ changes when we move in the direction of $\mathbf{n}$.
\end{defi}
In particular, the directional derivative is maximized when $\mathbf{n}$ is in the direction of $\nabla f$. So $\nabla f$ points in the direction of greatest slope.

To evaluate $\nabla f$, suppose we have an orthonormal basis $\mathbf{e}_i$. Setting $\mathbf{n} = \mathbf{e}_i$ in the above equation, we obtain
\[
  \mathbf{e}_i \cdot \nabla f = \lim_{h\to 0} \frac{1}{h}[f(\mathbf{r} + h\mathbf{e}_i) - f(\mathbf{r})] = \frac{\partial f}{\partial x_i}.
\]
Hence 
\begin{thm}
  The gradient is
  \[
    \nabla f = \frac{\partial f}{\partial x_i}\mathbf{e}_i
  \]
\end{thm}

Hence we can write the condition of differentiability as
\[
  \delta f = \frac{\partial f}{\partial x_i}\delta x_i + o(\delta x).
\]
In differential notation, we write
\[ 
  df = \nabla f\cdot \d \mathbf{r} = \frac{\partial f}{\partial x_i}\d x_i,
\]
which is the chain rule for partial derivatives.

\begin{eg}
  Take $f(x, y, z) = x + e^{xy}\sin z$. Then
  \begin{align*}
    \nabla f &= \left(\frac{\partial f}{\varphi x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z}\right)\\
    &= (1 + ye^{xy}\sin z, xe^{xy}\sin z, e^{xy}\cos z)
  \end{align*}

  At  $(x, y, z) = (0, 1, 0)$, $\nabla f = (1, 0, 1)$. So $f$ increases/decreases most rapidly for $\mathbf{n} = \pm \frac{1}{\sqrt{2}}(1, 0, 1)$ with a rate of change of $\pm \sqrt{2}$. There is no change in $f$ if $\mathbf{n}$ is perpendicular to $\pm \frac{1}{\sqrt{2}}(1, 0, 1)$.
\end{eg}

Now suppose we have a scalar function $f(\mathbf{r})$ and we want to consider the rate of change along a path $\mathbf{r}(u)$. A change $\delta u$ produces a change $\delta \mathbf{r} = \mathbf{r}' \delta u + o(\delta u)$, and
\[
  \delta f = \nabla f\cdot \delta \mathbf{r} + o(|\delta \mathbf{r}|) = \nabla f\cdot \mathbf{r}'(u)\delta u + o(\delta u).
\]
This shows that $f$ is differentiable as a function of $u$ and
\begin{thm}[Chain rule]
  Given a function $f(\mathbf{r}(u))$,
  \[
    \d f = \nabla f\cdot \d \mathbf{r} = \frac{\partial f}{\partial x_i} \d x_i.
  \]
\end{thm}

\subsection{Differentiable functions \texorpdfstring{$\R^n\to \R^m$}{Rn to Rm}}
So far, we have only considered functions $\R \to \R^n$ and $\R^n \to \R$. We can also consider vector fields:
\begin{defi}[Vector field]
  A \emph{vector field} is a function $\mathbf{F}: \R^n\to \R^m$.
\end{defi}

\begin{defi}[Derivative of vector field]
  A vector field $\mathbf{F}: \R^n \to \R^m$ is differentiable if
  \[
    \delta \mathbf{F} \stackrel{def}{=} \mathbf{F}(\mathbf{x} + \delta\mathbf{x}) - \mathbf{F}(\delta\mathbf{x}) = M\delta\mathbf{x} + o(\delta \mathbf{x})
  \]
  for some $n\times m$ matrix $M$. $M$ is the \emph{derivative} of $\mathbf{F}$.
\end{defi}

Given an arbitrary function $\mathbf{F}: \R^n \to \R^m$ that maps $\mathbf{x}\mapsto \mathbf{y}$ and a choice of basis, we can write $\mathbf{F}$ as a set of $m$ functions $y_j = F_j(\mathbf{x})$ such that $\mathbf{y} = (y_1, y_2, \cdots, y_m)$. Then
\[
  \d y_j = \frac{\partial F_j}{\partial x_i} \d x_i.
\]
and we can write the derivative as
\begin{thm}
  The derivative of $\mathbf{F}$ is given by
  \[
    M_{ji} =\frac{\partial y_j}{\partial x_i}.
  \]
\end{thm}

\begin{defi}
  A function is \emph{smooth} if it can be differentiated any number of times, i.e. if all partial derivatives exist and are totally symmetric in $i, j$ and $k$ (i.e. the differential operation is commutative).
\end{defi}
The functions we will consider will be smooth except where things obviously go wrong (e.g. $f(x) = 1/x$ at $x = 0$).
\end{document}
