\documentclass[a4paper]{article}

\usepackage[pdftex,
  hidelinks,
  pdfauthor={Dexter Chua},
  pdfsubject={Cambridge Maths Notes: Part II - Logic and Set Theory},
  pdftitle={Part IB - Logic and Set Theory},
pdfkeywords={Cambridge Mathematics Maths Math II Lent Logic and Set Theory}]{hyperref}

\title{Part II - Logic and Set Theory}
\author{Lectured by I. B. Leader}
\date{Lent 2015}

\input{header}

\begin{document}
\maketitle
{\small
  \noindent\textbf{Ordinals and cardinals}\\
  Well-orderings and order-types. Examples of countable ordinals. Uncountable ordinals and Hartogs' lemma. Induction and recursion for ordinals. Ordinal arithmetic. Cardinals; the hierarchy of alephs. Cardinal arithmetic.\hspace*{\fill} [5]

  \vspace{10pt}
  \noindent\textbf{Posets and Zorn's lemma}\\
  Partially ordered sets; Hasse diagrams, chains, maximal elements. Lattices and Boolean algebras. Complete and chain-complete posets; fixed-point theorems. The axiom of choice and Zorn's lemma. Applications of Zorn's lemma in mathematics. The well-ordering principle.\hspace*{\fill} [5]

  \vspace{10pt}
  \noindent\textbf{Propositional logic}\\
  The propositional calculus. Semantic and syntactic entailment. The deduction and completeness theorems. Applications: compactness and decidability.\hspace*{\fill} [3]

  \vspace{10pt}
  \noindent\textbf{Predicate logic}\\
  The predicate calculus with equality. Examples of first-order languages and theories. Statement of the completeness theorem; *sketch of proof*. The compactness theorem and the Lowenheim-Skolem theorems. Limitations of first-order logic. Model theory.\hspace*{\fill} [5]

  \vspace{10pt}
  \noindent\textbf{Set theory}\\ Set theory as a first-order theory; the axioms of ZF set theory. Transitive closures, epsilon-induction and epsilon-recursion. Well-founded relations. Mostowski's collapsing theorem. The rank function and the von Neumann hierarchy.\hspace*{\fill} [5]
  
  \vspace{10pt}
  \noindent\textbf{Consistency}\\
  *Problems of consistency and independence*\hspace*{\fill} [1]}

\tableofcontents

\section{Propositional calculus}
\begin{defi}[Propositions]
  Let $P$ be a set of \emph{primitive propositions}. These are a bunch of (meaningless) symbols, that are usually interpreted to take a truth value. Usually, any symbol (composed of alphabets and subscripts) is in the set of primitive propositions.

  The set of \emph{propositions}, written as $L$ or $L(P)$, is defined inductively by
  \begin{enumerate}
    \item If $p\in P$, then $p\in L$.
    \item $\bot\in L$, where $\bot$ is ``false'' (also a meaningless symbol).
    \item If $p, q\in L$, then $p\Rightarrow q)\in L$.
  \end{enumerate}
\end{defi}

\begin{eg}
  $p\Rightarrow q$, $p\Rightarrow \bot$, $((p\Rightarrow q)\Rightarrow (p\Rightarrow r))$ are propositions.
\end{eg}

To define $L$ formally, we let $L_1 = \{\bot\}\cup P$, and for $n\geq 1$, $L_{n + 1} = L_n\cup \{(p\Rightarrow q): p, q\in L_n\}$. Then set $L = L_1\cup L_2\cup \cdots$.

In formal language terms, $L$ is the set of finite strings of symbols from the alphabet $\bot$, $\bot$, $\Rightarrow $, $($, $)$, $p_1$, $p_2, \cdots$ that satisfies some formal grammar rule (eg. brackets have to match).

We define the following abbreviations:
\begin{defi}[Logical symbols]\leavevmode
  \begin{center}
    \begin{tabular}[]{cccc}
      $\neg p$ & (``not $p$'') & is an abbreviation for & $(p\Rightarrow \bot)$\\
      $p\wedge q$ & (``$p$ and $q$'') & is an abbreviation for & $\neg(p\Rightarrow (\neg q))$\\
      $p\vee q$ & (``$p$ or $q$'') & is an abbreviation for & $(\neg p)\Rightarrow q$
    \end{tabular}
  \end{center}
\end{defi}
\subsection{Semantic implication}
\begin{defi}[Valuation]
  A \emph{valuation} on $L$ is a function $v: L\to \{0, 1\}$ such that:
  \begin{itemize}
  \item $v(\bot) = 0$,
  \item $v(p\Rightarrow q) = \begin{cases} 0 & \text{if }v(p) = 1, v(q) = 0,\\1 & \text{otherwise}\end{cases}$
  \end{itemize}
  We interpret $v(p)$ to be the truth value of $p$, with 0 denoting ``false'' and 1 denoting ``true''.

  Note that we do not impose any restriction of $v(p)$ when $p$ is a primitive proposition (that is not $\bot$).
\end{defi}

We can also give $\{0, 1\}$ a binary operation $\Rightarrow$ by
\[
  a\Rightarrow b = \begin{cases}
    0 & \text{if }a = 1, b = 0\\
    1 & \text{otherwise}
  \end{cases}
\]
with a constant $\bot = 0$. Then a valuation $v: K\to \{0, 1\}$ is simply a homomorphism between the two structures that preserve $\bot$ and $\Rightarrow $.

\begin{prop}\leavevmode
  \begin{enumerate}
    \item If $v$ and $v'$ are valuations with $v(p) = v'(p)$ for all $p\in P$, then $v = v'$.
    \item For any function $W: P \to \{0, 1\}$, there is a valuation $v$ such that $v(p) = w(p)$ for all $p\in L$, ie. we can extend $w$ to a full valuation.
  \end{enumerate}
  This means ``A valuation is determined by its values on $P$, and any values will do''.
\end{prop}

\begin{proof}
  \begin{enumerate}
    \item Recall that $L$ is defined inductively. We are given that $v(p) = v'(p)$ on $L_1$. Then for all $p\in L_2$, $p$ must be in the form $q\Rightarrow r$ for $q, r\in L_1$. Then $v(q\Rightarrow r) = v(p\Rightarrow q)$ since the value of $v$ is uniquely determined by the definition. So for all $p\in L_2$, $v(p) = v'(p)$.

      Continue inductively to show that $v(p) = v'(p)$ for all $p\in L_n$ for any $n$.
    
    \item Set $v$ to agree with $w$ for all $p\in P$, and set $v(\bot) = 0$. Then define $v$ on $L_n$ inductively according to the definition.
  \end{enumerate}
\end{proof}

\begin{eg}
  Suppose $v$ is a valuation with $v(p) = v(q) = 1$, $v(r) = 0$. Then
  \[
    v((p\Rightarrow q)\Rightarrow r) = 0.
  \]
\end{eg}

\begin{defi}[Tautology]
  $t$ is a \emph{tautology}, written as $\models t$, if $v(t) = 1$. 
\end{defi}

\begin{eg}
  \begin{enumerate}
    \item $p\Rightarrow (q\Rightarrow p)$ ``A true statement is implied by anything''.\vspace{5pt}\\
      \begin{tabular}[]{cccc}
        $v(p)$ & $v(q)$ & $v(q\Rightarrow p)$ & $v(p\Rightarrow (q\Rightarrow p))$\\
        1 & 1 & 1 & 1\\
        1 & 0 & 1 & 1\\
        0 & 1 & 0 & 1\\
        0 & 0 & 1 & 1
      \end{tabular}
    \item $(\neg \neg p)\Rightarrow p$. Recall that $\neg\neg p$ is defined as $((p\Rightarrow \bot)\Rightarrow \bot)$.\vspace{5pt}\\
    \begin{tabular}{cccc}
      $v(p)$ & $v(p\Rightarrow \bot)$ & $v((p\Rightarrow \bot)\Rightarrow \bot)$ & $v(((p\Rightarrow \bot)\Rightarrow \bot)\Rightarrow p)$\\
      1 & 0 & 1 & 1\\
      0 & 1 & 0 & 1
    \end{tabular}
  \item $(p\Rightarrow (q\Rightarrow r))\Rightarrow ((p\Rightarrow q)\Rightarrow (p\Rightarrow r))$.

    Instead of creating a truth table, which would be horribly long, we show this by reasoning: Suppose it is not a tautology. So there is a $v$ such that $v(p\Rightarrow q\Rightarrow r)) = 1$ and $v((p\Rightarrow q)\Rightarrow (p\Rightarrow r)) =0 $. For the second equality to hold, we must have $v(p\Rightarrow q) = 1$ and $v(p\Rightarrow r) = 0$. So $v(p) = 1, v(r) = 0, v(q) = 1$. But then $v(p\Rightarrow q) = 0$. 
  \end{enumerate}
\end{eg}

\begin{defi}[Semantic entailment]
  For $S\subseteq L$, $t\in L$, we say $S$ \emph{entails} $t$, $S$ \emph{semantically implies t} or $S\models t$ if, for any $v$ such that $v(s) = 1$ for all $s\in S$, $v(t) = 1$.

  ``Whenever all of $S$ is true, $t$ is true as well.''
\end{defi}

\begin{eg}
  $\{p\Rightarrow q, q\Rightarrow r\}\models (p\Rightarrow r).$

  We want to show that for any valuation $v$ with $v(p\Rightarrow q) = v(q\Rightarrow r) = 1$, we have $v(p\Rightarrow r) = 1$. We prove the contrapositive.

  If $v(p\Rightarrow r) = 0$, then $v(p) = 1$ and $v(r) = 0$. If $v(q) = 0$, then $v(p\Rightarrow q) = 0$. If $v(q) = 1$, then $v(q\Rightarrow r) = 0$. So $v(p\Rightarrow r) = 0$ only if one of $v(p\Rightarrow q)$ or $v(q\Rightarrow r)$ is zero. 
\end{eg}
\begin{defi}[Truth and model]
  If $v(t) = 1$, then we say that $t$ is \emph{true} in $v$, or $v$ is a \emph{model} of $t$. For $S\subseteq L$, a valuation $v$ is a \emph{model} of $S$ if $v(s) = 1$. Then $\models t$ means $\emptyset \models t$. 
\end{defi}
\subsection{Syntactic implication}
While semantic implication captures the idea of truthfulness, syntactic implication captures the idea of proofs. To do so, we need to have axioms and deduction rules.

Our system of deduction composes of the following axioms:
\begin{enumerate}
  \item $p\Rightarrow(q\Rightarrow p)$
  \item $[p\Rightarrow(q\Rightarrow r)]\Rightarrow[(p\Rightarrow q)\Rightarrow(p \Rightarrow r)]$
  \item $(\neg\neg p)\Rightarrow p$
\end{enumerate}
and the deduction rule of \emph{modus ponens}: from $p$ and $p\Rightarrow q$, we can deduce $q$.

Note that every axiom is a tautology. 

\begin{defi}[Proof and syntactic entailment]
  For any $S\subseteq L$, a \emph{proof} of $t$ from $S$ is a finite sequence $t_1, t_2, \cdots t_n$ of propositions, with $t_n = t$, such that each $t_i$ is one of the following:
\begin{enumerate}
  \item An axiom
  \item A member of $S$
  \item A proposition $t_i$ such that there exist $j, k < i$ with $t_j = (t_k\Rightarrow t_i)$.
\end{enumerate}
If there is a proof of $t$ from $S$, we say that $S$ \emph{proves} or \emph{syntactically entails} $t$, written $S\vdash t$.

If $\emptyset \vdash t$, say $t$ is a \emph{theorem} and write $\vdash t$.

In a proof of $t$ from $S$, $t$ is the \emph{conclusion} and $S$ is the set of \emph{hypothesis} or \emph{premises}.


\end{defi}
\begin{eg}
  $\{p\Rightarrow q, q\Rightarrow r\} \vdash p\Rightarrow r$

  ``Go for $(p\Rightarrow  q)\Rightarrow  (p\Rightarrow  r)$ via Axiom 2.
  \begin{enumerate}[label=\arabic{*}.]
    \item $[p\Rightarrow (q\Rightarrow r)]\Rightarrow [(p\Rightarrow q) \Rightarrow (p\Rightarrow r)]$ \hfill Axiom 2
    \item $q\Rightarrow r$ \hfill Hypothesis
    \item $(q\Rightarrow r)\Rightarrow [q\Rightarrow (q\Rightarrow r)]$\hfill Axiom 1
    \item $p\Rightarrow (q\Rightarrow r)$ \hfill MP on 2,3
    \item $(p\Rightarrow q)\Rightarrow (p\Rightarrow r)$\hfill MP on 1, 4
    \item $p\Rightarrow q$\hfill Hypothesis
    \item $p\Rightarrow r$\hfill MP on 5, 6
  \end{enumerate}
\end{eg}

\begin{eg}
  $\vdash (p\Rightarrow p)$

  ``Go for $[p\Rightarrow (p\Rightarrow p)]\Rightarrow (p\Rightarrow p)$''
  \begin{enumerate}[label=\arabic{*}.]
    \item $[p\Rightarrow ((p\Rightarrow p)\Rightarrow p)]\Rightarrow [(p\Rightarrow (p\Rightarrow p))\Rightarrow (p\Rightarrow p)]$ \hfill Axiom 2
    \item $p\Rightarrow ( (p\Rightarrow p)\Rightarrow p)$\hfill Axiom 1
    \item $[p\Rightarrow (p\Rightarrow p)]\Rightarrow (p\Rightarrow p)$ \hfill MP on 1, 2
    \item $p\Rightarrow (p\Rightarrow p)$\hfill Axiom 1
    \item $p\Rightarrow p$ \hfill MP on 3, 4
  \end{enumerate}
\end{eg}

This seems like a really tedious way to prove things. We now prove that the \emph{deduction theorem}, that can usually help to prove $S\vdash t$.

\begin{prop}[Deduction theorem]
  Let $S\subset L$ and $p, q\in L$. Then $S\vdash (p\Rightarrow q)$ if and only if $S\cup {p} \vdash q$.\\

  ``$\vdash$ behaves like the connective $\Rightarrow $ in the language''
\end{prop}

\begin{proof}
  ($\Rightarrow $) Given a proof of $p\Rightarrow q$ from $S$, append the lines
  \begin{itemize}
    \item $p$\hfill Hypothesis
    \item $q$\hfill $MP$
  \end{itemize}
  to obtain a proof of $q$ from $S\cup \{q\}$.

  ($\Leftarrow$) Let $t_1, t_2, \cdots, t_n = q$ be a proof of $q$ from $S\cup \{p\}$. We'll show that $S\vdash p\Rightarrow t_i$ for all $i$.

  We consider different possibilities of $t_i$:
  \begin{itemize}
    \item $t_i$ is an axiom: Write down
      \begin{itemize}
        \item $t_i\Rightarrow (p\Rightarrow t_i)$\hfill (Axiom 1)
        \item $t_i$\hfill Axiom
        \item $p\Rightarrow t_i$ \hfill MP
      \end{itemize}
    \item $t_i\in S$: Write down
      \begin{itemize}
        \item $t_i\Rightarrow (p\Rightarrow t_i)$\hfill (Axiom 1)
        \item $t_i$\hfill Hypothesis
        \item $p\Rightarrow t_i$ \hfill MP
      \end{itemize}
      To get $S\models (p\Rightarrow t_i)$
    \item $t_i = p$: Write down our proof of $p\Rightarrow p$ from our example above.
    \item $t_i$ is obtained by MP: we have some $j, k< i$ such that $t_k = (t_k\Rightarrow t_i)$. We can assume that $S\vdash (p\Rightarrow t_j)$ and $S\vdash (p\Rightarrow t_k)$ by induction on $i$. Now we can write down
      \begin{itemize}
        \item $[p\Rightarrow (t_j\Rightarrow t_i)]\Rightarrow [(p\Rightarrow t_j)\Rightarrow (p\Rightarrow t_i)]$\hfill Axiom 2
        \item $p\Rightarrow (t_j\Rightarrow t_i)$\hfill Known already
        \item $(p\Rightarrow t_j)\Rightarrow (p\Rightarrow t_i)$\hfill MP
        \item $p\Rightarrow t_j$\hfill Known already
        \item $p\Rightarrow t_i$\hfill MP
      \end{itemize}
      to get $S\models (p\Rightarrow t_i)$. 
  \end{itemize}
  This is why Axiom 2 is as it is - it enables us to prove the deduction theorem. 
\end{proof}

\begin{eg}
  We want to show $\{p\Rightarrow  q, q\Rightarrow r\} \vdash (p\Rightarrow r)$. By the deduction theorem, it is enough to show that $\{p\Rightarrow q, q\Rightarrow  r, p\}\vdash r$, which is trivial by applying MP twice. 
\end{eg}

Now we have two notions: $\models$ and $\vdash$. How are they related? We want to show that they are equal: if something is true, we can prove it; if we can prove something, it must be true.

\noindent\textbf{Aim.} Show that $S\vdash t$ if and only if $S\models t$.
This is the \emph{completeness theorem}, made up of two directions:
\begin{enumerate}
  \item Soundness: If $S\vdash t$, then $S\models t$. ``Our axioms aren't absurd''
  \item Adequacy: If $S\models t$, $S\vdash t$.  ``Our axioms are strong enough to be able to deduce, from $S$, \emph{all} semantic consequences of $S$.''
\end{enumerate}

\begin{prop}[Soundness theorem]
  If $S\vdash t$, then $S\models t$.
\end{prop}

\begin{proof}
  Given valuation $v$ with $v(s) = 1$ for all $s\in S$, we need to show that $v(t) = 1$. But $v(p) = 1$ for all axioms $p$, and $v(p) = 1$ for all $p\in S$, and if $v(p) = 1$ and $v(p\Rightarrow q) = 1$, then $v(q) = 1$. Hence each line $t_i$ in a proof $t_1, \cdots, t_n$ of from $S$ has $v(t_i) = 1$. 
\end{proof}
This works because we know that all axioms of tautologies.

We first prove a special case of adequacy:
\begin{defi}[Consistent]
  $S$ is \emph{inconsistent} if $S\vdash \bot$. $S$ is \emph{consistent} if it is not inconsistent.
\end{defi}

We prove the following statement:
\begin{thm}[Model existence theorem]
  If $S\models \bot$, then $S\vdash \bot$. ie., if $S$ has no model, then $S$ is consistent. ie. If $S$ is consistent, then $S$ has a model.

  \note Some books call this the ``completeness theorem'', because the rest of the completeness theorem follows trivially from this. 
\end{thm}

In fact, this would imply adequacy. Indeed if $S\models t$, then  $S\cup \{\neg t\}\models \bot$. Hence $S\cup \{\neg t\}\vdash \bot$ by our special case. So $S\vdash \neg \neg t$ by the deduction theorem. But $\vdash (\neg\neg t)\Rightarrow t$ by Axiom 3. So $S\vdash t$.

\begin{proof}
  The idea is that we'd like to define $v: L \to \{0, 1\}$ by
  \[
    p\mapsto
    \begin{cases}
      1 & \text{if } p\in S\\
      0 & \text{if } p\in S
    \end{cases}
  \]
  However, this is obviously going to fail, because we might have implications of $S$ that are not in $S$, ie. $S$ is not \emph{deductively closed} (deductively closed means $S\vdash p$ implies $p\in S$). Yet this is not a serious problem - we take the deductive closure first.

  But there is a more serious problem. There might be a $p$ with $S\not\vdash p$ and $S\not\vdash \neg p$. This is the case if $p$ never appears in $S$. We'll try to extend $S$ to ``swallow up'' half of $L$. ie. we give $p$ an arbitrary truth value, without making $S$ inconsistent. The meat of this proof is then to see that we can ``swallow up'' propositions consistently.

  We first try to swallow up one proposition only.
  
  \noindent\textbf{Claim.} For consistent $S\subset L$ and $p\in L$, we have $S\cup \{p\}$ or $S\cup \{\neg p\}$ consistent.

  Suppose instead that $S\cup \{p\} \vdash \bot$ and $S\cup \{\neg p\}\vdash \bot$.Then by the deduction theorem, $S\vdash p$ and $S\vdash \neg p$. So $S\vdash \bot$.

  As a general rule of mathematics, after doing it for one thing, we do it for infinitely many things.

  Now we suppose $L$ is countable. So we can list $L$ as $\{t_1, t_2, \cdots\}$.

  Let $S_0 = S$. Then let $S_1 = S\cup \{t_1\}$ or $S\cup \{\neg t_1\}$ such that $S_1$ is consistent, and let $S_2 = S_1 \cup \{t_2\}$ or $S_1\cup \{\neg t_2\}$ such that $S_2$ is consistent. Continue inductively.

  Set $\bar{S} = S_0\cup S_1\cup S_2\cdot$. Then $p\in \bar{S}$ or $\neg p\in \bar{S}$ for each $p\in l$ by construction. Also $\bar S$ is consistent (If $\bar S\vdash \bot$, then some $S_n\vdash \bot$ since proofs are finite, but all $S_n$ are consistent). Finally, we check that $\bar S$ is deductively closed, since if $\bar S\models p$, and $p\not\in \bar S$, then $\neg p\not\in \bar S$. Then $\bar S$ would be inconsistent.

  Define $v: L\to \{0, 1\}$ by
  \[
    p \mapsto
    \begin{cases}
      1 & \text{if }p\in \bar S\\
      0 & \text{if not}
    \end{cases}.
  \]
  We claim this is a valuation:

  $v(\bot) = 0$ as $\bot \not\in \bar S$ (since $\bar S$ is consistent).

  For $p\Rightarrow q$,
  \begin{enumerate}
    \item If $v(p) = 1, v(q) = 0$, we have $p\in \bar S$, $q\not\in \bar S$. We want to show $p\Rightarrow q\not\in \bar S$. But if $p\Rightarrow q\in \bar S$, then $\bar S \vdash q$ by MP. Hence $q\in \bar S$ since $\bar S$ is deductively closed.
    \item If $v(q) = 1$, then $q\in \bar S$. We want $p\Rightarrow q\in \bar S$. But $\vdash p\Rightarrow (p\Rightarrow q)$ (Axiom 1). So $p\Rightarrow q \in \bar S$ by deductive closure.
    \item If $v(p) = 0$, then $p\not\in \bar S$. So $\neg p\in \bar S$, and we want $p\Rightarrow q\in \bar S$. So we want to show $\neg p\vdash p\Rightarrow q$. By the deduction theorem, this is equivalent to $\{p, \neg p\} \vdash q$. But $\{p, \neg p\}\vdash \bot$. So it is enough to show $\bot \vdash q$. But $\bot \models \neg \neg q$ by Axiom 1 (since $\bot \Rightarrow (\neg q\Rightarrow \bot)$). It is a theorem that $\neg \neg q\Rightarrow q$. So $\bot \vdash q$. 
  \end{enumerate}
\end{proof}
Note that this is the place where we really use Axiom 3 for the first time.

However, what if the primitives $P$ are not countable? (eg. $P = \{p_r: r\in \R\}$) This proof would not work, and we will need Zorn's Lemma (cf. later lectures).

By remark before our theorem, we have
\begin{cor}[Adequacy theorem]
  Let $S\subset L$, $t\in L$. Then $S\models t$ implies $S\vdash t$. 
\end{cor}

\begin{thm}[Completeness theorem]
  Le $S\subset L$ and $t\in L$. Then $S\models t$ if and only if $S\vdash t$.
\end{thm}

\begin{proof}
  ($\Leftarrow$): Soundness. ($\Rightarrow $) Adequacy.
\end{proof}

This has two nice consequences.
\begin{cor}[Compactness theorem]
  Let $S\subset L$ and $t\in L$ with $S\models t$. The some finite $S'\subset S$ has $S'\models t$.
\end{cor}

\begin{proof}
  Trivial with $\models$ replaced by $\vdash$, because proofs are finite.
\end{proof}
The special case $t = \bot$ says, if every finite subset of $S$ has a models, then $S$ has a model. This is also called the compactness theorem.

\begin{cor}[Decidability theorem]
  Let finite $S\subset L$, $t\in L$. Then there exists an algorithm that determines, in finite time, whether or not $S\vdash t$.
\end{cor}
This is \emph{very} surprising because proofs are HARD TO FIND!
\begin{proof}
  Trivial with $\vdash$ replaced by $\models$, by making a truth table.
\end{proof}
\section{Well-orderings and ordinals}
\begin{defi}[Total order]
  A \emph{total order} or \emph{linear order} is a pair $(X, <)$, where $X$ is a set $<$ is a relation on $X$ that is
  \begin{enumerate}
    \item Irreflexive: Not $x < x$ for all $x$.
    \item Transitive: If $x < y$, $y < z$, then $x < z$.
    \item Trichotomous: $x < y$ or $x = y$ or $y < x$ (can't have more than one is true because if $x < y$ and $y < x$, then $x < x$.)
  \end{enumerate}
\end{defi}

\begin{eg}\leavevmode
  \begin{enumerate}
    \item $\N$ with usual $<$. (Note: $\N = \{0, 1, \cdots\}$. We write $\N_+$ for $\N\setminus\{0\}$)
    \item $\Z, \Q, \R$ with usual $<$.
    \item On $\N_+$, `$x < y$' if $x|y$ and $x \not=y$ is not trichotomous so not a total order.
    \item On $\P(S)$, define `$x<y$' if $x\subsetneq y$. This is not a total order since it is not trichotomous (for $|X| > 1$)
  \end{enumerate}
\end{eg}

\begin{notation}
  Write $x \leq y$ if $x < y$ or $x = y$; $x > y$ if $y < x$ etc.
\end{notation}

In terms of $\leq$, a total order can be defined as
\begin{defi}[Total order (v2)]
  A total order is:
  \begin{enumerate}
    \item Reflexive: $x \leq x$
    \item Transitive: $x\leq y$ and $y \leq z$ implies $x\leq z$.
    \item Antisymmetric: $x\leq y$ and $y\leq x$ implies $x = y$.
    \item Trichotomous: $x\leq y$ or $y\leq x$.
  \end{enumerate}
\end{defi}

\begin{defi}[Well order]
  A total order $(X, <)$ is a \emph{well-ordering} if every (non-empty) subset has a least element, ie.
  \[
    \forall S\subseteq X\; [S\not= \emptyset \Rightarrow  \exists x\in S (\forall y\in F:\; y \geq x)].
  \]
\end{defi}

\begin{eg}
  \begin{enumerate}
    \item $\N$ with use ordering is a well order
    \item $\Z, \Q, \R$ are not well-ordered because the whole set itself does not have a least ordering.
    \item $\{X\in \Q: x\geq 0\}$ is not well-ordered. eg. $\{x\in X: x> 0\}$ has no least element.
    \item In $\R$, $\{1 - 1/n: n = 2, 3, 4, \cdots\}$ is well-ordered because it is isomorphic to the naturals.
    \item $\{1- 1/n: n = 2, 3, 4, \cdots\} \cup \{1\}$ is also well-ordered (if the subset is only $1$, then $1$ is the least element. Otherwise take the least element of the remaining set).
    \item Similarly, $\{1 - 1/n: n = 2, 3, 4, \cdots\}\cup \{2\}$ is well-ordered.
    \item $\{1 - 1/n: n = 2, 3, 4, \cdots\} \cup \{2 - 1/n: n = 2, 3, 4, \cdots\}$ is also well-ordered. This is a good example to keep in mind.
  \end{enumerate}
\end{eg}

\begin{prop}
  A total order is a well ordering if and only if it has no infinite strictly decreasing sequence.
\end{prop}

\begin{proof}
  If $x_1 > x_2 > x_3 > \cdots$, then $\{x_i: i\in \N\}$ has no least element.

  Conversely, if non-empty $S\subset X$ has no least element, then each $x\in S$ have $x'\in S$ with $x' < x$. Then $\exists x'': x'' < x'$, \emph{ad infinitum}. So 
  \[
    x > x' > x'' > x''' > \cdots
  \]
\end{proof}

\begin{defi}[Order isomorphism]
  Say the total orders $X, Y$ are \emph{isomorphic} if $\exists$ bijection $f: X\to Y$ that is order-preserving, ie. $x < y \Rightarrow  f(x) < f(y)$. (This is the same as $x < y \Leftrightarrow f(x) < f(y)$ due to trichotomy)
\end{defi}

\begin{eg}\leavevmode
\begin{enumerate}
  \item $\N$ and $\{1 - 1/n: n = 2, 3, 4, \cdots\}$ are isomorphic.
  \item $\{1 - 1/n:n = 2, 3, 4, \cdots\}\cup \{1\}$ is isomorphic to $\{1 = 1/n: n = 2, 3, 4, \cdots\} \cup \{2\}$.
  \item $\{1 - 1/n: n = 2, 3, 4, \cdots\}$ and $\{1 - 1/n: n = 2, 3, 4, \cdots\}\cup \{1\}$ are not isomorphic because the second has a least element but the first doesn't.
\end{enumerate}
\end{eg}

\begin{prop}[Proof by induction]
  Let $X$ be a well-ordered set. Suppose $S \subseteq X$ has the property:
  \[
    (\forall y < x: y\in S) \Rightarrow x\in S,
  \]
  then $S = X$.
  Equivalently, if a property $P(x)$ has
  \[
    (\forall y < x: P(x))\Rightarrow P(x),
  \]
  then $P(x)$ for all $x$.
\end{prop}

\begin{proof}
  Suppose $S\not=X$. Let $x$ be the least element of $X\setminus S$. Then $\forall y < x: y\in S$ by minimality of $x$. Hence $x\in S$.
\end{proof}

A typical application of proof by induction:
\begin{prop}
  Let $X$ and $Y$ be isomorphic well-orderings. Then there is a unique isomorphism between $X$ and $Y$.

  \note This is not true for general total orderings, eg. $\Z\to \Z$ has the following isomorphisms: $x\mapsto x$ and $x\mapsto x - 13$ are both isomorphisms.
\end{prop}

\begin{proof}
  Let $f$ and $g$ be two isomorphisms $X\to Y$. To show that $f = g$, it is enough, by induction, to show $f(x) = g(x)$ given $f(y) = g(y)$ for all $y < x$.

  Put $S = \{f(y): y < x\}$. Let $a$ be the least member of $Y\setminus S$ ($S\not= Y$ as $f(x) \not\in S$). Then we must have $f(x) = a$. Or else, some $x ' > x$ has $f(x') = a < f(x)$ since $f$ is a bijection, which contradicts $f$ order-preservingness.

  Similarly, $g(x) = a$ (since $S$ also is $\{g(y): y < x\}$ by induction hypothesis).
\end{proof}


\begin{defi}[Initial segment]
  A subset $Y$ of a totally ordered $X$ is an \emph{initial segment} if
  \[
    x\in Y, y< x \Rightarrow  y\in Y,
  \]
  ie. the ``bottom part'' of the $X$.
  \begin{center}
    \begin{tikzpicture}
     \begin{scope}
       \clip (0, 0) ellipse (0.5 and 1.3);
        \fill [gray] (-0.5, 0) rectangle (0.5, -1.3);
      \end{scope}
      \draw (0, 0) ellipse (0.5 and 1.3);
      \draw (-0.5, 0) -- (0.5, 0);
      \node at (0, -0.5) {$Y$};
      \node at (0.7, 1) {$X$};
    \end{tikzpicture}
  \end{center}
\end{defi}

\begin{eg}
  For any $x\in X$, the set $I_x = \{y\in x: y< x\}$ is an initial segment. However, not every initial segment of $X$ need to be in this form.

  For example, in $\R$, $\{x: x\leq 3\}$; in $\Q$, $\{x: x < 0\text{ or }x^2 < 2\}$ are both initial segments not of this form.
\end{eg}
However, in a well-ordered, every proper initial segment is of this form.
\begin{prop}
  Every initial segment of a well-ordered set $X$ is of the form $I_x = \{y\in X: y < x\}$.
\end{prop}

\begin{proof}
  Take $x = \min X\setminus Y$. Then $y < x\Rightarrow y\in Y$ by the definition of $x$.  Conversely, if $y\in Y$, then $y < x$ (since $y = x$ and $y > x$ both yield contradictions).
\end{proof}

We want to show that: In a well-ordering $X$, \emph{every} subset $S$ is isomorphic to an initial segment.

\note This is \emph{very} false for a general total order. eg. in $\Z$, take $\{1, 2, 3\}$, but every initial segment of $\Z$ is either infinite or empty. Or, in $\R$, take $\Q$.

It is intuitively obvious that we can do this by sending the minimum element of $S$ to the minimum of $X$, and the continue recursively. However, if we have, say, the double-infinite well-order, then we will never reach the second infinite set. So we need some sort of ``infinite recursion'' that allows us to continue our recursion after infinite time.

We first define the restriction of a function:
\begin{defi}[Restriction of function]
  For $f: A\to B$ and $C\subseteq A$, the \emph{restriction}  of $f$ to $C$ is 
  \[
    f|_C = \{(x, f(x): x\in C\}.
  \]
\end{defi}

\begin{thm}[Definition by recursion]
  Let $X$ be a well-ordered set and $Y$ be any set. Then for any function $G: \P(X\times Y)\to Y$, $\exists f:X\to Y$ such that
  \[
    f(x) = G(F|_{I_x})
  \]
  for all $x$.

  Intuitively, $G$ takes previous values of $f(x)$ and outputs the desired output.

  ``In defining $f$ at $x$, we are allowed to make use of values of $f$ on $I_x$. (eg. $f(x) = nf(n - 1)$ for the factorial function, with $f(0) = 1$)
\end{thm}

\begin{proof}
  We might want to jump into the proof and define $f(0) = G(\emptyset)$, where $0$ is the minimum element, then $f(1) = G(f(0))$ etc., but doing so is simply recursion, which is the thing we want to prove that works!

  Instead, we use the following clever trick: We define an ``$h$ is an attempt'' to mean
  \begin{center}
    $h: I \to Y$, for some initial segment $I$ of $X$, and $h(x) = G(h|_{I_x})$ for $x\in I$.
  \end{center}
  Then we can show that for any $x$, there is an attempt $h$ that is defined at $x$. Then take the value $f(x)$ to be $h(x)$. However, we must show this is well-defined first:

  If attempts $h$ and $h'$ are defined at $x$, then $h(x) = h'(x)$. By induction on $x$, it is enough to show that $h(x) = h'(x)$ assuming $h(y) = h'(y)$ for all $y < x$. But then $h(x) = G(h|_{I_x}) = G(h'|_{I_x}) = h'(x)$.

  Now let's show that for any $x$, there must exist an attempt $h$ that is defined at $x$. Indeed, we may assume (by induction) that for each $y < x$, $\exists$ an attempt $h_y$ defined at $y$. wlog, $h_y$ is defined on all $z \leq y$. Then we put all these functions together, and take $h' = \bigcup_{y < x} h_y$. This is defined for all $y < x$, and is well-defined since the $h_y$ never disagree.

  Finally, add to it $(x, G(h'|_{I_x}))$. Then $h = h'\cup (x, G(h'|_{I_x}))$ is an attempt defined at $x$.

  Now define $f:X\to Y$ by $f(x) = y$ if $\exists$ attempt $h$, defined at $x$, with $h(x) = y$.

  We finally show uniqueness by induction of $x$: suppose $f$ and $f'$ both work. Then if $f(y) = f'(y)$ for all $y < x$, then $f(x) = f'(x)$ by definition. So for all $x$, $f'(x) = f(x)$.
\end{proof}
Now we prove our statement above:
\begin{prop}[Subset collapse]
  Let $X$ be a well-ordering and let $Y\subseteq X$. Then $Y$ is isomorphic to an initial segment of $X$. Moreover, this initial segment is unique.
\end{prop}

\begin{proof}
  For $f: Y\to X$ to be an order-preserving bijection with an initial segment of $X$, we need to map $x$ to the smallest thing not yet mapped to, ie. 
  \[
    f(x) = \min X\setminus \{f(y): y\in Y, y < x\}.
  \]
  (Note: we don't have $\{f(y): y\in Y, y < x\} = X$ because $f(z) \leq z$ for all $z\in Y$ by induction, hence $x$ is not that set)

  Then by the recursion theorem, this function exists and is uniqueness.
\end{proof}
\note So a well-ordered $X$ can \emph{never} be isomorphic to a proper initial segment of $X$, because $X$ is isomorphic to $X$ itself, and uniqueness shows that it cannot be isomorphic to something else.

How do different well-orderings compare?
\begin{notation}
  Write $X\leq Y$ if $X$ is isomorphic to an initial segment of $Y$.
\end{notation}

\begin{eg}
  If $X = \N$, $Y = \{\frac{1}{2}, \frac{2}{3}, \frac{3}{4},\cdots\}\cup \{1\}$, then $X \leq Y$.
\end{eg}

\begin{thm}
  Let $X, Y$ be well-orderings. Then $X\leq Y$ or $Y \leq X$.

  This is ``the best we can hope for''. We cannot find anything analogous for, say, groups.
\end{thm}

\begin{proof}
  Suppose $Y \not\leq X$. For $f: X\to Y$ to be an isomorphism with an initial segment of $Y$, we need $f(x) = \min Y\setminus \{f(y): y < x\}$. We have to make sure that $Y\setminus \{f(y): y < x\}\not= \emptyset$, i.e. $\{f(y): y < x\} \not= Y$. This is true because if we really had $Y = \{f(y): y < x\}$, then we have constructed an isomorphism from $Y$ to an initial segment of $X$.
\end{proof}

\begin{thm}
  Let $X, Y$ be well-orderings with $X\leq Y$ and $Y \leq X$. Then $X$ and $Y$ are isomorphic.
\end{thm}

\begin{proof}
  We have isomorphisms $f: X\to \text{initial segment of }Y$ and $g: Y\to \text{initial segment of }X$. Then $g\circ f: X\to X$ is an isomorphism from $X$ to an initial segment of $X$ (as an initial segment of an initial segment of $X$ is an initial segment of $X$).

  Recall that $X$ is isomorphic to no proper initial segment of $X$. So $g\circ f$ has image $X$. Similarly, $f\circ g$ is a bijection. So $f$ and $g$ must be bijections.
\end{proof}

\subsection{New well-orderings from old}
We write $X < Y$ if $X\leq Y$ but $X$ is not isomorphic to $Y$, ie. $X$ is isomorphic to a proper initial segment of $Y$.

\subsubsection*{Add one element}
\begin{defi}[Successor]
  Given $X$, choose some $x\not\in X$ and define a well-ordering on $X\cup \{x\}$ by setting $y < x$ for all $y \in X$. This is the \emph{successor} of $X$, written $X^+$.
\end{defi}
Clearly $X < X^+$.
\subsubsection*{Put some together}
\begin{defi}[Extension]
  For well-orderings $(X, <_X)$ and $(Y, <_Y)$, we say $Y$ \emph{extends} $X$ iff $Y > X$, $<_X$ and $<_Y$ agree when defined, and $X$ is an initial segment of $Y$.
\end{defi}

\begin{defi}[Nested family]
  We say well-orderings $(X_i: i\in I)$ form a \emph{nested} family if $\forall i, j\in I$, either $X_i$ extends $X_j$, or $X_j$ extends $X_i$.
\end{defi}

\begin{prop}
  Let $\{X_i: i\in I\}$ be a nested set of well-orderings. Then there exists a well-ordering $X$ with $X\leq X_i$ for all $i$.
\end{prop}
\note This is still true if the $X_i$ are not nested, but the resulting $X$ will not simply be the union of all $X_i$.

\begin{proof}
  Let $X = \bigcup_{i\in I}X_i$ with $<$ defined on $X$ by $< = \bigcup_{i\in I} <_i$ (where $<_i$ is the orderings of $X_i$), i.e. inherit the orders from the $X_i$s. This is a total ordering.

  To see if it is a well-ordering, let $S\subseteq X$ be a non-empty subset of $X$.

  Then $S\cap X_i$ is non-empty for some $i$. Let $x$ be the minimum element (in $X_i$) of $S\cap X_i$. Then also $x \leq y$ for all $y\in S$, as  $X_i$ is an initial segment of $X$.
\end{proof}
This is why we require $X$ to be an initial segment of $Y$ when we define extension. Or else we can take the collection of all subsets $X_n = \{x \geq -n: x\in \Z\}$, and their union would be $\Z$, which is not well-ordered.

\subsection{Ordinals}
Is the collection of all well-orderings (up to isomorphism) itself a well-ordering? We have already shown that it is a total orders.

\begin{defi}[Ordinal]
  An \emph{ordinal} is a well-ordered set, with two regarded as the same if they are isomorphic. We write ordinals as Greek letters $\alpha, \beta$ etc.

  (cf. the rationals consist of all expressions $\frac{m}{n}$, with two regarded as the same if $mn' = nm'$)
\end{defi}
We would want to define ordinals as equivalence classes, but we cannot, because they do not form a set. We will provide a formal treatment later.

\begin{defi}[Order type]
  If a well-ordering $X$ has corresponding ordinal $\alpha$, we say $X$ has \emph{order type} $\alpha$.
\end{defi}

\begin{notation}
  For each $k\in \N$, we write $k$ for the order type of the (unique) well-ordering of size $k$.

  We write $\omega$ for the order type of $\N$.
\end{notation}

\begin{eg}
  In $\R$, $\{2, 3, 5 ,6\}$ has order type 4.

  $\{\frac{1}{2}, \frac{2}{3}, \cdots\}$ has order type $\omega$.
\end{eg}

\begin{notation}
  For ordinals $\alpha, \beta$, write $\alpha \leq \beta$ if $X\leq Y$ for some $X$ of order type $\alpha$, $Y$ of order type $\beta$. This does not depend on the choice of $X$ and $Y$ (since any two choices must be isomorphic).

  We define $\alpha^+$ similarly.
\end{notation}

\begin{prop}
  Let $\alpha$ be an ordinal. Then the ordinals $<\alpha$ form a well-ordering of order type $\alpha$.
\end{prop}

\begin{notation}
  Write $I_\alpha = \{\beta: \beta < \alpha\}$. This is a nice set of order type $\alpha$.
\end{notation}

\begin{proof}
  Let $X$ have order type $\alpha$. The well-orderings $< X$ are precisely (up to isomorphism) the proper initial segments of $X$ (by uniqueness of subset collapse). But these are the $I_x$ for all $x\in X$. These are order-isomorphic to $X$ via $x\mapsto I_x$.
\end{proof}

\begin{prop}
  Let $S$ be a non-empty set of ordinals. Then $S$ has a least element.
\end{prop}

\begin{proof}
  Choose $\alpha\in S$. If it is minimal, done.

  If not, then $S\cap I_\alpha$ is non-empty. But $I_\alpha$ is well-ordered (proposition above). So $S\cap I_\alpha$ has a least element, $\beta$. Then this is a minimal element of $S$
\end{proof}

\begin{thm}[Burali-Forti paradox]
  The ordinals do not form a set.
\end{thm}

\begin{proof}
  Suppose not. Let $X =$ set of ordinals. Then $X$ is a well-ordering. Let its order-type be $\alpha$. Then $X$ is isomorphic to $I_\alpha$, a proper initial subset of $X$. Contradiction
\end{proof}
\note Any set $\{\alpha_i: i\in I\}$ of ordinals has an upper bound ($\alpha$ with $\alpha \geq \alpha_i$ for all $i$). We can apply ``nested well-orders'' to the initial segments $\{I_{\alpha_i}: i\in I\}$. Hence it has a \emph{least} upper bound, $\sup\{\alpha_i: i\in I\}$.

\begin{eg}
  $\{2, 4, 6, 8, \cdots\}$ has supremum $\omega$.
\end{eg}

Now we have two ways of producing ordinals: $+1$ and supremum.

We can generate a lot of ordinals now:

\noindent\begin{tabular}{ccccccc}
  0                                 & $\omega\cdot 2 + 1$             & $\omega^2 + 1$                           & $\omega^2\cdot 3$     & $\omega^{\omega + 2}$                    & $\epsilon_0 + 1$                                 \\
  1                                 & $\omega\cdot 2 + 2$             & $\omega^2 + 2$                           & $\omega^2\cdot 4$     & \vdots                                   & \vdots                                           \\
  2                                 & $\omega\cdot 2 + 3$             & $\omega^2 + 3$                           & $\omega^2\cdot 5$     & $\omega^{\omega \cdot 2}$                & $\epsilon_0 \cdot 2$                             \\
  \vdots                            & \vdots                          & \vdots                                   & \vdots                & \vdots                                   & \vdots                                           \\
  $\omega$                          & $\omega\cdot 3$                 & $\omega^2 + \omega$                      & $\omega^3$            & $\omega^{\omega^2}$                      & $\epsilon_0^2$                                   \\
  $\omega + 1$                      & $\omega\cdot 4$                 & \vdots                                   & \vdots                & \vdots                                   & \vdots                                           \\
  $\omega + 2$                      & $\omega\cdot 5$                 & $\omega^2 + \omega \cdot 2$              & $\omega^\omega$       & $\omega^{\omega^{\omega}}$               & $\epsilon_0^{\epsilon_0}$                        \\
  \vdots                            & \vdots                          & \vdots                                   & \vdots                & \vdots                                   & \vdots                                           \\
  $\omega + \omega = \omega\cdot 2$ & $\omega\cdot \omega = \omega^2$ & $\omega^2 + \omega^2 = \omega^2 \cdot 2$ & $\omega^{\omega + 1}$ & $\omega^{\omega^{.^{.^.}}} = \epsilon_0$ & $\epsilon_0^{\epsilon_0^{.^{.^.}}} = \epsilon_1$ \\
\end{tabular}

Note that officially, $\omega + 1 = \omega^+$, and $\omega \cdot 2= \sup\{\omega, \omega + 1, \omega + 2, \cdots\}$.

All ordinals above are countable, because they are all countable union of countable sets.

Is there an uncountable ordinal? We can well-order $\N$ and $\Q$.

\begin{thm}
  There is an uncountable ordinal.
\end{thm}

\begin{proof}
  We look at the supremum of the set of all countable ordinals. This works only if the collection of countable ordinals is a set.

  Let $A = \{R\in \P(\N\times \N): R \text{ is a well-ordering of a subset of }\N\}$. So $A \subseteq \P(\N\times \N)$. Then $B = \{\text{order type of }R: R\in A\}$ is the set of countable ordinals.
  
  Let $\omega_1 = \sup B$. Then $\omega$ is uncountable. Indeed, if $\omega_1$ is countable, then it is the greatest countable ordinal, but $\omega_1 + 1$ is greater and is also countable.
\end{proof}

\note $\omega_1$ is the \emph{least} uncountable ordinal, by definition, and everything in our previous big list of ordinals is less than $\omega_1$.

There are two strange properties of $\omega_1$:
\begin{enumerate}
  \item $\omega_1$ is an uncountable ordering, yet for every $x\in \omega_1$, the set $\{y: y< x\}$ is countable.
  \item Every sequence in $\omega_1$ is bounded, since its supremum is a countable union of countable sets, which is countable.
\end{enumerate}
In general, we have the following:
\begin{thm}[Hartogs' lemma]
  For any set $X$, there is an ordinal that does not inject into $X$.
\end{thm}

\begin{proof}
  As before, with $B = \{\alpha: \alpha\text{ injects into }X\}$.
\end{proof}

\begin{notation}
  Write $\gamma(X)$ for the least ordinal that does not inject into $X$. eg. $\gamma(\omega) = \omega_1$.
\end{notation}

\subsection{Successors and limits}
Given an ordinal $\alpha$, is there a greatest element of $\alpha$? (ie. does $I_\alpha = \{\beta: \beta < \alpha\}$ have a greatest element?)

If yes, say $\beta$ is the greatest element. Then $\gamma\in I_\alpha \Leftrightarrow \gamma \leq \beta$. So $I_\alpha = \{\beta\}\cup I_\beta$, i.e. $\alpha = \beta^+$.

\begin{defi}[Successor ordinal]
  An ordinal $\alpha$ is a \emph{successor ordinal} if there is a greatest element $\beta$ below it. Then $\alpha = \beta^+$.
\end{defi}

On the other hand, if no, then $\forall \gamma < \alpha, \exists \beta < \alpha$ with $\beta > \gamma$. So $\alpha = \sup \{\beta: \beta < \alpha\}$.
\begin{defi}[Limit ordinal]
  An ordinal $\alpha$ is a limit if it has no greatest element below it. We usually write $\lambda$ for limit ordinals.
\end{defi}

\begin{eg}
  $5$ and $\omega^+$ are successors. $\omega$ and $0$ are limits ($0$ is a limit because it has no element below it, let alone a greatest one!)
\end{eg}

\subsection{Ordinal arithmetic}
We want to define ordinals arithmetic such as $+$ and $\times$, so that we can make formal sense out of our notations $\omega + \omega$ in our huge list of ordinals.

\begin{defi}[Ordinal addition (inductive)]
  Define $\alpha + \beta$ by recursion on $\beta$ ($\alpha$ is fixed):
  \begin{itemize}
    \item $\alpha + 0 = \alpha$.
    \item $\alpha + \beta^+ = (\alpha + \beta)^+$.
    \item $\alpha + \lambda = \sup \{\alpha + \gamma: \gamma < \lambda\}$ for non-zero limit $\lambda$.
  \end{itemize}
\end{defi}

\begin{eg}
  $\omega + 1 = (\omega + 0)^+ = \omega^+$.

  $\omega + 2 = (\omega + 1)^+ = \omega^{++}$.

  $1 + \omega = \sup\{ 1 + n: n \leq \omega\} \sup\{1, 2, 3, \cdots\} = \omega$.
\end{eg}
So addition is not commutative! This asymmetry arises from our decision to perform recursion on $\beta$ instead of $\alpha$.

\note ``Recursion on the ordinals'' isn't formally allowed because the ordinals do not form a set. Officially, we mean: define $\alpha + \gamma$ on $\{\gamma: \gamma \leq \beta\}$ (which is a set) for each $\beta$. We use the uniqueness of recursion to make sure this is well-defined.

We do this similarly for induction. If $(\forall \beta < \alpha: p(\beta)) \Rightarrow  p(\alpha)$, then if we have $\alpha$ with $p(\alpha)$ false, then $p(\beta)$ is not always true on $\{\beta: \beta \leq \alpha\}$.

\begin{prop}
  Addition is associative, i.e. $(\alpha + \beta) + \gamma = \alpha + (\beta + \gamma)$.
\end{prop}

\begin{proof}
  Since we define addition by recursion, it makes sense to prove this by induction. Since we recursed on the right-hand term in the definition, it only makes sense to induct on $\gamma$ (and fix $\alpha + \beta$).

\begin{enumerate}
  \item If $\gamma = 0$, then $\alpha + (\beta + 0) = \alpha + \beta = (\alpha + \beta) + 0$.
  \item If $\gamma = \delta^+$ is a successor, then 
    \begin{align*}
      \alpha + (\beta + \delta^+) &= \alpha + (\beta + \delta)^+\\
      &= [\alpha + (\beta + \delta)]^+\\
      &= [(\alpha + \beta) + \delta]^+\\
      &= (\alpha + \beta) + \delta^+\\
      &= (\alpha + \beta) + \gamma.
    \end{align*}
  \item If $\gamma$ is a limit ordinal, we have
    \begin{align*}
      (\alpha + \beta) + \lambda &= \sup\{(\alpha + \beta) + \gamma: \gamma < \lambda\}\\
      &= \sup\{\alpha + (\beta + \gamma): \gamma < \lambda\}
    \end{align*}
    If we want to evaluate $\alpha + (\beta + \lambda)$, we have to first know whether $\beta + \lambda$ is a successor or a limit. We now claim it is a limit:

    $\beta + \lambda = \sup\{\beta + \gamma: \gamma < \lambda\}$. This cannot have a greatest element because $\gamma < \gamma' \Rightarrow \beta + \gamma < \beta + \gamma'$, and for each $\beta + \gamma$, we can find a $\gamma' > \gamma$ (because $\lambda$ is a limit) and then $\beta + \gamma' > \beta + \gamma$.

    So
    \[
      \alpha + (\beta + \lambda) = \sup\{\alpha + \delta: \delta < \beta + \lambda\}.
    \]
    We need to show that
    \[
      \sup\{\alpha + \delta: \delta < \beta + \lambda\} = \sup\{\alpha + (\beta + \gamma): \gamma < \lambda\}.
    \]
    Note that the two sets are not equal. For example, if $\beta = 3$ and $\lambda = \omega$, then the left contains $\alpha + 2$ but the right does not.

    So we show that the left is $\geq$ the right and the right is $\geq$ the left.

    $\geq$: Each element of the right hand set is an element of the left.

    $\leq$: For $\delta < \beta + \lambda$, we have $\delta < \sup \{\beta + \gamma: \gamma < \lambda\}$. So $\delta < \beta + \gamma$ for some $\gamma < \lambda$. Hence $\alpha + \delta < \alpha + (\beta + \gamma)$.
\end{enumerate}
\end{proof}
\note  We prove $\beta \leq \gamma \Rightarrow  \alpha + \beta \leq \alpha + \gamma$ by induction on $\gamma$. Hence $\beta < \gamma \Rightarrow  \alpha + \beta < \alpha + \gamma$. But it is not true the other way round: $1 < 2$ but $1 + \omega = 2 + \omega$.

The above definition is called the \emph{inductive} definition. There is also a synthetic definition of $+$.

Intuitively, we first write out all the elements of $\alpha$, then write out all the elements of $\beta$ after it. The $\alpha + \beta$ is the order type of the combined mess.

\begin{defi}[Ordinal addition (synthetic)]
  $\alpha + \beta$ is the order type of $\alpha \sqcup \beta$ ($\alpha$ disjoint union $\beta$, eg. $\alpha\times \{0\}\cup \beta\times \{1\}$), with all $\alpha$ before all of $\beta$
  \[
    \alpha + \beta = \underbracket{\quad\quad\vphantom{\beta}\alpha\vphantom{\beta}\quad\quad}\underbracket{\quad\;\beta\;\quad}
  \]
\end{defi}
\begin{eg}
  $\omega + 1 = \omega^+$.

  $1 + \omega = \omega$.
\end{eg}

With this definition, associativity is trivial:.
\[
  \alpha + (\beta + \gamma) = \underbracket{\quad\quad\vphantom{\beta}\alpha\vphantom{\beta}\quad\quad}\underbracket{\quad\;\beta\;\quad}\underbracket{\quad\gamma\quad} = (\alpha + \beta) + \gamma.
\]

With two definitions, we must show that they are the same:
\begin{prop}
  The inductive and synthetic definition of $+$ coincide.
\end{prop}

\begin{proof}
  Write $+$ for inductive definition, and $+'$ for synthetic. We want to show that $\alpha + \beta = \alpha +' \beta$. We induct on $\beta$.

  \begin{enumerate}
    \item $\alpha + 0 = \alpha = \alpha +' $.
    \item $\alpha + \beta^+ = (\alpha + \beta)^+ = (\alpha +' \beta)^+ = \otp\underbracket{\quad\vphantom\beta\alpha\vphantom\beta\quad}\underbracket{\quad\beta\quad}\underbracket{\vphantom\beta\cdot\vphantom\beta} = \alpha +' \beta^+$
    \item $\alpha + \lambda = \sup\{\alpha + \gamma: \gamma < \lambda\} = \sup \{\alpha +' \gamma: \gamma < \lambda\} = \alpha +' \lambda$, because $\sup = $ union as the $\alpha +' \gamma$ are nested.
      \[
        \underbracket{\quad\vphantom\gamma\alpha\vphantom\gamma\quad}\underbracket{\gamma\quad\gamma'\;\gamma''\cdots \lambda}
      \]
  \end{enumerate}
\end{proof}
The synthetic definition is usually easier to work with, if possible. However, in some cases, we must use induction (eg. for $\varepsilon_0$). In this case, we can use the inductive definition.

\begin{defi}[Ordinal multiplication (inductive)]
  We define $\alpha\cdot \beta$ by induction on $\beta$ by:
  \begin{enumerate}
    \item $\alpha\cdot 0 = 0$.
    \item $\alpha\cdot (\beta^+) = \alpha\cdot \beta + \alpha$.
    \item $\alpha\cdot \lambda = \sup\{\alpha\cdot \gamma: \gamma < \lambda\}$ for $\lambda$ a non-zero limit.
  \end{enumerate}
\end{defi}

\begin{eg}\leavevmode
  \begin{itemize}
    \item $\omega \cdot 1 = \omega\cdot 0 + \omega = 0 + \omega = \omega$.
    \item $\omega \cdot 2 = \omega \cdot 1 + \omega = \omega + \omega$.
    \item $2\cdot \omega = \sup\{2\cdot n: n < \omega\} = \omega$.
    \item $\omega\cdot \omega = \sup \{\omega\cdot n: n < \omega\} = \sup\{\omega, \omega^2, \omega^3, \cdots\}$.
  \end{itemize}
\end{eg}

We also have a synthetic definition.
\begin{defi}[Ordinal multiplication (synthetic)]
  \[
    \beta\left\{
      \begin{array}{c}
        \underbracket{\quad\alpha\quad} \\
        \vdots \\
        \underbracket{\quad\alpha\quad} \\
        \underbracket{\quad\alpha\quad}
      \end{array}\right.
    \]
  Formally, $\alpha\cdot \beta$ is the order type of $\alpha\times \beta$, with $(x, y) < (x', y')$ if $y < y'$ or $y = y'$ and $x < x'$.
\end{defi}

\begin{eg}
  $\displaystyle\omega\cdot 2 =
  \begin{array}{c}
    \underbracket{\quad\omega\quad}\\
    \underbracket{\quad\omega\quad}
  \end{array} = \omega + \omega$.

  Also $2\cdot \omega = \omega\left\{
  \begin{array}{c}
        \underbracket{\,\cdot\,\cdot\,} \\
        \vdots \\
        \underbracket{\,\cdot\,\cdot\,} \\
        \underbracket{\,\cdot\,\cdot\,} \\
      \end{array}\right. = \omega$
\end{eg}
We can check that the definitions coincide, $\alpha(\beta\gamma) = (\alpha\beta)\gamma$ etc.

We can define ordinal exponentiation, towers etc similarly:
\begin{defi}[Ordinal exponentiation (inductive)]
  $\alpha^\beta$ is defined as
  \begin{enumerate}
    \item $\alpha^0 = 1$
    \item $\alpha^{\beta^+} = \alpha^\beta \cdot \alpha$
    \item $\alpha^{\lambda} = \sup \{\alpha^\gamma: \gamma< \lambda\}$.
  \end{enumerate}
\end{defi}

\begin{eg}
  $\omega^1 = \omega^0\cdot \omega = 1\cdot \omega = \omega$.

  $\omega^2 = \omega^1\cdot \omega = \omega\cdot \omega$.

  $2^{\omega} = \sup \{2^n: n < \omega\} = \omega$.
\end{eg}
Some people write $\R = 2^{\N}$. But $\R$ is uncountable and $2^\omega = \omega$ is countable! This is because the definitions of exponentiation for set sizes and well-orderings are different.

\section{Posets and Zorn's lemma}
\begin{defi}[Partial ordering (poset)]
  A \emph{partial ordering} or \emph{poset} is a pair $(X, \leq)$, where $X$ is a set and $\leq$ is a relation on $X$ that is
  \begin{enumerate}
    \item Reflexive: $x\leq x$ for all $x\in X$
    \item Transitive: $x \leq y$ and $y \leq z \Rightarrow x \leq z$.
    \item Antisymmetric: $x \leq y$ and $y \leq x \Rightarrow x = y$.
  \end{enumerate}
  We write $x \leq y$ to mean $ x\leq y$ and $x\not= y$. We can also define posets in terms of $<$:
  \begin{enumerate}
    \item Irreflexive: $x \not< x$ for all $x\in X$.
    \item Transitive: $x < y$ and $y < z\Rightarrow  x < z$.
  \end{enumerate}
\end{defi}

\begin{eg}\leavevmode
  \begin{enumerate}
    \item Any totally order is (trivially) a partial order.
    \item $\N$ with ``$x\leq y$'' if $x | y$.
    \item $\P(S)$ with $\subseteq$ for any set $S$.
    \item Any subset of $\P(S)$.
    \item We can use a diagram
      \begin{center}
        \begin{tikzpicture}[grow=up]
          \node {a}
          child {
            node {b} edge from parent
            child {
              node {c} edge from parent
            }
          }
          child {
            node {d} edge from parent
            child {
              node {e} edge from parent
            }
          };
        \end{tikzpicture}
      \end{center}
      Where ``above'' means ``greater''. So $a \leq b\leq c$, $a \leq d\leq e$, and what follows by transitivity. This is a Hasse diagram.

      \begin{defi}[Hasse diagram]
        In general, a \emph{Hasse diagram} for a poset $X$ consists of a drawing of the points of $X$ in the plane with an upwards line from $x$ to $y$ if $y$ \emph{covers} $x$:
      \end{defi}
      \begin{defi}[Cover]
        In a poset, $y$ covers $x$ if $y \geq x$ and no $z$ has $y > z > x$.
      \end{defi}
      Hasse diagrams can be useful - eg. $\N$, or useless, eg. $\Q$.
    \item The following example shows that we cannot assign ``heights'' or ``ranks'' to posets:
      \begin{center}
        \begin{tikzpicture}
          \node (a) {$a$};
          \node[above=0.5 of a] (dummy1) {};
          \node[above=0.5 of dummy1] (dummy2) {};
          \node[above=0.5 of dummy2] (dummy3) {};
          
          \node[right=of dummy1] (d) {$d$} edge (a);
          \node[left=of dummy2] (b) {$b$} edge (a);
          \node[right=of dummy3] (e) {$e$} edge (d);
          \node [above=0.5 of dummy3] {$c$} edge (b) edge (e);
        \end{tikzpicture}
      \end{center}
    \item We can also have complicated structures:
      \begin{center}
        \begin{tikzpicture}[node distance=1]
          \node at (-1, 0) (a) {$a$};
          \node at (1, 0) (b) {$b$};
          \node at (-1, 1) (c) {$c$} edge (a) edge (b);
          \node at (1, 1) (d) {$d$} edge (a) edge (b);
          \node at (0, 2) {$e$} edge (c) edge (d);
        \end{tikzpicture}
      \end{center}
    \item Or the empty poset (nothing is less than anything else).
  \end{enumerate}
\end{eg}
While there are many examples of posets, all we care about are actually power sets and their subsets only.

\begin{defi}[Chain and antichain]
  In a poset, a subset $S$ is a \emph{chain} if it is totally ordered, i.e. for all $x$, $y$, $x\leq y$ or $y\leq x$. An \emph{antichain} is a subset in which no two things are related.
\end{defi}

\begin{eg}
  In $(\N, |)$, $1, 2, 4, 8, 16, \cdots$ is a chain.

  In (v), $\{a, b, c\}$ or $\{a, c\}$ are chains.

  $\R$ is a chain in $\R$.
\end{eg}

\begin{defi}[Upper bound and supremum]
  For $S\subset X$, an \emph{upper bound} for $S$ is an $x$ such that $\forall y\in S: x \geq y$.

  $x\in X$ is a \emph{least upper bound}, \emph{supremum} or \emph{join} of $S$, written $x = \sup S$ or $x = \bigvee S$, if $x$ is an upper bound for $S$, and $\forall y \in X$, if $y$ is an upper bound, then $y \geq x$.
\end{defi}

\begin{eg}\leavevmode
  \begin{enumerate}
    \item In $\R$, $\{x: x < \sqrt{2}\}$ has an upper bound $7$, and has a supremum $\sqrt{2}$.

    \item In (v) above, consider $\{a, b\}$. Upper bounds are $b$ and $c$. So $\sup  = b$. However, $\{b, d\}$ has no upper bound!
    \item In (vii), $\{a, b\}$ has upper bounds $c, d, e$, but has no \emph{least} upper bound.
  \end{enumerate}
\end{eg}

\begin{defi}[Complete poset]
  A poset $X$ is \emph{complete} if every $S\subseteq X$ has a supremum. In particular, it has a greatest element (ie. $x$ such that $\forall y: x \geq y$), namely $\sup X$, and least element (ie. $x$ such that $\forall y: x \leq y$), namely $\sup \emptyset$.
\end{defi}
\note This does \emph{not} require that $S$ is bounded above or non-empty. This is different to metric space completeness.

\begin{eg}\leavevmode
  \begin{itemize}
    \item $\R$ is not complete because $\R$ itself has no supremum.
    \item $[0, 1]$ is complete because every subset is bounded above, and so has a least upper bound. Also, $\emptyset$ has a supremum of $0$.
    \item $(0, 1)$ is not complete because $(0, 10)$ has no upper bound.
    \item $\P(S)$ For any $S$ is \emph{always} complete, because given any $\{A_i: i\in A\}$, where each $A_i\subseteq S$, $\bigcup A_i$ is its supremum.
  \end{itemize}
\end{eg}

Now we are going to derive fixed-point theorems for complete posets. We start with a few definitions:

\begin{defi}[Fixed point]
  A \emph{fixed point} of a function $f:X\to X$ is an $x$ such that $f(x) = x$.
\end{defi}

\begin{defi}[Order-preserving function]
  For a poset $X$, $f: X\to X$ is \emph{order-preserving} of $x \leq y \Rightarrow  f(x) \leq f(y)$.
\end{defi}

\begin{eg}\leavevmode
  \begin{itemize}
    \item On $\N$, $x\mapsto x + 1$ is order-preserving
    \item On $\Z$, $x\mapsto x - 1$ is order-preserving
    \item On $(0, 1)$, $x\mapsto \frac{1 + x}{2}$ is order-preserving (this is halving the distance to $1$).
    \item On $\P(S)$, let some fixed $i\in S$. Then $A\mapsto A\cup \{i\}$ is order-preserving.
  \end{itemize}
\end{eg}
Not every order-preserving $f$ has a fixed point (eg. first two above). However, we have
\begin{thm}[Knaster-Tarski fixed point theorem]
  Let $X$ be a complete poset, and $f: X\to X$ be a order-preserving function. Then $f$ has a fixed point.
\end{thm}

\begin{proof}
  To show that $f(x) = x$, we need $f(x) \leq x$ and $f(x) \geq x$. Let's not be too greedy and just want half of it:

  Let $E = \{x: x \leq f(x)\}$. Let $s = \sup E$. We claim that this is a fixed point, by showing $f(s) \leq s$ and $s \leq f(s)$.

  To show $s \leq f(s)$, we use the fact that $s$ is the least upper bound. So if $f(s)$ is also an upper bound, then $s \leq f(s)$. Now let $x \in E$. So $x\leq s$. Therefore $f(x) \leq f(s)$ by order-preservingness. Since $x \leq f(x)$ (by definition of $E$) $x \leq f(x) \leq f(s)$.

  To show $f(s) \leq s$, we simply have to show $f(s) \in E$, since $s$ is an upper bound. But we already know $s \leq f(s)$. By order-preservingness, $f(s) \leq f(f(s))$. So $f(s)\in E$ by definition.
\end{proof}
While this proof looks rather simple, we need to first establish that $s \leq f(s)$, then use this fact to show $f(s) \leq s$. If we decided to show $f(s) \leq s$ first, then we would fail!

This is a typical application of Knaster-Tarski:
\begin{cor}[Cantor-Schr\"oder-Bernstein theorem]
  Let $A, B$ be sets. Let $f: A\to B$ and $g: B\to A$ be injections. Then there is a bijection $h: A\to B$. 
\end{cor}

\begin{proof}
  We try to partition $A$ into $P$ and $Q$, and $B$ into $R$ and $S$, such that $f(P) = R$ and $g(S) = Q$. Then we let $h = f$ on $R$ and $g^{-1}$ on $Q$.

  Since $S = B\setminus R$ and $Q = A \setminus P$, so we want
  \[
    P = A\setminus g(B\setminus f(P))
  \]
  Since the function $A\setminus g(B\setminus f(P))$ from $\P(A)$ to $\P(A)$ is order-preserving. So done by Knaster-Tarski (and $\P(A)$ is complete).

  \begin{center}
    \begin{tikzpicture}
      \draw (-1, 0) ellipse (0.5 and 1.3);
      \draw (-1.5, 0) -- (-0.5, 0);
      \node at (-1, -0.5) {$Q$};
      \node at (-1, 0.5) {$P$};
      \draw (1, 0) ellipse (0.5 and 1.3);
      \draw (0.5, 0) -- (1.5, 0);
      \node at (1, -0.5) {$S$};
      \node at (1, 0.5) {$R$};
      \draw [->] (-0.4, 0.7) -- (0.4, 0.7) node [pos = 0.5, above] {$f$};
      \draw [->] (0.4, -0.7) -- (-0.4, -0.7) node [pos = 0.5, above] {$g$};
    \end{tikzpicture}
  \end{center}
\end{proof}

\begin{defi}[Maximal element]
  In a poset $X$, $x\in X$ is maximal if no $y\in X$ has $y > x$.
\end{defi}

\begin{eg}
  In
  \begin{center}
    \begin{tikzpicture}[grow=up]
      \node {a}
      child {
        node {b} edge from parent
        child {
          node {c} edge from parent
        }
      }
      child {
        node {d} edge from parent
        child {
          node {e} edge from parent
        }
      };
    \end{tikzpicture}
  \end{center}
  $c$ and $e$ are maximal
\end{eg}

Not every poset has a maximal element, eg. $\N, \Q, \R$. In each of these, not only are they incomplete. They have chains that are not bounded above.

\begin{thm}[Zorn's lemma]
  Assuming Axiom of Choice, let $X$ be a (non-empty) poset in which every chain has an upper bound. Then it has a maximal element.
\end{thm}
\note that ``non-empty'' is not strictly necessary, because if $X$ is an empty poset, then the empty chain has no upper bound. So the conditions can never be satisfied.

We ``hunt'' for the maximal element. We start with $x_0$. If it is maximal, done. If not, we find a bigger $x_1$. If $x_1$ is maximal, done. Otherwise, keep go on.

If we never meet a maximal element, then we have an infinite chain. This has an upper bound $x_\omega$. If this is maximal, done. If not, find $x_{\omega + 1}$. Keep going on.

We have not yet reached a contradiction. But suppose we never meet a maximal element. If $X$ is countable, and we reach $x_{\omega_1}$, then we have found uncountably many elements in a countable set!

Since the ordinals can be arbitrarily large (Hartog's lemma), if we never reach a maximal element, then we can get find more elements that $X$ has.


\begin{proof}
  Suppose not. So for each $x\in x$, we have $x'\in X$ with $x' > x$. We denote the-element-larger-than-$x$ by $x'$.

  We know that each chain $C$ has an upper bound, asy $u(C)$.

  Let $\gamma = \gamma(X)$, the ordinal-larger-than-$X$ by Hartog's lemma.

  We pick $x\in X$, and define $x_\alpha$ for $\alpha < \gamma$ recursively by
  \begin{itemize}
    \item $x_0 = x$
    \item $x_{\alpha^+} = x_\alpha'$
    \item $x_{\lambda} = u(\{x_\alpha: \alpha < \lambda\})'$ for non-zero limit $\lambda$
  \end{itemize}
  (note that $\{x_\alpha: \alpha < \lambda\}$ is a chain by induction )

  Then $\alpha \mapsto x_n$ is an injection from $\gamma\to X$.
\end{proof}
\note We could also have $x_\lambda = u(\{x_\alpha : \alpha < \lambda\})$, and it is still an injection, but we put the ``prime'' just to save some lines of proof.

\note The proof of Zorn was easy, but only because we are given ordinals, definition by recursion, and Hartog's.

A typical application of Zorn's lemma is: Does every vector space have a basis? Recall that a \emph{basis} of $V$ is a subset of $V$ that is linearly independent (no finite linear combination $= 0$) and spanning (ie every $x\in V$ is a finite linear combination from it).

\begin{eg}\leavevmode
  \begin{itemize}
    \item Let $V$ be the space of all real polynomials. A basis is $\{1, x, x^2, x^3, \cdots\}$.
    \item Let $V$ be the space of all real sequences. Let $\mathbf{e}_i$ be the sequence with all $0$ except $1$ in the $i$th place. However, $\{\mathbf{e}_i\}$ is not a basis, sicne $1, 1, \cdots$ cannot be written as a finite linear combination of them. In fact, there is no countable basis (easy exercise). It turns out that there is no ``explicit basis''.
    \item Take $\R$ as a vector space over $\Q$. A basis here, if exists, is called a Hamel basis.
  \end{itemize}
\end{eg}

\begin{thm}
  Every vector space $V$ has a basis.
\end{thm}


\begin{proof}
  ``Go for maximal linearly independent set''

  Let $X$ be the set of all linearly independent subsets of $V$, ordered by inclusion. We want to find a maximal $B\in X$. Then $B$ is a basis. Otherwise, if $B$ does not span $V$, choose $x\not\in \spn B$, and $B\cup \{x\}$ is independent, contradicting maximality. 
  
  So we have to find such a maximal $B$. By Zorn's lemma, we simply have to show that every chain has an upper bound.

  Given a chain $\{A_i: i\in I\}$ in $X$, a reasonable guess is to try the union. Let $A = \bigcup A_i$. Then $A\subseteq A_i$ for all $i$, by definition. So it is enough to check that $A\in X$, ie. is linearly independent.

  Suppose not. Say $\lambda_1x_1 + \cdots + \lambda_nx_n = 0$ for some $\lambda_1 \cdots \lambda_n$ scalars (not all $0$). Suppose $x_1 \in A_{i_1}, \cdots x_n \in A_{i_n}$ for some $i_1, \cdots i_n \in I$. Then the $A_{i_k}$ contains a largest one (since it is a finite chain), and it contains all $x_i$. This contradicts independence of $A_{i_k}$.
  
  Hence by Zorn, $X$ has a maximal element.
\end{proof}
\note The only place in the proof where we actually did some maths was in the final check check that maximal $\Rightarrow$ spanning.

Another application is the completeness theorem for propositional logic when $P$, the primitives, can be uncountable.

\begin{thm}[Model existence theorem (uncountable case)]
  Let $S\subseteq L(P)$ for any primitive proposition $P$. Then if $S$ is consistent, $S$ has a model.
\end{thm}

\begin{proof}
  We need a consistent $\bar S \subseteq S$ such that $\forall t\in L$, $t\in \bar S$ or $\neg t\in \bar S$. Then we have a valuation $v(t) = \begin{cases} 1 & t\in \bar S \\ 0 & t\not\in \bar S\end{cases}$, as in our original proof for the countable case.

  So we seek a \emph{maximal} consistent $\bar S\supseteq S$. Then done: if $t\not\in \bar S$, then $\bar S \cup \{t\}\vdash \bot$ by maximality. So $\bar S\vdash \neg t$ by deduction theorem. Then $\neg t \in \bar S$ by maximality. So either $t$ or $\neg t$ is in $\bar S$.

  Now we show that there is such a maximal $\bar S$. Let $X = \{ T\subseteq L: T\text{ is consistent }, T\subseteq S\}$. Then $X\not\emptyset$ since $S\in X$. We show that any non-empty chain has an upper bound. An obvious choice is, again the union.
  
  Let $\{T_i: i\in I\}$ be a non-empty chain. Let $T = \bigcup T_i$. Then $T\supseteq T_i$ for all $i$. So to show that $T$ is an upper bound, we have to show $T\in X$.

  Certainly, $T\supseteq S$, as any $T_i$ contains $S$ (and the chain is non-empty). So we want to show $T$ is consistent. Suppose $T\vdash \bot$. So we have $t_1, \cdots, t_n \in T$ with $\{t_1, \cdots, t_n\} \vdash \bot$, since proofs are finite. Then some $T_k$ contains all $t_i$ since $T_i$ are nested. So $T_k$ is inconsistent. Therefore $T$ must be consistent.

  Hence by Zorn's lemma, there is a maximal element of $X$.
\end{proof}
\note This is the same proof as the proof that every vector space has a basis!

\subsection{Zorn's lemma and axiom of choice}
Recall that in the proof of Zorn's, we picked $x$, then picked $x'$, then picked $x''$, \emph{ad infinitum}. Here we are making arbitrary choices of $x'$. In particular, we have made infinitely many arbitrary choices.

We did the same in IA, when proving a countable union of countable sets is countable, because we chose, for each $A_n$, a listing of $A_n$, and then list them diagonally. We needed to make a choice because each $A_n$ has a lot of possible listings, and we have to pick exactly one.

In terms of ``rules for producing sets'', we are appealing to the axiom of choice, which states that you can pick an element of each $A_i$ whenever $\{A_i: i\in I\}$ is a family of non-empty sets. Formally,
\begin{axiom}[Axiom of choice]
  Given any family $\{A_i: i\in I\}$ of non-empty sets, there is a \emph{choice function} $f: i \to \bigcup A_i$ such that $f(i)\in A_i$.
\end{axiom}
This is of a different character from the other set-building rules (eg. unions and power sets exist). The difference is that the other rules are concrete. We know exactly what $A\cup B$ is, and there is only one possible candidate for what $A\cup B$ is. ``Union'' uniquely specifies what it produces. However, the choice function is not. $\{A_i:i\in I\}$ can have many choice functions, and the axiom of choice does not give us a solid choice function. We say the axiom of choice is \emph{non-constructive}.

We are not saying that it's wrong, but it's \emph{weird}. For this reason, it is often of interest to ask ``Did I use AC?'' and ``Do I need AC?''.

\note AC is trivial if $|I| = 1$, since $A\not=\emptyset$ means $\exists x\in A$. We can also do it for two sets. Similarly, for $|I|$ finite, we can do it by induction. However, in general, AC is required to make infinite choices, ie. it cannot be deduced from the other axioms of set theory.

In the proof of Zorn's we used Choice. However, do we \emph{need} it? Is it possible to prove it without Choice?

The answer is it is necessary, since we can deduce AC from Zorn's. ie, we can write down a proof of AC from Zorn's, using only the other set-building rules.

\begin{thm}
  Zorn's Lemma $\Leftrightarrow$ Axiom of choice.
\end{thm}

As in the past uses of Zorn's lemma, we have a big scary choice function to produce. We know that we can do it for small cases, such as when $|I| = 1$. So we start with small attempts and show that the maximal attempt is what we want.
\begin{proof}
  We have already proved that AC $\Rightarrow $ Zorn. We now proved the other way round.

  Given a family $\{A_i: i\in I\}$ of non-empty sets. We say a \emph{partial choice function} is a function $f: J\to \bigcup_{i\in I}A_i$ (for some $J\subseteq I$) such that $f(j)\in A$ for all $j\in J$.

  Let $X = \{(J, f): f\text{ is a partial choice function with domain }J\}$. We order by extension, ie. $(J, f) \leq (J', f')$ iff $J\subseteq J'$ and $f'$ agrees with $f$ when both are defined.

  Given a chain $\{(J_k, f_k): k\in K\}$, we have an upper bound $\left(\bigcup J_k, \bigcup f_k\right)$, ie the function obtained by combining all functions in the chain. So by Zorn's, it has a maximal element $(J, f)$.

  Suppose $J \not = I$. Then pick $i\in I\setminus J$. Then pick $x\in A_i$. Set $J' = J\cup \{i\}$ and $f' = f\cup\{(i, x)\}$. Then this is greater than $(J, f)$. This contradicts the maximality of $(J, f)$. So we must have $J = I$, ie $f$ is a full choice function.
\end{proof}

There is another ingredient in this.
\begin{thm}[Well-ordering theorem]
  Axiom of choice $\Rightarrow$ every set $X$ can be well-ordered.
\end{thm}
\note This might be very surprising at first for, say $X = \R$, until we know Hartog's lemma, since Hartog's lemma says that there is a (well-ordered) ordinal even bigger than $\R$. So well-ordering $\R$ shouldn't be hard.

\begin{proof}
  The idea is to pick an element from $X$ and call it the first; pick another element and call it the second, and continue transfinitely until we pick everything.

  For each $A\subseteq X$ with $A\not= X$, we have some $y_A\in X\setminus A$ (here we are using choice to pick out $y_A$).

  Define $x_\alpha$ recursively: Having defined $x_{\beta}$ for all $\beta < \alpha$, if $\{x_\beta: \beta < \alpha\} = X$, then stop. Otherwise, set $x_\alpha = y_{\{x_\beta: \beta< \alpha\}}$, ie pick $x_\alpha$ to be something not yet chosen.

  We must stop at some time. Or else we have injected $\gamma(X)$ (ie the ordinal larger than $X$) into $X$, contradiction. So when stop, we have bijected $X$ with an well-ordered $x$ (ie. $I_\alpha$, where $\alpha$ is when you've stopped).
\end{proof}

Did we need AC? Yes, trivially.
\begin{thm}
  Well-ordering theorem $\Rightarrow $ Axiom of Choice.
\end{thm}

\begin{proof}
  Given non-empty sets $\{A_i: i\in I\}$, well-order $\bigcup A_i$. Then set $f(i)$ to be the least element of $A_i$.
\end{proof}
Our conclusion is:
\begin{center}
  Axiom of Choice $\Leftrightarrow$ Zorn's lemma $\Leftrightarrow$ Well-ordering theorem.
\end{center}
\note We showed their equivalence by using a lot of ordinal theory. We have to make sure that we did not use AC when building our ordinal theory (apart from the remark that $\omega_1$ is not a countable supremum - which used the fact that a countable union of countable sets is countable).

\subsection{Bourbaki-Witt theorem*}
\begin{defi}[Chain-complete poset]
  We say a poset $X$ is \emph{chain-complete} if $X \not=\emptyset$ and every non-empty chain has a supremum.
\end{defi}

\begin{eg}\leavevmode
  \begin{itemize}
    \item Every complete poset is chain-complete.
    \item Any finite (non-empty) poset, since every chain is finite and has a greatest element.
    \item $\{A\subseteq V:  A\text{ is linearly independent}\}$ for any vector space $V$ is chain-complete, as shown in the proof that every vector space has a basis.
  \end{itemize}
\end{eg}

\begin{defi}[Inflationary function]
  A function $f: X\to X$ is \emph{inflationary} if $f(x) \geq x$ for all $x$.
\end{defi}

\begin{thm}[Bourbaki-Witt theorem]
  If $X$ is chain-complete and $f: X\to X$ is inflationary, then $f$ has a fixed point.
\end{thm}
This is follows instantly from Zorn's, since $X$ has a maximal element $x$, and since $f(x) \geq x$, we must have $f(x) = x$. However, we can prove Bourbaki-Witt without choice. In the proof of Zorn's, we had to ``pick'' and $x_1 > x_0$. Here, we can simply let
\[
  x_0 \xmapsto{\,f\,} x_1 \xmapsto{\,f\,} x_2 \xmapsto{\,f\,} x_3 \cdots
\]
and do the same proof to find a fixed point.

We can view this as the ``AC-free'' part of Zorn's. It can be used to prove Zorn's lemma, but the proof is totally magic.

\note Zorn is hard to prove from first principles because we needed ordinals, recursion, Hartogs etc. It is NOT because of its relation with AC (AC is very helpful in the proof!).

\section{Predicate logic}
\subsection{Overview or the set-up}
Recall that a \emph{group} is a set $A$ equipped with operations like $m: A^2\to A$ (multiplication), with \emph{arity} 2 (ie takes 2 inputs); $i: A\to A$, the inverse with arity 1, and a constant $e\in A$. We can see this as a function $e: A^0 \to A$, ie. a function that takes no inputs and outputs an element in $A$. We say it has arity 0. They have to satisfy sever rules, eg. $(\forall x, y, z) m(x, m(y, z)) = m(m(x, y), z)$.

We can compare propositional logic and predicate logic:

\noindent\begin{tabular}{p{0.45\textwidth}p{0.45\textwidth}}
  \toprule
  Propositional logic & Predicate logic\\
  \midrule
  Language & eg. language of groups ($m, i, e$ and axioms)\\
  Valuation & A structure, ie. a set equipped with functions and so on, of the correct arities\\
  $S\models t$ & $S\models t$: in any structure where all of $S$ is true, $t$ is true. eg, Axioms of group theory $\models m(e, e) = e$, ie in any set that satisfies the group axioms, $m(e, e) = e$.\\
  $S\vdash t$ & $S\vdash t$: we can prove $t$ from $S$, but with more axioms and rules.\\
  \bottomrule
\end{tabular}

\end{document}
